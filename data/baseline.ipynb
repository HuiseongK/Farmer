{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 농산물 가격 예측을 위한 AI 모델 개발 \n",
    "- '2024 농산물 가격 예측 AI 경진대회'는 데이터와 AI 기술을 활용하여 농산물 가격 예측 능력을 향상시키는 것을 목표로 합니다.<br>  이 대회는 농업 분야의 복잡한 시계열 데이터를 효율적으로 분석하고 예측할 수 있는 AI 알고리즘 개발에 초점을 맞추고 있습니다. <br> <br>\n",
    "- 이 대회의 궁극적 목적은 참가자들의 시계열 데이터 분석 및 예측 역량을 강화하고, <br> AI 기술이 실제 농산물 가격 예측과 관련 정책 결정에 어떻게 기여할 수 있는지 탐구하는 것입니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm.notebook import tqdm\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from types import SimpleNamespace\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"learning_rate\": 2e-4,\n",
    "    \"epoch\": 100,\n",
    "    \"batch_size\": 64,\n",
    "    \"hidden_size\": 64,\n",
    "    \"num_layers\": 2,\n",
    "    \"output_size\": 3\n",
    "}\n",
    "\n",
    "CFG = SimpleNamespace(**config)\n",
    "\n",
    "품목_리스트 = ['건고추', '사과', '감자', '배', '깐마늘(국산)', '무', '상추', '배추', '양파', '대파']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Function for Feature Engineering\n",
    "- 타겟의 필터 조건을 제외한 메타데이터의 필터 조건은 참가자들 각자의 기준에 맞춰 자유롭게 사용가능 \n",
    "- 밑의 필터 조건은 임의로 제공하는 예시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def process_data(raw_file, 산지공판장_file, 전국도매_file, 품목명, scaler=None):\n",
    "    raw_data = pd.read_csv(raw_file)\n",
    "    산지공판장 = pd.read_csv(산지공판장_file)\n",
    "    전국도매 = pd.read_csv(전국도매_file)\n",
    "\n",
    "    # 타겟 및 메타데이터 필터 조건 정의\n",
    "    conditions = {\n",
    "    '감자': {\n",
    "        'target': lambda df: (df['품종명'] == '감자 수미') & (df['거래단위'] == '20키로상자') & (df['등급'] == '상'),\n",
    "        '공판장': {'공판장명': ['*전국농협공판장'], '품목명': ['감자'], '품종명': ['수미'], '등급명': ['상']},\n",
    "        '도매': {'시장명': ['*전국도매시장'], '품목명': ['감자'], '품종명': ['수미']}\n",
    "    },\n",
    "    '건고추': {\n",
    "        'target': lambda df: (df['품종명'] == '화건') & (df['거래단위'] == '30 kg') & (df['등급'] == '상품'),\n",
    "        '공판장': None, \n",
    "        '도매': None  \n",
    "    },\n",
    "    '깐마늘(국산)': {\n",
    "        'target': lambda df: (df['거래단위'] == '20 kg') & (df['등급'] == '상품'),\n",
    "        '공판장': {'공판장명': ['*전국농협공판장'], '품목명': ['마늘'], '품종명': ['깐마늘'], '등급명': ['상']},\n",
    "        '도매': {'시장명': ['*전국도매시장'], '품목명': ['마늘'], '품종명': ['깐마늘']}\n",
    "    },\n",
    "    '대파': {\n",
    "        'target': lambda df: (df['품종명'] == '대파(일반)') & (df['거래단위'] == '1키로단') & (df['등급'] == '상'),\n",
    "        '공판장': {'공판장명': ['*전국농협공판장'], '품목명': ['대파'], '품종명': ['대파(일반)'], '등급명': ['상']},\n",
    "        '도매': {'시장명': ['*전국도매시장'], '품목명': ['대파'], '품종명': ['대파(일반)']}\n",
    "    },\n",
    "    '무': {\n",
    "        'target': lambda df: (df['거래단위'] == '20키로상자') & (df['등급'] == '상'),\n",
    "        '공판장': {'공판장명': ['*전국농협공판장'], '품목명': ['무'], '품종명': ['기타무'], '등급명': ['상']},\n",
    "        '도매': {'시장명': ['*전국도매시장'], '품목명': ['무'], '품종명': ['무']}\n",
    "    },\n",
    "    '배추': {\n",
    "        'target': lambda df: (df['거래단위'] == '10키로망대') & (df['등급'] == '상'),\n",
    "        '공판장': {'공판장명': ['*전국농협공판장'], '품목명': ['배추'], '품종명': ['쌈배추'], '등급명': ['상']},\n",
    "        '도매': {'시장명': ['*전국도매시장'], '품목명': ['배추'], '품종명': ['배추']}\n",
    "    },\n",
    "    '사과': {\n",
    "        'target': lambda df: (df['품종명'].isin(['홍로', '후지'])) & (df['거래단위'] == '10 개') & (df['등급'] == '상품'),\n",
    "        '공판장': {'공판장명': ['*전국농협공판장'], '품목명': ['사과'], '품종명': ['후지'], '등급명': ['상']},\n",
    "        '도매': {'시장명': ['*전국도매시장'], '품목명': ['사과'], '품종명': ['후지']}\n",
    "    },\n",
    "    '상추': {\n",
    "        'target': lambda df: (df['품종명'] == '청') & (df['거래단위'] == '100 g') & (df['등급'] == '상품'),\n",
    "        '공판장': {'공판장명': ['*전국농협공판장'], '품목명': ['상추'], '품종명': ['청상추'], '등급명': ['상']},\n",
    "        '도매': {'시장명': ['*전국도매시장'], '품목명': ['상추'], '품종명': ['청상추']}\n",
    "    },\n",
    "    '양파': {\n",
    "        'target': lambda df: (df['품종명'] == '양파') & (df['거래단위'] == '1키로') & (df['등급'] == '상'),\n",
    "        '공판장': {'공판장명': ['*전국농협공판장'], '품목명': ['양파'], '품종명': ['기타양파'], '등급명': ['상']},\n",
    "        '도매': {'시장명': ['*전국도매시장'], '품목명': ['양파'], '품종명': ['양파(일반)']}\n",
    "    },\n",
    "    '배': {\n",
    "        'target': lambda df: (df['품종명'] == '신고') & (df['거래단위'] == '10 개') & (df['등급'] == '상품'),\n",
    "        '공판장': {'공판장명': ['*전국농협공판장'], '품목명': ['배'], '품종명': ['신고'], '등급명': ['상']},\n",
    "        '도매': {'시장명': ['*전국도매시장'], '품목명': ['배'], '품종명': ['신고']}\n",
    "    }\n",
    "    }\n",
    "\n",
    "    # 타겟 데이터 필터링\n",
    "    raw_품목 = raw_data[raw_data['품목명'] == 품목명]\n",
    "    target_mask = conditions[품목명]['target'](raw_품목)\n",
    "    filtered_data = raw_품목[target_mask]\n",
    "\n",
    "    # 다른 품종에 대한 파생변수 생성\n",
    "    other_data = raw_품목[~target_mask]\n",
    "    unique_combinations = other_data[['품종명', '거래단위', '등급']].drop_duplicates()\n",
    "    for _, row in unique_combinations.iterrows():\n",
    "        품종명, 거래단위, 등급 = row['품종명'], row['거래단위'], row['등급']\n",
    "        mask = (other_data['품종명'] == 품종명) & (other_data['거래단위'] == 거래단위) & (other_data['등급'] == 등급)\n",
    "        temp_df = other_data[mask]\n",
    "        for col in ['평년 평균가격(원)', '평균가격(원)']:\n",
    "            new_col_name = f'{품종명}_{거래단위}_{등급}_{col}'\n",
    "            filtered_data = filtered_data.merge(temp_df[['시점', col]], on='시점', how='left', suffixes=('', f'_{new_col_name}'))\n",
    "            filtered_data.rename(columns={f'{col}_{new_col_name}': new_col_name}, inplace=True)\n",
    "\n",
    "\n",
    "    # 공판장 데이터 처리\n",
    "    if conditions[품목명]['공판장']:\n",
    "        filtered_공판장 = 산지공판장\n",
    "        for key, value in conditions[품목명]['공판장'].items():\n",
    "            filtered_공판장 = filtered_공판장[filtered_공판장[key].isin(value)]\n",
    "        \n",
    "        filtered_공판장 = filtered_공판장.add_prefix('공판장_').rename(columns={'공판장_시점': '시점'})\n",
    "        filtered_data = filtered_data.merge(filtered_공판장, on='시점', how='left')\n",
    "\n",
    "    # 도매 데이터 처리\n",
    "    if conditions[품목명]['도매']:\n",
    "        filtered_도매 = 전국도매\n",
    "        for key, value in conditions[품목명]['도매'].items():\n",
    "            filtered_도매 = filtered_도매[filtered_도매[key].isin(value)]\n",
    "        \n",
    "        filtered_도매 = filtered_도매.add_prefix('도매_').rename(columns={'도매_시점': '시점'})\n",
    "        filtered_data = filtered_data.merge(filtered_도매, on='시점', how='left')\n",
    "\n",
    "    # 수치형 컬럼 처리\n",
    "    numeric_columns = filtered_data.select_dtypes(include=[np.number]).columns\n",
    "    filtered_data = filtered_data[['시점'] + list(numeric_columns)]\n",
    "    filtered_data[numeric_columns] = filtered_data[numeric_columns].fillna(0)\n",
    "\n",
    "    # 정규화 적용\n",
    "    if scaler is None:\n",
    "        scaler = MinMaxScaler()\n",
    "        filtered_data[numeric_columns] = scaler.fit_transform(filtered_data[numeric_columns])\n",
    "    else:\n",
    "        filtered_data[numeric_columns] = scaler.transform(filtered_data[numeric_columns])\n",
    "\n",
    "    return filtered_data, scaler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Custom Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgriculturePriceDataset(Dataset):\n",
    "    def __init__(self, dataframe, window_size=9, prediction_length=3, is_test=False):\n",
    "        self.data = dataframe\n",
    "        self.window_size = window_size\n",
    "        self.prediction_length = prediction_length\n",
    "        self.is_test = is_test\n",
    "\n",
    "        self.price_column = [col for col in self.data.columns if '평균가격(원)' in col and len(col.split('_')) == 1][0]\n",
    "        self.numeric_columns = self.data.select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "        self.sequences = []\n",
    "        if not self.is_test:\n",
    "            for i in range(len(self.data) - self.window_size - self.prediction_length + 1):\n",
    "                x = self.data[self.numeric_columns].iloc[i:i+self.window_size].values\n",
    "                y = self.data[self.price_column].iloc[i+self.window_size:i+self.window_size+self.prediction_length].values\n",
    "                self.sequences.append((x, y))\n",
    "        else:\n",
    "            self.sequences = [self.data[self.numeric_columns].values]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if not self.is_test:\n",
    "            x, y = self.sequences[idx]\n",
    "            return torch.FloatTensor(x), torch.FloatTensor(y)\n",
    "        else:\n",
    "            return torch.FloatTensor(self.sequences[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Model Architecture and Training Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class PricePredictionLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
    "        super(PricePredictionLSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n",
    "\n",
    "def train_model(model, train_loader, criterion, optimizer, num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch_x, batch_y in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_x)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(train_loader)\n",
    "\n",
    "def evaluate_model(model, test_loader, criterion):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_x, batch_y in test_loader:\n",
    "            outputs = model(batch_x)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            total_loss += loss.item()\n",
    "    return total_loss / len(test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Models and Generate Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6277750b79240ca8dbfbbf7dbb23aac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "품목 처리 중:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Train Loss: 0.6836, Val Loss: 0.6525\n",
      "Epoch 2/100, Train Loss: 0.6674, Val Loss: 0.6446\n",
      "Epoch 3/100, Train Loss: 0.6646, Val Loss: 0.6367\n",
      "Epoch 4/100, Train Loss: 0.6544, Val Loss: 0.6286\n",
      "Epoch 5/100, Train Loss: 0.6509, Val Loss: 0.6205\n",
      "Epoch 6/100, Train Loss: 0.6369, Val Loss: 0.6122\n",
      "Epoch 7/100, Train Loss: 0.6299, Val Loss: 0.6036\n",
      "Epoch 8/100, Train Loss: 0.6240, Val Loss: 0.5947\n",
      "Epoch 9/100, Train Loss: 0.6153, Val Loss: 0.5854\n",
      "Epoch 10/100, Train Loss: 0.6086, Val Loss: 0.5757\n",
      "Epoch 11/100, Train Loss: 0.6005, Val Loss: 0.5653\n",
      "Epoch 12/100, Train Loss: 0.5887, Val Loss: 0.5543\n",
      "Epoch 13/100, Train Loss: 0.5749, Val Loss: 0.5424\n",
      "Epoch 14/100, Train Loss: 0.5617, Val Loss: 0.5295\n",
      "Epoch 15/100, Train Loss: 0.5483, Val Loss: 0.5153\n",
      "Epoch 16/100, Train Loss: 0.5354, Val Loss: 0.4997\n",
      "Epoch 17/100, Train Loss: 0.5190, Val Loss: 0.4823\n",
      "Epoch 18/100, Train Loss: 0.5028, Val Loss: 0.4628\n",
      "Epoch 19/100, Train Loss: 0.4861, Val Loss: 0.4408\n",
      "Epoch 20/100, Train Loss: 0.4601, Val Loss: 0.4158\n",
      "Epoch 21/100, Train Loss: 0.4335, Val Loss: 0.3872\n",
      "Epoch 22/100, Train Loss: 0.4031, Val Loss: 0.3542\n",
      "Epoch 23/100, Train Loss: 0.3723, Val Loss: 0.3160\n",
      "Epoch 24/100, Train Loss: 0.3296, Val Loss: 0.2716\n",
      "Epoch 25/100, Train Loss: 0.2884, Val Loss: 0.2198\n",
      "Epoch 26/100, Train Loss: 0.2358, Val Loss: 0.1614\n",
      "Epoch 27/100, Train Loss: 0.1789, Val Loss: 0.1403\n",
      "Epoch 28/100, Train Loss: 0.1507, Val Loss: 0.1319\n",
      "Epoch 29/100, Train Loss: 0.1447, Val Loss: 0.1306\n",
      "Epoch 30/100, Train Loss: 0.1400, Val Loss: 0.1246\n",
      "Epoch 31/100, Train Loss: 0.1306, Val Loss: 0.1259\n",
      "Epoch 32/100, Train Loss: 0.1241, Val Loss: 0.1158\n",
      "Epoch 33/100, Train Loss: 0.1107, Val Loss: 0.0991\n",
      "Epoch 34/100, Train Loss: 0.0951, Val Loss: 0.0879\n",
      "Epoch 35/100, Train Loss: 0.0908, Val Loss: 0.0801\n",
      "Epoch 36/100, Train Loss: 0.0845, Val Loss: 0.0774\n",
      "Epoch 37/100, Train Loss: 0.0877, Val Loss: 0.0770\n",
      "Epoch 38/100, Train Loss: 0.0937, Val Loss: 0.0771\n",
      "Epoch 39/100, Train Loss: 0.0952, Val Loss: 0.0760\n",
      "Epoch 40/100, Train Loss: 0.0893, Val Loss: 0.0754\n",
      "Epoch 41/100, Train Loss: 0.0883, Val Loss: 0.0754\n",
      "Epoch 42/100, Train Loss: 0.0843, Val Loss: 0.0755\n",
      "Epoch 43/100, Train Loss: 0.0821, Val Loss: 0.0767\n",
      "Epoch 44/100, Train Loss: 0.0791, Val Loss: 0.0785\n",
      "Epoch 45/100, Train Loss: 0.0815, Val Loss: 0.0786\n",
      "Epoch 46/100, Train Loss: 0.0815, Val Loss: 0.0775\n",
      "Epoch 47/100, Train Loss: 0.0790, Val Loss: 0.0760\n",
      "Epoch 48/100, Train Loss: 0.0803, Val Loss: 0.0742\n",
      "Epoch 49/100, Train Loss: 0.0776, Val Loss: 0.0729\n",
      "Epoch 50/100, Train Loss: 0.0772, Val Loss: 0.0722\n",
      "Epoch 51/100, Train Loss: 0.0750, Val Loss: 0.0722\n",
      "Epoch 52/100, Train Loss: 0.0732, Val Loss: 0.0725\n",
      "Epoch 53/100, Train Loss: 0.0767, Val Loss: 0.0725\n",
      "Epoch 54/100, Train Loss: 0.0774, Val Loss: 0.0721\n",
      "Epoch 55/100, Train Loss: 0.0750, Val Loss: 0.0715\n",
      "Epoch 56/100, Train Loss: 0.0744, Val Loss: 0.0709\n",
      "Epoch 57/100, Train Loss: 0.0717, Val Loss: 0.0701\n",
      "Epoch 58/100, Train Loss: 0.0727, Val Loss: 0.0695\n",
      "Epoch 59/100, Train Loss: 0.0723, Val Loss: 0.0689\n",
      "Epoch 60/100, Train Loss: 0.0683, Val Loss: 0.0684\n",
      "Epoch 61/100, Train Loss: 0.0708, Val Loss: 0.0682\n",
      "Epoch 62/100, Train Loss: 0.0696, Val Loss: 0.0680\n",
      "Epoch 63/100, Train Loss: 0.0681, Val Loss: 0.0680\n",
      "Epoch 64/100, Train Loss: 0.0701, Val Loss: 0.0674\n",
      "Epoch 65/100, Train Loss: 0.0682, Val Loss: 0.0668\n",
      "Epoch 66/100, Train Loss: 0.0692, Val Loss: 0.0663\n",
      "Epoch 67/100, Train Loss: 0.0664, Val Loss: 0.0661\n",
      "Epoch 68/100, Train Loss: 0.0648, Val Loss: 0.0659\n",
      "Epoch 69/100, Train Loss: 0.0649, Val Loss: 0.0656\n",
      "Epoch 70/100, Train Loss: 0.0639, Val Loss: 0.0646\n",
      "Epoch 71/100, Train Loss: 0.0632, Val Loss: 0.0641\n",
      "Epoch 72/100, Train Loss: 0.0637, Val Loss: 0.0642\n",
      "Epoch 73/100, Train Loss: 0.0621, Val Loss: 0.0648\n",
      "Epoch 74/100, Train Loss: 0.0613, Val Loss: 0.0635\n",
      "Epoch 75/100, Train Loss: 0.0599, Val Loss: 0.0624\n",
      "Epoch 76/100, Train Loss: 0.0613, Val Loss: 0.0627\n",
      "Epoch 77/100, Train Loss: 0.0650, Val Loss: 0.0637\n",
      "Epoch 78/100, Train Loss: 0.0630, Val Loss: 0.0620\n",
      "Epoch 79/100, Train Loss: 0.0642, Val Loss: 0.0609\n",
      "Epoch 80/100, Train Loss: 0.0600, Val Loss: 0.0613\n",
      "Epoch 81/100, Train Loss: 0.0610, Val Loss: 0.0620\n",
      "Epoch 82/100, Train Loss: 0.0589, Val Loss: 0.0605\n",
      "Epoch 83/100, Train Loss: 0.0599, Val Loss: 0.0598\n",
      "Epoch 84/100, Train Loss: 0.0600, Val Loss: 0.0598\n",
      "Epoch 85/100, Train Loss: 0.0599, Val Loss: 0.0596\n",
      "Epoch 86/100, Train Loss: 0.0617, Val Loss: 0.0595\n",
      "Epoch 87/100, Train Loss: 0.0598, Val Loss: 0.0589\n",
      "Epoch 88/100, Train Loss: 0.0584, Val Loss: 0.0581\n",
      "Epoch 89/100, Train Loss: 0.0581, Val Loss: 0.0576\n",
      "Epoch 90/100, Train Loss: 0.0593, Val Loss: 0.0581\n",
      "Epoch 91/100, Train Loss: 0.0600, Val Loss: 0.0579\n",
      "Epoch 92/100, Train Loss: 0.0569, Val Loss: 0.0565\n",
      "Epoch 93/100, Train Loss: 0.0571, Val Loss: 0.0560\n",
      "Epoch 94/100, Train Loss: 0.0549, Val Loss: 0.0563\n",
      "Epoch 95/100, Train Loss: 0.0579, Val Loss: 0.0555\n",
      "Epoch 96/100, Train Loss: 0.0575, Val Loss: 0.0547\n",
      "Epoch 97/100, Train Loss: 0.0564, Val Loss: 0.0546\n",
      "Epoch 98/100, Train Loss: 0.0548, Val Loss: 0.0542\n",
      "Epoch 99/100, Train Loss: 0.0561, Val Loss: 0.0532\n",
      "Epoch 100/100, Train Loss: 0.0552, Val Loss: 0.0532\n",
      "Best Validation Loss for 건고추: 0.0532\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5cb04d1b27d49ba9309878927c47cf3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "테스트 파일 추론 중:   0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Train Loss: 0.8333, Val Loss: 0.8394\n",
      "Epoch 2/100, Train Loss: 0.8258, Val Loss: 0.8306\n",
      "Epoch 3/100, Train Loss: 0.8156, Val Loss: 0.8216\n",
      "Epoch 4/100, Train Loss: 0.8050, Val Loss: 0.8122\n",
      "Epoch 5/100, Train Loss: 0.7995, Val Loss: 0.8025\n",
      "Epoch 6/100, Train Loss: 0.7825, Val Loss: 0.7926\n",
      "Epoch 7/100, Train Loss: 0.7756, Val Loss: 0.7821\n",
      "Epoch 8/100, Train Loss: 0.7639, Val Loss: 0.7708\n",
      "Epoch 9/100, Train Loss: 0.7542, Val Loss: 0.7587\n",
      "Epoch 10/100, Train Loss: 0.7391, Val Loss: 0.7456\n",
      "Epoch 11/100, Train Loss: 0.7247, Val Loss: 0.7311\n",
      "Epoch 12/100, Train Loss: 0.7130, Val Loss: 0.7152\n",
      "Epoch 13/100, Train Loss: 0.6925, Val Loss: 0.6974\n",
      "Epoch 14/100, Train Loss: 0.6738, Val Loss: 0.6774\n",
      "Epoch 15/100, Train Loss: 0.6510, Val Loss: 0.6552\n",
      "Epoch 16/100, Train Loss: 0.6300, Val Loss: 0.6300\n",
      "Epoch 17/100, Train Loss: 0.6016, Val Loss: 0.6013\n",
      "Epoch 18/100, Train Loss: 0.5707, Val Loss: 0.5682\n",
      "Epoch 19/100, Train Loss: 0.5352, Val Loss: 0.5302\n",
      "Epoch 20/100, Train Loss: 0.4917, Val Loss: 0.4863\n",
      "Epoch 21/100, Train Loss: 0.4442, Val Loss: 0.4358\n",
      "Epoch 22/100, Train Loss: 0.3938, Val Loss: 0.3795\n",
      "Epoch 23/100, Train Loss: 0.3350, Val Loss: 0.3183\n",
      "Epoch 24/100, Train Loss: 0.2742, Val Loss: 0.2653\n",
      "Epoch 25/100, Train Loss: 0.2343, Val Loss: 0.2350\n",
      "Epoch 26/100, Train Loss: 0.2144, Val Loss: 0.2184\n",
      "Epoch 27/100, Train Loss: 0.2058, Val Loss: 0.2080\n",
      "Epoch 28/100, Train Loss: 0.1941, Val Loss: 0.1889\n",
      "Epoch 29/100, Train Loss: 0.1752, Val Loss: 0.1620\n",
      "Epoch 30/100, Train Loss: 0.1517, Val Loss: 0.1347\n",
      "Epoch 31/100, Train Loss: 0.1256, Val Loss: 0.1159\n",
      "Epoch 32/100, Train Loss: 0.1097, Val Loss: 0.1087\n",
      "Epoch 33/100, Train Loss: 0.1027, Val Loss: 0.1107\n",
      "Epoch 34/100, Train Loss: 0.1042, Val Loss: 0.1168\n",
      "Epoch 35/100, Train Loss: 0.1032, Val Loss: 0.1205\n",
      "Epoch 36/100, Train Loss: 0.1087, Val Loss: 0.1187\n",
      "Epoch 37/100, Train Loss: 0.1069, Val Loss: 0.1118\n",
      "Epoch 38/100, Train Loss: 0.1017, Val Loss: 0.1022\n",
      "Epoch 39/100, Train Loss: 0.0911, Val Loss: 0.0960\n",
      "Epoch 40/100, Train Loss: 0.0903, Val Loss: 0.0942\n",
      "Epoch 41/100, Train Loss: 0.0863, Val Loss: 0.0948\n",
      "Epoch 42/100, Train Loss: 0.0904, Val Loss: 0.0954\n",
      "Epoch 43/100, Train Loss: 0.0887, Val Loss: 0.0955\n",
      "Epoch 44/100, Train Loss: 0.0868, Val Loss: 0.0962\n",
      "Epoch 45/100, Train Loss: 0.0871, Val Loss: 0.0967\n",
      "Epoch 46/100, Train Loss: 0.0860, Val Loss: 0.0952\n",
      "Epoch 47/100, Train Loss: 0.0830, Val Loss: 0.0931\n",
      "Epoch 48/100, Train Loss: 0.0821, Val Loss: 0.0921\n",
      "Epoch 49/100, Train Loss: 0.0821, Val Loss: 0.0910\n",
      "Epoch 50/100, Train Loss: 0.0816, Val Loss: 0.0902\n",
      "Epoch 51/100, Train Loss: 0.0817, Val Loss: 0.0897\n",
      "Epoch 52/100, Train Loss: 0.0768, Val Loss: 0.0892\n",
      "Epoch 53/100, Train Loss: 0.0795, Val Loss: 0.0890\n",
      "Epoch 54/100, Train Loss: 0.0790, Val Loss: 0.0888\n",
      "Epoch 55/100, Train Loss: 0.0794, Val Loss: 0.0888\n",
      "Epoch 56/100, Train Loss: 0.0753, Val Loss: 0.0889\n",
      "Epoch 57/100, Train Loss: 0.0772, Val Loss: 0.0885\n",
      "Epoch 58/100, Train Loss: 0.0752, Val Loss: 0.0881\n",
      "Epoch 59/100, Train Loss: 0.0745, Val Loss: 0.0876\n",
      "Epoch 60/100, Train Loss: 0.0765, Val Loss: 0.0872\n",
      "Epoch 61/100, Train Loss: 0.0742, Val Loss: 0.0871\n",
      "Epoch 62/100, Train Loss: 0.0762, Val Loss: 0.0870\n",
      "Epoch 63/100, Train Loss: 0.0714, Val Loss: 0.0874\n",
      "Epoch 64/100, Train Loss: 0.0753, Val Loss: 0.0874\n",
      "Epoch 65/100, Train Loss: 0.0732, Val Loss: 0.0874\n",
      "Epoch 66/100, Train Loss: 0.0690, Val Loss: 0.0872\n",
      "Epoch 67/100, Train Loss: 0.0733, Val Loss: 0.0870\n",
      "Epoch 68/100, Train Loss: 0.0699, Val Loss: 0.0866\n",
      "Epoch 69/100, Train Loss: 0.0711, Val Loss: 0.0862\n",
      "Epoch 70/100, Train Loss: 0.0737, Val Loss: 0.0858\n",
      "Epoch 71/100, Train Loss: 0.0690, Val Loss: 0.0857\n",
      "Epoch 72/100, Train Loss: 0.0705, Val Loss: 0.0855\n",
      "Epoch 73/100, Train Loss: 0.0691, Val Loss: 0.0856\n",
      "Epoch 74/100, Train Loss: 0.0687, Val Loss: 0.0859\n",
      "Epoch 75/100, Train Loss: 0.0717, Val Loss: 0.0860\n",
      "Epoch 76/100, Train Loss: 0.0690, Val Loss: 0.0859\n",
      "Epoch 77/100, Train Loss: 0.0662, Val Loss: 0.0853\n",
      "Epoch 78/100, Train Loss: 0.0708, Val Loss: 0.0850\n",
      "Epoch 79/100, Train Loss: 0.0707, Val Loss: 0.0848\n",
      "Epoch 80/100, Train Loss: 0.0653, Val Loss: 0.0848\n",
      "Epoch 81/100, Train Loss: 0.0647, Val Loss: 0.0847\n",
      "Epoch 82/100, Train Loss: 0.0665, Val Loss: 0.0846\n",
      "Epoch 83/100, Train Loss: 0.0638, Val Loss: 0.0849\n",
      "Epoch 84/100, Train Loss: 0.0653, Val Loss: 0.0848\n",
      "Epoch 85/100, Train Loss: 0.0640, Val Loss: 0.0843\n",
      "Epoch 86/100, Train Loss: 0.0621, Val Loss: 0.0838\n",
      "Epoch 87/100, Train Loss: 0.0652, Val Loss: 0.0836\n",
      "Epoch 88/100, Train Loss: 0.0636, Val Loss: 0.0835\n",
      "Epoch 89/100, Train Loss: 0.0604, Val Loss: 0.0841\n",
      "Epoch 90/100, Train Loss: 0.0623, Val Loss: 0.0840\n",
      "Epoch 91/100, Train Loss: 0.0611, Val Loss: 0.0832\n",
      "Epoch 92/100, Train Loss: 0.0634, Val Loss: 0.0832\n",
      "Epoch 93/100, Train Loss: 0.0605, Val Loss: 0.0832\n",
      "Epoch 94/100, Train Loss: 0.0597, Val Loss: 0.0831\n",
      "Epoch 95/100, Train Loss: 0.0600, Val Loss: 0.0832\n",
      "Epoch 96/100, Train Loss: 0.0580, Val Loss: 0.0831\n",
      "Epoch 97/100, Train Loss: 0.0586, Val Loss: 0.0830\n",
      "Epoch 98/100, Train Loss: 0.0593, Val Loss: 0.0829\n",
      "Epoch 99/100, Train Loss: 0.0550, Val Loss: 0.0829\n",
      "Epoch 100/100, Train Loss: 0.0591, Val Loss: 0.0829\n",
      "Best Validation Loss for 사과: 0.0829\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96ba93d47bae4306b39b6ac266cde6b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "테스트 파일 추론 중:   0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Train Loss: 0.4122, Val Loss: 0.3290\n",
      "Epoch 2/100, Train Loss: 0.4024, Val Loss: 0.3213\n",
      "Epoch 3/100, Train Loss: 0.4019, Val Loss: 0.3141\n",
      "Epoch 4/100, Train Loss: 0.3888, Val Loss: 0.3070\n",
      "Epoch 5/100, Train Loss: 0.3817, Val Loss: 0.2997\n",
      "Epoch 6/100, Train Loss: 0.3707, Val Loss: 0.2922\n",
      "Epoch 7/100, Train Loss: 0.3709, Val Loss: 0.2846\n",
      "Epoch 8/100, Train Loss: 0.3492, Val Loss: 0.2765\n",
      "Epoch 9/100, Train Loss: 0.3387, Val Loss: 0.2679\n",
      "Epoch 10/100, Train Loss: 0.3299, Val Loss: 0.2587\n",
      "Epoch 11/100, Train Loss: 0.3166, Val Loss: 0.2493\n",
      "Epoch 12/100, Train Loss: 0.3062, Val Loss: 0.2392\n",
      "Epoch 13/100, Train Loss: 0.3060, Val Loss: 0.2286\n",
      "Epoch 14/100, Train Loss: 0.2753, Val Loss: 0.2176\n",
      "Epoch 15/100, Train Loss: 0.2743, Val Loss: 0.2078\n",
      "Epoch 16/100, Train Loss: 0.2607, Val Loss: 0.1999\n",
      "Epoch 17/100, Train Loss: 0.2527, Val Loss: 0.1942\n",
      "Epoch 18/100, Train Loss: 0.2348, Val Loss: 0.1909\n",
      "Epoch 19/100, Train Loss: 0.2227, Val Loss: 0.1894\n",
      "Epoch 20/100, Train Loss: 0.2127, Val Loss: 0.1895\n",
      "Epoch 21/100, Train Loss: 0.2000, Val Loss: 0.1906\n",
      "Epoch 22/100, Train Loss: 0.1915, Val Loss: 0.1934\n",
      "Epoch 23/100, Train Loss: 0.1933, Val Loss: 0.1979\n",
      "Epoch 24/100, Train Loss: 0.1880, Val Loss: 0.2022\n",
      "Epoch 25/100, Train Loss: 0.1860, Val Loss: 0.2048\n",
      "Epoch 26/100, Train Loss: 0.1828, Val Loss: 0.2055\n",
      "Epoch 27/100, Train Loss: 0.1857, Val Loss: 0.2043\n",
      "Epoch 28/100, Train Loss: 0.1831, Val Loss: 0.2012\n",
      "Epoch 29/100, Train Loss: 0.1810, Val Loss: 0.1980\n",
      "Epoch 30/100, Train Loss: 0.1777, Val Loss: 0.1939\n",
      "Epoch 31/100, Train Loss: 0.1777, Val Loss: 0.1899\n",
      "Epoch 32/100, Train Loss: 0.1712, Val Loss: 0.1858\n",
      "Epoch 33/100, Train Loss: 0.1675, Val Loss: 0.1819\n",
      "Epoch 34/100, Train Loss: 0.1706, Val Loss: 0.1782\n",
      "Epoch 35/100, Train Loss: 0.1678, Val Loss: 0.1752\n",
      "Epoch 36/100, Train Loss: 0.1663, Val Loss: 0.1727\n",
      "Epoch 37/100, Train Loss: 0.1574, Val Loss: 0.1708\n",
      "Epoch 38/100, Train Loss: 0.1527, Val Loss: 0.1687\n",
      "Epoch 39/100, Train Loss: 0.1528, Val Loss: 0.1666\n",
      "Epoch 40/100, Train Loss: 0.1550, Val Loss: 0.1641\n",
      "Epoch 41/100, Train Loss: 0.1472, Val Loss: 0.1623\n",
      "Epoch 42/100, Train Loss: 0.1442, Val Loss: 0.1596\n",
      "Epoch 43/100, Train Loss: 0.1396, Val Loss: 0.1560\n",
      "Epoch 44/100, Train Loss: 0.1372, Val Loss: 0.1526\n",
      "Epoch 45/100, Train Loss: 0.1343, Val Loss: 0.1489\n",
      "Epoch 46/100, Train Loss: 0.1387, Val Loss: 0.1460\n",
      "Epoch 47/100, Train Loss: 0.1355, Val Loss: 0.1430\n",
      "Epoch 48/100, Train Loss: 0.1295, Val Loss: 0.1413\n",
      "Epoch 49/100, Train Loss: 0.1249, Val Loss: 0.1391\n",
      "Epoch 50/100, Train Loss: 0.1229, Val Loss: 0.1375\n",
      "Epoch 51/100, Train Loss: 0.1184, Val Loss: 0.1361\n",
      "Epoch 52/100, Train Loss: 0.1187, Val Loss: 0.1333\n",
      "Epoch 53/100, Train Loss: 0.1192, Val Loss: 0.1298\n",
      "Epoch 54/100, Train Loss: 0.1165, Val Loss: 0.1277\n",
      "Epoch 55/100, Train Loss: 0.1103, Val Loss: 0.1261\n",
      "Epoch 56/100, Train Loss: 0.1063, Val Loss: 0.1245\n",
      "Epoch 57/100, Train Loss: 0.1043, Val Loss: 0.1219\n",
      "Epoch 58/100, Train Loss: 0.1066, Val Loss: 0.1187\n",
      "Epoch 59/100, Train Loss: 0.1013, Val Loss: 0.1154\n",
      "Epoch 60/100, Train Loss: 0.0986, Val Loss: 0.1122\n",
      "Epoch 61/100, Train Loss: 0.0946, Val Loss: 0.1108\n",
      "Epoch 62/100, Train Loss: 0.0954, Val Loss: 0.1113\n",
      "Epoch 63/100, Train Loss: 0.0907, Val Loss: 0.1068\n",
      "Epoch 64/100, Train Loss: 0.0898, Val Loss: 0.1006\n",
      "Epoch 65/100, Train Loss: 0.0882, Val Loss: 0.0981\n",
      "Epoch 66/100, Train Loss: 0.0842, Val Loss: 0.0961\n",
      "Epoch 67/100, Train Loss: 0.0820, Val Loss: 0.0933\n",
      "Epoch 68/100, Train Loss: 0.0795, Val Loss: 0.0909\n",
      "Epoch 69/100, Train Loss: 0.0820, Val Loss: 0.0892\n",
      "Epoch 70/100, Train Loss: 0.0776, Val Loss: 0.0851\n",
      "Epoch 71/100, Train Loss: 0.0787, Val Loss: 0.0803\n",
      "Epoch 72/100, Train Loss: 0.0757, Val Loss: 0.0805\n",
      "Epoch 73/100, Train Loss: 0.0731, Val Loss: 0.0791\n",
      "Epoch 74/100, Train Loss: 0.0699, Val Loss: 0.0747\n",
      "Epoch 75/100, Train Loss: 0.0675, Val Loss: 0.0722\n",
      "Epoch 76/100, Train Loss: 0.0710, Val Loss: 0.0726\n",
      "Epoch 77/100, Train Loss: 0.0691, Val Loss: 0.0737\n",
      "Epoch 78/100, Train Loss: 0.0694, Val Loss: 0.0708\n",
      "Epoch 79/100, Train Loss: 0.0684, Val Loss: 0.0675\n",
      "Epoch 80/100, Train Loss: 0.0679, Val Loss: 0.0681\n",
      "Epoch 81/100, Train Loss: 0.0645, Val Loss: 0.0719\n",
      "Epoch 82/100, Train Loss: 0.0641, Val Loss: 0.0682\n",
      "Epoch 83/100, Train Loss: 0.0643, Val Loss: 0.0657\n",
      "Epoch 84/100, Train Loss: 0.0643, Val Loss: 0.0663\n",
      "Epoch 85/100, Train Loss: 0.0626, Val Loss: 0.0664\n",
      "Epoch 86/100, Train Loss: 0.0630, Val Loss: 0.0639\n",
      "Epoch 87/100, Train Loss: 0.0603, Val Loss: 0.0623\n",
      "Epoch 88/100, Train Loss: 0.0601, Val Loss: 0.0629\n",
      "Epoch 89/100, Train Loss: 0.0609, Val Loss: 0.0641\n",
      "Epoch 90/100, Train Loss: 0.0587, Val Loss: 0.0650\n",
      "Epoch 91/100, Train Loss: 0.0581, Val Loss: 0.0623\n",
      "Epoch 92/100, Train Loss: 0.0588, Val Loss: 0.0600\n",
      "Epoch 93/100, Train Loss: 0.0575, Val Loss: 0.0612\n",
      "Epoch 94/100, Train Loss: 0.0565, Val Loss: 0.0632\n",
      "Epoch 95/100, Train Loss: 0.0579, Val Loss: 0.0622\n",
      "Epoch 96/100, Train Loss: 0.0549, Val Loss: 0.0584\n",
      "Epoch 97/100, Train Loss: 0.0557, Val Loss: 0.0584\n",
      "Epoch 98/100, Train Loss: 0.0556, Val Loss: 0.0608\n",
      "Epoch 99/100, Train Loss: 0.0554, Val Loss: 0.0630\n",
      "Epoch 100/100, Train Loss: 0.0546, Val Loss: 0.0593\n",
      "Best Validation Loss for 감자: 0.0584\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "284819670e5540e496d978a3000f029e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "테스트 파일 추론 중:   0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Train Loss: 0.5344, Val Loss: 0.5804\n",
      "Epoch 2/100, Train Loss: 0.5440, Val Loss: 0.5736\n",
      "Epoch 3/100, Train Loss: 0.5314, Val Loss: 0.5668\n",
      "Epoch 4/100, Train Loss: 0.5263, Val Loss: 0.5601\n",
      "Epoch 5/100, Train Loss: 0.5218, Val Loss: 0.5532\n",
      "Epoch 6/100, Train Loss: 0.5192, Val Loss: 0.5462\n",
      "Epoch 7/100, Train Loss: 0.5073, Val Loss: 0.5390\n",
      "Epoch 8/100, Train Loss: 0.4993, Val Loss: 0.5316\n",
      "Epoch 9/100, Train Loss: 0.4958, Val Loss: 0.5238\n",
      "Epoch 10/100, Train Loss: 0.4825, Val Loss: 0.5156\n",
      "Epoch 11/100, Train Loss: 0.4751, Val Loss: 0.5069\n",
      "Epoch 12/100, Train Loss: 0.4719, Val Loss: 0.4976\n",
      "Epoch 13/100, Train Loss: 0.4508, Val Loss: 0.4876\n",
      "Epoch 14/100, Train Loss: 0.4475, Val Loss: 0.4767\n",
      "Epoch 15/100, Train Loss: 0.4322, Val Loss: 0.4650\n",
      "Epoch 16/100, Train Loss: 0.4315, Val Loss: 0.4520\n",
      "Epoch 17/100, Train Loss: 0.3964, Val Loss: 0.4377\n",
      "Epoch 18/100, Train Loss: 0.3936, Val Loss: 0.4222\n",
      "Epoch 19/100, Train Loss: 0.3708, Val Loss: 0.4052\n",
      "Epoch 20/100, Train Loss: 0.3531, Val Loss: 0.3864\n",
      "Epoch 21/100, Train Loss: 0.3381, Val Loss: 0.3651\n",
      "Epoch 22/100, Train Loss: 0.3140, Val Loss: 0.3413\n",
      "Epoch 23/100, Train Loss: 0.2878, Val Loss: 0.3153\n",
      "Epoch 24/100, Train Loss: 0.2618, Val Loss: 0.2863\n",
      "Epoch 25/100, Train Loss: 0.2327, Val Loss: 0.2584\n",
      "Epoch 26/100, Train Loss: 0.2015, Val Loss: 0.2353\n",
      "Epoch 27/100, Train Loss: 0.1844, Val Loss: 0.2221\n",
      "Epoch 28/100, Train Loss: 0.1842, Val Loss: 0.2201\n",
      "Epoch 29/100, Train Loss: 0.1752, Val Loss: 0.2211\n",
      "Epoch 30/100, Train Loss: 0.1821, Val Loss: 0.2226\n",
      "Epoch 31/100, Train Loss: 0.1911, Val Loss: 0.2221\n",
      "Epoch 32/100, Train Loss: 0.1817, Val Loss: 0.2200\n",
      "Epoch 33/100, Train Loss: 0.1793, Val Loss: 0.2172\n",
      "Epoch 34/100, Train Loss: 0.1786, Val Loss: 0.2155\n",
      "Epoch 35/100, Train Loss: 0.1694, Val Loss: 0.2150\n",
      "Epoch 36/100, Train Loss: 0.1681, Val Loss: 0.2156\n",
      "Epoch 37/100, Train Loss: 0.1742, Val Loss: 0.2161\n",
      "Epoch 38/100, Train Loss: 0.1690, Val Loss: 0.2163\n",
      "Epoch 39/100, Train Loss: 0.1703, Val Loss: 0.2161\n",
      "Epoch 40/100, Train Loss: 0.1695, Val Loss: 0.2148\n",
      "Epoch 41/100, Train Loss: 0.1662, Val Loss: 0.2130\n",
      "Epoch 42/100, Train Loss: 0.1668, Val Loss: 0.2113\n",
      "Epoch 43/100, Train Loss: 0.1627, Val Loss: 0.2098\n",
      "Epoch 44/100, Train Loss: 0.1652, Val Loss: 0.2084\n",
      "Epoch 45/100, Train Loss: 0.1634, Val Loss: 0.2073\n",
      "Epoch 46/100, Train Loss: 0.1597, Val Loss: 0.2063\n",
      "Epoch 47/100, Train Loss: 0.1625, Val Loss: 0.2055\n",
      "Epoch 48/100, Train Loss: 0.1585, Val Loss: 0.2047\n",
      "Epoch 49/100, Train Loss: 0.1585, Val Loss: 0.2041\n",
      "Epoch 50/100, Train Loss: 0.1630, Val Loss: 0.2035\n",
      "Epoch 51/100, Train Loss: 0.1571, Val Loss: 0.2028\n",
      "Epoch 52/100, Train Loss: 0.1519, Val Loss: 0.2023\n",
      "Epoch 53/100, Train Loss: 0.1518, Val Loss: 0.2017\n",
      "Epoch 54/100, Train Loss: 0.1576, Val Loss: 0.2010\n",
      "Epoch 55/100, Train Loss: 0.1509, Val Loss: 0.2000\n",
      "Epoch 56/100, Train Loss: 0.1579, Val Loss: 0.1992\n",
      "Epoch 57/100, Train Loss: 0.1579, Val Loss: 0.1979\n",
      "Epoch 58/100, Train Loss: 0.1541, Val Loss: 0.1965\n",
      "Epoch 59/100, Train Loss: 0.1566, Val Loss: 0.1952\n",
      "Epoch 60/100, Train Loss: 0.1459, Val Loss: 0.1938\n",
      "Epoch 61/100, Train Loss: 0.1487, Val Loss: 0.1926\n",
      "Epoch 62/100, Train Loss: 0.1498, Val Loss: 0.1916\n",
      "Epoch 63/100, Train Loss: 0.1478, Val Loss: 0.1907\n",
      "Epoch 64/100, Train Loss: 0.1463, Val Loss: 0.1896\n",
      "Epoch 65/100, Train Loss: 0.1494, Val Loss: 0.1883\n",
      "Epoch 66/100, Train Loss: 0.1477, Val Loss: 0.1868\n",
      "Epoch 67/100, Train Loss: 0.1365, Val Loss: 0.1852\n",
      "Epoch 68/100, Train Loss: 0.1424, Val Loss: 0.1838\n",
      "Epoch 69/100, Train Loss: 0.1393, Val Loss: 0.1825\n",
      "Epoch 70/100, Train Loss: 0.1363, Val Loss: 0.1810\n",
      "Epoch 71/100, Train Loss: 0.1376, Val Loss: 0.1792\n",
      "Epoch 72/100, Train Loss: 0.1375, Val Loss: 0.1771\n",
      "Epoch 73/100, Train Loss: 0.1357, Val Loss: 0.1749\n",
      "Epoch 74/100, Train Loss: 0.1319, Val Loss: 0.1725\n",
      "Epoch 75/100, Train Loss: 0.1324, Val Loss: 0.1707\n",
      "Epoch 76/100, Train Loss: 0.1285, Val Loss: 0.1689\n",
      "Epoch 77/100, Train Loss: 0.1277, Val Loss: 0.1672\n",
      "Epoch 78/100, Train Loss: 0.1267, Val Loss: 0.1653\n",
      "Epoch 79/100, Train Loss: 0.1217, Val Loss: 0.1626\n",
      "Epoch 80/100, Train Loss: 0.1202, Val Loss: 0.1599\n",
      "Epoch 81/100, Train Loss: 0.1239, Val Loss: 0.1567\n",
      "Epoch 82/100, Train Loss: 0.1182, Val Loss: 0.1536\n",
      "Epoch 83/100, Train Loss: 0.1158, Val Loss: 0.1503\n",
      "Epoch 84/100, Train Loss: 0.1155, Val Loss: 0.1468\n",
      "Epoch 85/100, Train Loss: 0.1119, Val Loss: 0.1439\n",
      "Epoch 86/100, Train Loss: 0.1112, Val Loss: 0.1410\n",
      "Epoch 87/100, Train Loss: 0.1111, Val Loss: 0.1392\n",
      "Epoch 88/100, Train Loss: 0.1114, Val Loss: 0.1367\n",
      "Epoch 89/100, Train Loss: 0.1084, Val Loss: 0.1340\n",
      "Epoch 90/100, Train Loss: 0.1074, Val Loss: 0.1318\n",
      "Epoch 91/100, Train Loss: 0.1071, Val Loss: 0.1301\n",
      "Epoch 92/100, Train Loss: 0.1065, Val Loss: 0.1286\n",
      "Epoch 93/100, Train Loss: 0.1075, Val Loss: 0.1277\n",
      "Epoch 94/100, Train Loss: 0.1066, Val Loss: 0.1268\n",
      "Epoch 95/100, Train Loss: 0.1062, Val Loss: 0.1262\n",
      "Epoch 96/100, Train Loss: 0.1049, Val Loss: 0.1257\n",
      "Epoch 97/100, Train Loss: 0.1052, Val Loss: 0.1253\n",
      "Epoch 98/100, Train Loss: 0.1050, Val Loss: 0.1250\n",
      "Epoch 99/100, Train Loss: 0.1017, Val Loss: 0.1246\n",
      "Epoch 100/100, Train Loss: 0.1045, Val Loss: 0.1244\n",
      "Best Validation Loss for 배: 0.1244\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8251e2ba2f294e7296e9b1508205e64b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "테스트 파일 추론 중:   0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Train Loss: 0.0421, Val Loss: 0.0360\n",
      "Epoch 2/100, Train Loss: 0.0343, Val Loss: 0.0314\n",
      "Epoch 3/100, Train Loss: 0.0296, Val Loss: 0.0279\n",
      "Epoch 4/100, Train Loss: 0.0256, Val Loss: 0.0230\n",
      "Epoch 5/100, Train Loss: 0.0205, Val Loss: 0.0175\n",
      "Epoch 6/100, Train Loss: 0.0151, Val Loss: 0.0121\n",
      "Epoch 7/100, Train Loss: 0.0104, Val Loss: 0.0079\n",
      "Epoch 8/100, Train Loss: 0.0070, Val Loss: 0.0054\n",
      "Epoch 9/100, Train Loss: 0.0059, Val Loss: 0.0063\n",
      "Epoch 10/100, Train Loss: 0.0076, Val Loss: 0.0076\n",
      "Epoch 11/100, Train Loss: 0.0089, Val Loss: 0.0077\n",
      "Epoch 12/100, Train Loss: 0.0087, Val Loss: 0.0068\n",
      "Epoch 13/100, Train Loss: 0.0075, Val Loss: 0.0054\n",
      "Epoch 14/100, Train Loss: 0.0060, Val Loss: 0.0045\n",
      "Epoch 15/100, Train Loss: 0.0052, Val Loss: 0.0042\n",
      "Epoch 16/100, Train Loss: 0.0047, Val Loss: 0.0040\n",
      "Epoch 17/100, Train Loss: 0.0041, Val Loss: 0.0045\n",
      "Epoch 18/100, Train Loss: 0.0041, Val Loss: 0.0048\n",
      "Epoch 19/100, Train Loss: 0.0042, Val Loss: 0.0047\n",
      "Epoch 20/100, Train Loss: 0.0040, Val Loss: 0.0039\n",
      "Epoch 21/100, Train Loss: 0.0034, Val Loss: 0.0031\n",
      "Epoch 22/100, Train Loss: 0.0029, Val Loss: 0.0027\n",
      "Epoch 23/100, Train Loss: 0.0028, Val Loss: 0.0024\n",
      "Epoch 24/100, Train Loss: 0.0027, Val Loss: 0.0023\n",
      "Epoch 25/100, Train Loss: 0.0026, Val Loss: 0.0022\n",
      "Epoch 26/100, Train Loss: 0.0023, Val Loss: 0.0020\n",
      "Epoch 27/100, Train Loss: 0.0020, Val Loss: 0.0019\n",
      "Epoch 28/100, Train Loss: 0.0018, Val Loss: 0.0019\n",
      "Epoch 29/100, Train Loss: 0.0018, Val Loss: 0.0019\n",
      "Epoch 30/100, Train Loss: 0.0017, Val Loss: 0.0017\n",
      "Epoch 31/100, Train Loss: 0.0016, Val Loss: 0.0015\n",
      "Epoch 32/100, Train Loss: 0.0015, Val Loss: 0.0013\n",
      "Epoch 33/100, Train Loss: 0.0014, Val Loss: 0.0012\n",
      "Epoch 34/100, Train Loss: 0.0012, Val Loss: 0.0011\n",
      "Epoch 35/100, Train Loss: 0.0012, Val Loss: 0.0012\n",
      "Epoch 36/100, Train Loss: 0.0011, Val Loss: 0.0010\n",
      "Epoch 37/100, Train Loss: 0.0010, Val Loss: 0.0010\n",
      "Epoch 38/100, Train Loss: 0.0009, Val Loss: 0.0010\n",
      "Epoch 39/100, Train Loss: 0.0009, Val Loss: 0.0009\n",
      "Epoch 40/100, Train Loss: 0.0009, Val Loss: 0.0009\n",
      "Epoch 41/100, Train Loss: 0.0008, Val Loss: 0.0009\n",
      "Epoch 42/100, Train Loss: 0.0008, Val Loss: 0.0009\n",
      "Epoch 43/100, Train Loss: 0.0007, Val Loss: 0.0009\n",
      "Epoch 44/100, Train Loss: 0.0007, Val Loss: 0.0008\n",
      "Epoch 45/100, Train Loss: 0.0007, Val Loss: 0.0008\n",
      "Epoch 46/100, Train Loss: 0.0007, Val Loss: 0.0007\n",
      "Epoch 47/100, Train Loss: 0.0007, Val Loss: 0.0008\n",
      "Epoch 48/100, Train Loss: 0.0006, Val Loss: 0.0008\n",
      "Epoch 49/100, Train Loss: 0.0006, Val Loss: 0.0007\n",
      "Epoch 50/100, Train Loss: 0.0006, Val Loss: 0.0008\n",
      "Epoch 51/100, Train Loss: 0.0006, Val Loss: 0.0006\n",
      "Epoch 52/100, Train Loss: 0.0006, Val Loss: 0.0006\n",
      "Epoch 53/100, Train Loss: 0.0006, Val Loss: 0.0007\n",
      "Epoch 54/100, Train Loss: 0.0006, Val Loss: 0.0006\n",
      "Epoch 55/100, Train Loss: 0.0005, Val Loss: 0.0007\n",
      "Epoch 56/100, Train Loss: 0.0005, Val Loss: 0.0007\n",
      "Epoch 57/100, Train Loss: 0.0006, Val Loss: 0.0006\n",
      "Epoch 58/100, Train Loss: 0.0006, Val Loss: 0.0005\n",
      "Epoch 59/100, Train Loss: 0.0005, Val Loss: 0.0005\n",
      "Epoch 60/100, Train Loss: 0.0005, Val Loss: 0.0007\n",
      "Epoch 61/100, Train Loss: 0.0005, Val Loss: 0.0006\n",
      "Epoch 62/100, Train Loss: 0.0005, Val Loss: 0.0005\n",
      "Epoch 63/100, Train Loss: 0.0005, Val Loss: 0.0005\n",
      "Epoch 64/100, Train Loss: 0.0004, Val Loss: 0.0005\n",
      "Epoch 65/100, Train Loss: 0.0004, Val Loss: 0.0005\n",
      "Epoch 66/100, Train Loss: 0.0004, Val Loss: 0.0005\n",
      "Epoch 67/100, Train Loss: 0.0004, Val Loss: 0.0005\n",
      "Epoch 68/100, Train Loss: 0.0004, Val Loss: 0.0005\n",
      "Epoch 69/100, Train Loss: 0.0004, Val Loss: 0.0005\n",
      "Epoch 70/100, Train Loss: 0.0004, Val Loss: 0.0005\n",
      "Epoch 71/100, Train Loss: 0.0004, Val Loss: 0.0005\n",
      "Epoch 72/100, Train Loss: 0.0004, Val Loss: 0.0004\n",
      "Epoch 73/100, Train Loss: 0.0004, Val Loss: 0.0004\n",
      "Epoch 74/100, Train Loss: 0.0004, Val Loss: 0.0004\n",
      "Epoch 75/100, Train Loss: 0.0004, Val Loss: 0.0004\n",
      "Epoch 76/100, Train Loss: 0.0004, Val Loss: 0.0004\n",
      "Epoch 77/100, Train Loss: 0.0004, Val Loss: 0.0004\n",
      "Epoch 78/100, Train Loss: 0.0004, Val Loss: 0.0004\n",
      "Epoch 79/100, Train Loss: 0.0004, Val Loss: 0.0004\n",
      "Epoch 80/100, Train Loss: 0.0004, Val Loss: 0.0004\n",
      "Epoch 81/100, Train Loss: 0.0003, Val Loss: 0.0004\n",
      "Epoch 82/100, Train Loss: 0.0003, Val Loss: 0.0004\n",
      "Epoch 83/100, Train Loss: 0.0003, Val Loss: 0.0004\n",
      "Epoch 84/100, Train Loss: 0.0003, Val Loss: 0.0004\n",
      "Epoch 85/100, Train Loss: 0.0003, Val Loss: 0.0003\n",
      "Epoch 86/100, Train Loss: 0.0003, Val Loss: 0.0004\n",
      "Epoch 87/100, Train Loss: 0.0003, Val Loss: 0.0004\n",
      "Epoch 88/100, Train Loss: 0.0003, Val Loss: 0.0004\n",
      "Epoch 89/100, Train Loss: 0.0003, Val Loss: 0.0003\n",
      "Epoch 90/100, Train Loss: 0.0003, Val Loss: 0.0004\n",
      "Epoch 91/100, Train Loss: 0.0003, Val Loss: 0.0004\n",
      "Epoch 92/100, Train Loss: 0.0003, Val Loss: 0.0004\n",
      "Epoch 93/100, Train Loss: 0.0003, Val Loss: 0.0003\n",
      "Epoch 94/100, Train Loss: 0.0003, Val Loss: 0.0003\n",
      "Epoch 95/100, Train Loss: 0.0003, Val Loss: 0.0003\n",
      "Epoch 96/100, Train Loss: 0.0003, Val Loss: 0.0004\n",
      "Epoch 97/100, Train Loss: 0.0003, Val Loss: 0.0004\n",
      "Epoch 98/100, Train Loss: 0.0003, Val Loss: 0.0004\n",
      "Epoch 99/100, Train Loss: 0.0003, Val Loss: 0.0003\n",
      "Epoch 100/100, Train Loss: 0.0003, Val Loss: 0.0003\n",
      "Best Validation Loss for 깐마늘(국산): 0.0003\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f3c6b630b544182b0bc5f71ce198117",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "테스트 파일 추론 중:   0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Train Loss: 0.0952, Val Loss: 0.0861\n",
      "Epoch 2/100, Train Loss: 0.0837, Val Loss: 0.0752\n",
      "Epoch 3/100, Train Loss: 0.0729, Val Loss: 0.0642\n",
      "Epoch 4/100, Train Loss: 0.0617, Val Loss: 0.0531\n",
      "Epoch 5/100, Train Loss: 0.0503, Val Loss: 0.0421\n",
      "Epoch 6/100, Train Loss: 0.0394, Val Loss: 0.0323\n",
      "Epoch 7/100, Train Loss: 0.0288, Val Loss: 0.0248\n",
      "Epoch 8/100, Train Loss: 0.0224, Val Loss: 0.0196\n",
      "Epoch 9/100, Train Loss: 0.0177, Val Loss: 0.0172\n",
      "Epoch 10/100, Train Loss: 0.0154, Val Loss: 0.0165\n",
      "Epoch 11/100, Train Loss: 0.0160, Val Loss: 0.0171\n",
      "Epoch 12/100, Train Loss: 0.0166, Val Loss: 0.0178\n",
      "Epoch 13/100, Train Loss: 0.0166, Val Loss: 0.0172\n",
      "Epoch 14/100, Train Loss: 0.0158, Val Loss: 0.0153\n",
      "Epoch 15/100, Train Loss: 0.0135, Val Loss: 0.0131\n",
      "Epoch 16/100, Train Loss: 0.0116, Val Loss: 0.0117\n",
      "Epoch 17/100, Train Loss: 0.0103, Val Loss: 0.0114\n",
      "Epoch 18/100, Train Loss: 0.0095, Val Loss: 0.0111\n",
      "Epoch 19/100, Train Loss: 0.0094, Val Loss: 0.0108\n",
      "Epoch 20/100, Train Loss: 0.0091, Val Loss: 0.0105\n",
      "Epoch 21/100, Train Loss: 0.0085, Val Loss: 0.0100\n",
      "Epoch 22/100, Train Loss: 0.0078, Val Loss: 0.0092\n",
      "Epoch 23/100, Train Loss: 0.0068, Val Loss: 0.0082\n",
      "Epoch 24/100, Train Loss: 0.0061, Val Loss: 0.0073\n",
      "Epoch 25/100, Train Loss: 0.0058, Val Loss: 0.0068\n",
      "Epoch 26/100, Train Loss: 0.0056, Val Loss: 0.0065\n",
      "Epoch 27/100, Train Loss: 0.0054, Val Loss: 0.0062\n",
      "Epoch 28/100, Train Loss: 0.0049, Val Loss: 0.0060\n",
      "Epoch 29/100, Train Loss: 0.0046, Val Loss: 0.0058\n",
      "Epoch 30/100, Train Loss: 0.0043, Val Loss: 0.0056\n",
      "Epoch 31/100, Train Loss: 0.0042, Val Loss: 0.0052\n",
      "Epoch 32/100, Train Loss: 0.0039, Val Loss: 0.0048\n",
      "Epoch 33/100, Train Loss: 0.0037, Val Loss: 0.0046\n",
      "Epoch 34/100, Train Loss: 0.0037, Val Loss: 0.0043\n",
      "Epoch 35/100, Train Loss: 0.0034, Val Loss: 0.0041\n",
      "Epoch 36/100, Train Loss: 0.0032, Val Loss: 0.0039\n",
      "Epoch 37/100, Train Loss: 0.0030, Val Loss: 0.0039\n",
      "Epoch 38/100, Train Loss: 0.0029, Val Loss: 0.0036\n",
      "Epoch 39/100, Train Loss: 0.0027, Val Loss: 0.0034\n",
      "Epoch 40/100, Train Loss: 0.0026, Val Loss: 0.0032\n",
      "Epoch 41/100, Train Loss: 0.0025, Val Loss: 0.0031\n",
      "Epoch 42/100, Train Loss: 0.0023, Val Loss: 0.0030\n",
      "Epoch 43/100, Train Loss: 0.0023, Val Loss: 0.0029\n",
      "Epoch 44/100, Train Loss: 0.0021, Val Loss: 0.0027\n",
      "Epoch 45/100, Train Loss: 0.0021, Val Loss: 0.0025\n",
      "Epoch 46/100, Train Loss: 0.0019, Val Loss: 0.0026\n",
      "Epoch 47/100, Train Loss: 0.0019, Val Loss: 0.0025\n",
      "Epoch 48/100, Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch 49/100, Train Loss: 0.0017, Val Loss: 0.0022\n",
      "Epoch 50/100, Train Loss: 0.0017, Val Loss: 0.0021\n",
      "Epoch 51/100, Train Loss: 0.0016, Val Loss: 0.0021\n",
      "Epoch 52/100, Train Loss: 0.0016, Val Loss: 0.0021\n",
      "Epoch 53/100, Train Loss: 0.0015, Val Loss: 0.0020\n",
      "Epoch 54/100, Train Loss: 0.0014, Val Loss: 0.0020\n",
      "Epoch 55/100, Train Loss: 0.0014, Val Loss: 0.0019\n",
      "Epoch 56/100, Train Loss: 0.0013, Val Loss: 0.0018\n",
      "Epoch 57/100, Train Loss: 0.0013, Val Loss: 0.0018\n",
      "Epoch 58/100, Train Loss: 0.0013, Val Loss: 0.0017\n",
      "Epoch 59/100, Train Loss: 0.0012, Val Loss: 0.0017\n",
      "Epoch 60/100, Train Loss: 0.0012, Val Loss: 0.0016\n",
      "Epoch 61/100, Train Loss: 0.0011, Val Loss: 0.0016\n",
      "Epoch 62/100, Train Loss: 0.0011, Val Loss: 0.0016\n",
      "Epoch 63/100, Train Loss: 0.0010, Val Loss: 0.0015\n",
      "Epoch 64/100, Train Loss: 0.0010, Val Loss: 0.0014\n",
      "Epoch 65/100, Train Loss: 0.0010, Val Loss: 0.0014\n",
      "Epoch 66/100, Train Loss: 0.0010, Val Loss: 0.0014\n",
      "Epoch 67/100, Train Loss: 0.0009, Val Loss: 0.0013\n",
      "Epoch 68/100, Train Loss: 0.0009, Val Loss: 0.0014\n",
      "Epoch 69/100, Train Loss: 0.0010, Val Loss: 0.0012\n",
      "Epoch 70/100, Train Loss: 0.0009, Val Loss: 0.0012\n",
      "Epoch 71/100, Train Loss: 0.0009, Val Loss: 0.0012\n",
      "Epoch 72/100, Train Loss: 0.0008, Val Loss: 0.0011\n",
      "Epoch 73/100, Train Loss: 0.0008, Val Loss: 0.0012\n",
      "Epoch 74/100, Train Loss: 0.0008, Val Loss: 0.0011\n",
      "Epoch 75/100, Train Loss: 0.0008, Val Loss: 0.0011\n",
      "Epoch 76/100, Train Loss: 0.0008, Val Loss: 0.0010\n",
      "Epoch 77/100, Train Loss: 0.0007, Val Loss: 0.0010\n",
      "Epoch 78/100, Train Loss: 0.0007, Val Loss: 0.0009\n",
      "Epoch 79/100, Train Loss: 0.0007, Val Loss: 0.0009\n",
      "Epoch 80/100, Train Loss: 0.0007, Val Loss: 0.0010\n",
      "Epoch 81/100, Train Loss: 0.0007, Val Loss: 0.0009\n",
      "Epoch 82/100, Train Loss: 0.0006, Val Loss: 0.0009\n",
      "Epoch 83/100, Train Loss: 0.0006, Val Loss: 0.0008\n",
      "Epoch 84/100, Train Loss: 0.0006, Val Loss: 0.0008\n",
      "Epoch 85/100, Train Loss: 0.0006, Val Loss: 0.0008\n",
      "Epoch 86/100, Train Loss: 0.0006, Val Loss: 0.0008\n",
      "Epoch 87/100, Train Loss: 0.0006, Val Loss: 0.0008\n",
      "Epoch 88/100, Train Loss: 0.0006, Val Loss: 0.0008\n",
      "Epoch 89/100, Train Loss: 0.0006, Val Loss: 0.0008\n",
      "Epoch 90/100, Train Loss: 0.0006, Val Loss: 0.0008\n",
      "Epoch 91/100, Train Loss: 0.0007, Val Loss: 0.0009\n",
      "Epoch 92/100, Train Loss: 0.0007, Val Loss: 0.0008\n",
      "Epoch 93/100, Train Loss: 0.0006, Val Loss: 0.0008\n",
      "Epoch 94/100, Train Loss: 0.0006, Val Loss: 0.0008\n",
      "Epoch 95/100, Train Loss: 0.0006, Val Loss: 0.0008\n",
      "Epoch 96/100, Train Loss: 0.0006, Val Loss: 0.0008\n",
      "Epoch 97/100, Train Loss: 0.0005, Val Loss: 0.0007\n",
      "Epoch 98/100, Train Loss: 0.0005, Val Loss: 0.0008\n",
      "Epoch 99/100, Train Loss: 0.0005, Val Loss: 0.0007\n",
      "Epoch 100/100, Train Loss: 0.0005, Val Loss: 0.0008\n",
      "Best Validation Loss for 무: 0.0007\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4de41e975354494b1c0d7b257a40e90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "테스트 파일 추론 중:   0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Train Loss: 0.2995, Val Loss: 0.3282\n",
      "Epoch 2/100, Train Loss: 0.2967, Val Loss: 0.3217\n",
      "Epoch 3/100, Train Loss: 0.2919, Val Loss: 0.3154\n",
      "Epoch 4/100, Train Loss: 0.2904, Val Loss: 0.3091\n",
      "Epoch 5/100, Train Loss: 0.2751, Val Loss: 0.3030\n",
      "Epoch 6/100, Train Loss: 0.2740, Val Loss: 0.2971\n",
      "Epoch 7/100, Train Loss: 0.2636, Val Loss: 0.2911\n",
      "Epoch 8/100, Train Loss: 0.2572, Val Loss: 0.2850\n",
      "Epoch 9/100, Train Loss: 0.2554, Val Loss: 0.2789\n",
      "Epoch 10/100, Train Loss: 0.2486, Val Loss: 0.2724\n",
      "Epoch 11/100, Train Loss: 0.2390, Val Loss: 0.2658\n",
      "Epoch 12/100, Train Loss: 0.2326, Val Loss: 0.2588\n",
      "Epoch 13/100, Train Loss: 0.2373, Val Loss: 0.2514\n",
      "Epoch 14/100, Train Loss: 0.2210, Val Loss: 0.2445\n",
      "Epoch 15/100, Train Loss: 0.2163, Val Loss: 0.2378\n",
      "Epoch 16/100, Train Loss: 0.2059, Val Loss: 0.2325\n",
      "Epoch 17/100, Train Loss: 0.2095, Val Loss: 0.2272\n",
      "Epoch 18/100, Train Loss: 0.2040, Val Loss: 0.2217\n",
      "Epoch 19/100, Train Loss: 0.1968, Val Loss: 0.2170\n",
      "Epoch 20/100, Train Loss: 0.1960, Val Loss: 0.2125\n",
      "Epoch 21/100, Train Loss: 0.1960, Val Loss: 0.2082\n",
      "Epoch 22/100, Train Loss: 0.1940, Val Loss: 0.2057\n",
      "Epoch 23/100, Train Loss: 0.1934, Val Loss: 0.2041\n",
      "Epoch 24/100, Train Loss: 0.1898, Val Loss: 0.2032\n",
      "Epoch 25/100, Train Loss: 0.1894, Val Loss: 0.2029\n",
      "Epoch 26/100, Train Loss: 0.1893, Val Loss: 0.2029\n",
      "Epoch 27/100, Train Loss: 0.1979, Val Loss: 0.2031\n",
      "Epoch 28/100, Train Loss: 0.1888, Val Loss: 0.2033\n",
      "Epoch 29/100, Train Loss: 0.1950, Val Loss: 0.2036\n",
      "Epoch 30/100, Train Loss: 0.1909, Val Loss: 0.2040\n",
      "Epoch 31/100, Train Loss: 0.1828, Val Loss: 0.2042\n",
      "Epoch 32/100, Train Loss: 0.1875, Val Loss: 0.2045\n",
      "Epoch 33/100, Train Loss: 0.1838, Val Loss: 0.2046\n",
      "Epoch 34/100, Train Loss: 0.1823, Val Loss: 0.2047\n",
      "Epoch 35/100, Train Loss: 0.1814, Val Loss: 0.2047\n",
      "Epoch 36/100, Train Loss: 0.1826, Val Loss: 0.2047\n",
      "Epoch 37/100, Train Loss: 0.1867, Val Loss: 0.2046\n",
      "Epoch 38/100, Train Loss: 0.1840, Val Loss: 0.2045\n",
      "Epoch 39/100, Train Loss: 0.1856, Val Loss: 0.2042\n",
      "Epoch 40/100, Train Loss: 0.1876, Val Loss: 0.2039\n",
      "Epoch 41/100, Train Loss: 0.1786, Val Loss: 0.2036\n",
      "Epoch 42/100, Train Loss: 0.1743, Val Loss: 0.2033\n",
      "Epoch 43/100, Train Loss: 0.1720, Val Loss: 0.2029\n",
      "Epoch 44/100, Train Loss: 0.1740, Val Loss: 0.2027\n",
      "Epoch 45/100, Train Loss: 0.1799, Val Loss: 0.2025\n",
      "Epoch 46/100, Train Loss: 0.1804, Val Loss: 0.2023\n",
      "Epoch 47/100, Train Loss: 0.1762, Val Loss: 0.2020\n",
      "Epoch 48/100, Train Loss: 0.1788, Val Loss: 0.2017\n",
      "Epoch 49/100, Train Loss: 0.1719, Val Loss: 0.2014\n",
      "Epoch 50/100, Train Loss: 0.1789, Val Loss: 0.2012\n",
      "Epoch 51/100, Train Loss: 0.1706, Val Loss: 0.2010\n",
      "Epoch 52/100, Train Loss: 0.1708, Val Loss: 0.2008\n",
      "Epoch 53/100, Train Loss: 0.1717, Val Loss: 0.2007\n",
      "Epoch 54/100, Train Loss: 0.1700, Val Loss: 0.2006\n",
      "Epoch 55/100, Train Loss: 0.1741, Val Loss: 0.2004\n",
      "Epoch 56/100, Train Loss: 0.1694, Val Loss: 0.2002\n",
      "Epoch 57/100, Train Loss: 0.1690, Val Loss: 0.1999\n",
      "Epoch 58/100, Train Loss: 0.1629, Val Loss: 0.1995\n",
      "Epoch 59/100, Train Loss: 0.1694, Val Loss: 0.1991\n",
      "Epoch 60/100, Train Loss: 0.1714, Val Loss: 0.1985\n",
      "Epoch 61/100, Train Loss: 0.1664, Val Loss: 0.1978\n",
      "Epoch 62/100, Train Loss: 0.1605, Val Loss: 0.1970\n",
      "Epoch 63/100, Train Loss: 0.1633, Val Loss: 0.1961\n",
      "Epoch 64/100, Train Loss: 0.1618, Val Loss: 0.1953\n",
      "Epoch 65/100, Train Loss: 0.1593, Val Loss: 0.1945\n",
      "Epoch 66/100, Train Loss: 0.1607, Val Loss: 0.1938\n",
      "Epoch 67/100, Train Loss: 0.1651, Val Loss: 0.1931\n",
      "Epoch 68/100, Train Loss: 0.1649, Val Loss: 0.1923\n",
      "Epoch 69/100, Train Loss: 0.1586, Val Loss: 0.1915\n",
      "Epoch 70/100, Train Loss: 0.1559, Val Loss: 0.1906\n",
      "Epoch 71/100, Train Loss: 0.1513, Val Loss: 0.1898\n",
      "Epoch 72/100, Train Loss: 0.1549, Val Loss: 0.1887\n",
      "Epoch 73/100, Train Loss: 0.1502, Val Loss: 0.1875\n",
      "Epoch 74/100, Train Loss: 0.1523, Val Loss: 0.1864\n",
      "Epoch 75/100, Train Loss: 0.1482, Val Loss: 0.1852\n",
      "Epoch 76/100, Train Loss: 0.1473, Val Loss: 0.1839\n",
      "Epoch 77/100, Train Loss: 0.1486, Val Loss: 0.1826\n",
      "Epoch 78/100, Train Loss: 0.1494, Val Loss: 0.1814\n",
      "Epoch 79/100, Train Loss: 0.1482, Val Loss: 0.1803\n",
      "Epoch 80/100, Train Loss: 0.1425, Val Loss: 0.1796\n",
      "Epoch 81/100, Train Loss: 0.1392, Val Loss: 0.1787\n",
      "Epoch 82/100, Train Loss: 0.1410, Val Loss: 0.1771\n",
      "Epoch 83/100, Train Loss: 0.1411, Val Loss: 0.1742\n",
      "Epoch 84/100, Train Loss: 0.1387, Val Loss: 0.1718\n",
      "Epoch 85/100, Train Loss: 0.1341, Val Loss: 0.1697\n",
      "Epoch 86/100, Train Loss: 0.1352, Val Loss: 0.1677\n",
      "Epoch 87/100, Train Loss: 0.1334, Val Loss: 0.1658\n",
      "Epoch 88/100, Train Loss: 0.1277, Val Loss: 0.1648\n",
      "Epoch 89/100, Train Loss: 0.1298, Val Loss: 0.1633\n",
      "Epoch 90/100, Train Loss: 0.1258, Val Loss: 0.1609\n",
      "Epoch 91/100, Train Loss: 0.1219, Val Loss: 0.1593\n",
      "Epoch 92/100, Train Loss: 0.1211, Val Loss: 0.1586\n",
      "Epoch 93/100, Train Loss: 0.1209, Val Loss: 0.1587\n",
      "Epoch 94/100, Train Loss: 0.1225, Val Loss: 0.1591\n",
      "Epoch 95/100, Train Loss: 0.1194, Val Loss: 0.1572\n",
      "Epoch 96/100, Train Loss: 0.1205, Val Loss: 0.1538\n",
      "Epoch 97/100, Train Loss: 0.1144, Val Loss: 0.1518\n",
      "Epoch 98/100, Train Loss: 0.1149, Val Loss: 0.1519\n",
      "Epoch 99/100, Train Loss: 0.1164, Val Loss: 0.1524\n",
      "Epoch 100/100, Train Loss: 0.1131, Val Loss: 0.1524\n",
      "Best Validation Loss for 상추: 0.1518\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ce895a555414c16a1aa227bbfcbe094",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "테스트 파일 추론 중:   0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Train Loss: 0.2522, Val Loss: 0.2293\n",
      "Epoch 2/100, Train Loss: 0.2370, Val Loss: 0.2183\n",
      "Epoch 3/100, Train Loss: 0.2355, Val Loss: 0.2083\n",
      "Epoch 4/100, Train Loss: 0.2205, Val Loss: 0.1984\n",
      "Epoch 5/100, Train Loss: 0.2146, Val Loss: 0.1882\n",
      "Epoch 6/100, Train Loss: 0.1996, Val Loss: 0.1781\n",
      "Epoch 7/100, Train Loss: 0.1905, Val Loss: 0.1680\n",
      "Epoch 8/100, Train Loss: 0.1736, Val Loss: 0.1590\n",
      "Epoch 9/100, Train Loss: 0.1709, Val Loss: 0.1521\n",
      "Epoch 10/100, Train Loss: 0.1552, Val Loss: 0.1467\n",
      "Epoch 11/100, Train Loss: 0.1557, Val Loss: 0.1421\n",
      "Epoch 12/100, Train Loss: 0.1513, Val Loss: 0.1385\n",
      "Epoch 13/100, Train Loss: 0.1492, Val Loss: 0.1358\n",
      "Epoch 14/100, Train Loss: 0.1431, Val Loss: 0.1342\n",
      "Epoch 15/100, Train Loss: 0.1453, Val Loss: 0.1331\n",
      "Epoch 16/100, Train Loss: 0.1508, Val Loss: 0.1323\n",
      "Epoch 17/100, Train Loss: 0.1504, Val Loss: 0.1321\n",
      "Epoch 18/100, Train Loss: 0.1497, Val Loss: 0.1321\n",
      "Epoch 19/100, Train Loss: 0.1476, Val Loss: 0.1321\n",
      "Epoch 20/100, Train Loss: 0.1476, Val Loss: 0.1321\n",
      "Epoch 21/100, Train Loss: 0.1477, Val Loss: 0.1323\n",
      "Epoch 22/100, Train Loss: 0.1467, Val Loss: 0.1323\n",
      "Epoch 23/100, Train Loss: 0.1428, Val Loss: 0.1321\n",
      "Epoch 24/100, Train Loss: 0.1435, Val Loss: 0.1317\n",
      "Epoch 25/100, Train Loss: 0.1438, Val Loss: 0.1312\n",
      "Epoch 26/100, Train Loss: 0.1383, Val Loss: 0.1308\n",
      "Epoch 27/100, Train Loss: 0.1394, Val Loss: 0.1303\n",
      "Epoch 28/100, Train Loss: 0.1403, Val Loss: 0.1297\n",
      "Epoch 29/100, Train Loss: 0.1351, Val Loss: 0.1291\n",
      "Epoch 30/100, Train Loss: 0.1383, Val Loss: 0.1286\n",
      "Epoch 31/100, Train Loss: 0.1426, Val Loss: 0.1279\n",
      "Epoch 32/100, Train Loss: 0.1314, Val Loss: 0.1272\n",
      "Epoch 33/100, Train Loss: 0.1325, Val Loss: 0.1267\n",
      "Epoch 34/100, Train Loss: 0.1423, Val Loss: 0.1263\n",
      "Epoch 35/100, Train Loss: 0.1339, Val Loss: 0.1257\n",
      "Epoch 36/100, Train Loss: 0.1301, Val Loss: 0.1251\n",
      "Epoch 37/100, Train Loss: 0.1385, Val Loss: 0.1245\n",
      "Epoch 38/100, Train Loss: 0.1306, Val Loss: 0.1237\n",
      "Epoch 39/100, Train Loss: 0.1333, Val Loss: 0.1229\n",
      "Epoch 40/100, Train Loss: 0.1329, Val Loss: 0.1222\n",
      "Epoch 41/100, Train Loss: 0.1270, Val Loss: 0.1215\n",
      "Epoch 42/100, Train Loss: 0.1291, Val Loss: 0.1208\n",
      "Epoch 43/100, Train Loss: 0.1325, Val Loss: 0.1201\n",
      "Epoch 44/100, Train Loss: 0.1277, Val Loss: 0.1194\n",
      "Epoch 45/100, Train Loss: 0.1269, Val Loss: 0.1188\n",
      "Epoch 46/100, Train Loss: 0.1232, Val Loss: 0.1182\n",
      "Epoch 47/100, Train Loss: 0.1248, Val Loss: 0.1174\n",
      "Epoch 48/100, Train Loss: 0.1208, Val Loss: 0.1164\n",
      "Epoch 49/100, Train Loss: 0.1228, Val Loss: 0.1154\n",
      "Epoch 50/100, Train Loss: 0.1191, Val Loss: 0.1143\n",
      "Epoch 51/100, Train Loss: 0.1195, Val Loss: 0.1132\n",
      "Epoch 52/100, Train Loss: 0.1140, Val Loss: 0.1121\n",
      "Epoch 53/100, Train Loss: 0.1124, Val Loss: 0.1109\n",
      "Epoch 54/100, Train Loss: 0.1179, Val Loss: 0.1099\n",
      "Epoch 55/100, Train Loss: 0.1134, Val Loss: 0.1088\n",
      "Epoch 56/100, Train Loss: 0.1077, Val Loss: 0.1076\n",
      "Epoch 57/100, Train Loss: 0.1076, Val Loss: 0.1063\n",
      "Epoch 58/100, Train Loss: 0.1073, Val Loss: 0.1052\n",
      "Epoch 59/100, Train Loss: 0.1067, Val Loss: 0.1041\n",
      "Epoch 60/100, Train Loss: 0.1056, Val Loss: 0.1030\n",
      "Epoch 61/100, Train Loss: 0.1055, Val Loss: 0.1015\n",
      "Epoch 62/100, Train Loss: 0.1021, Val Loss: 0.0996\n",
      "Epoch 63/100, Train Loss: 0.0973, Val Loss: 0.0976\n",
      "Epoch 64/100, Train Loss: 0.0968, Val Loss: 0.0955\n",
      "Epoch 65/100, Train Loss: 0.0971, Val Loss: 0.0932\n",
      "Epoch 66/100, Train Loss: 0.0929, Val Loss: 0.0915\n",
      "Epoch 67/100, Train Loss: 0.0929, Val Loss: 0.0890\n",
      "Epoch 68/100, Train Loss: 0.0890, Val Loss: 0.0870\n",
      "Epoch 69/100, Train Loss: 0.0853, Val Loss: 0.0843\n",
      "Epoch 70/100, Train Loss: 0.0847, Val Loss: 0.0815\n",
      "Epoch 71/100, Train Loss: 0.0817, Val Loss: 0.0795\n",
      "Epoch 72/100, Train Loss: 0.0778, Val Loss: 0.0779\n",
      "Epoch 73/100, Train Loss: 0.0774, Val Loss: 0.0763\n",
      "Epoch 74/100, Train Loss: 0.0755, Val Loss: 0.0756\n",
      "Epoch 75/100, Train Loss: 0.0748, Val Loss: 0.0756\n",
      "Epoch 76/100, Train Loss: 0.0726, Val Loss: 0.0736\n",
      "Epoch 77/100, Train Loss: 0.0700, Val Loss: 0.0709\n",
      "Epoch 78/100, Train Loss: 0.0702, Val Loss: 0.0673\n",
      "Epoch 79/100, Train Loss: 0.0679, Val Loss: 0.0682\n",
      "Epoch 80/100, Train Loss: 0.0654, Val Loss: 0.0707\n",
      "Epoch 81/100, Train Loss: 0.0656, Val Loss: 0.0663\n",
      "Epoch 82/100, Train Loss: 0.0622, Val Loss: 0.0657\n",
      "Epoch 83/100, Train Loss: 0.0599, Val Loss: 0.0657\n",
      "Epoch 84/100, Train Loss: 0.0576, Val Loss: 0.0622\n",
      "Epoch 85/100, Train Loss: 0.0566, Val Loss: 0.0622\n",
      "Epoch 86/100, Train Loss: 0.0543, Val Loss: 0.0604\n",
      "Epoch 87/100, Train Loss: 0.0547, Val Loss: 0.0601\n",
      "Epoch 88/100, Train Loss: 0.0526, Val Loss: 0.0602\n",
      "Epoch 89/100, Train Loss: 0.0539, Val Loss: 0.0596\n",
      "Epoch 90/100, Train Loss: 0.0495, Val Loss: 0.0588\n",
      "Epoch 91/100, Train Loss: 0.0495, Val Loss: 0.0572\n",
      "Epoch 92/100, Train Loss: 0.0474, Val Loss: 0.0569\n",
      "Epoch 93/100, Train Loss: 0.0491, Val Loss: 0.0564\n",
      "Epoch 94/100, Train Loss: 0.0473, Val Loss: 0.0563\n",
      "Epoch 95/100, Train Loss: 0.0451, Val Loss: 0.0552\n",
      "Epoch 96/100, Train Loss: 0.0463, Val Loss: 0.0543\n",
      "Epoch 97/100, Train Loss: 0.0454, Val Loss: 0.0539\n",
      "Epoch 98/100, Train Loss: 0.0458, Val Loss: 0.0541\n",
      "Epoch 99/100, Train Loss: 0.0463, Val Loss: 0.0544\n",
      "Epoch 100/100, Train Loss: 0.0454, Val Loss: 0.0516\n",
      "Best Validation Loss for 배추: 0.0516\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8791339b6eab48429ad737b2053a11a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "테스트 파일 추론 중:   0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Train Loss: 0.5740, Val Loss: 0.5631\n",
      "Epoch 2/100, Train Loss: 0.5505, Val Loss: 0.5527\n",
      "Epoch 3/100, Train Loss: 0.5460, Val Loss: 0.5421\n",
      "Epoch 4/100, Train Loss: 0.5332, Val Loss: 0.5312\n",
      "Epoch 5/100, Train Loss: 0.5242, Val Loss: 0.5200\n",
      "Epoch 6/100, Train Loss: 0.5134, Val Loss: 0.5083\n",
      "Epoch 7/100, Train Loss: 0.4944, Val Loss: 0.4959\n",
      "Epoch 8/100, Train Loss: 0.4908, Val Loss: 0.4829\n",
      "Epoch 9/100, Train Loss: 0.4719, Val Loss: 0.4691\n",
      "Epoch 10/100, Train Loss: 0.4566, Val Loss: 0.4542\n",
      "Epoch 11/100, Train Loss: 0.4435, Val Loss: 0.4378\n",
      "Epoch 12/100, Train Loss: 0.4287, Val Loss: 0.4201\n",
      "Epoch 13/100, Train Loss: 0.4086, Val Loss: 0.4006\n",
      "Epoch 14/100, Train Loss: 0.3843, Val Loss: 0.3798\n",
      "Epoch 15/100, Train Loss: 0.3659, Val Loss: 0.3572\n",
      "Epoch 16/100, Train Loss: 0.3474, Val Loss: 0.3324\n",
      "Epoch 17/100, Train Loss: 0.3153, Val Loss: 0.3067\n",
      "Epoch 18/100, Train Loss: 0.2930, Val Loss: 0.2818\n",
      "Epoch 19/100, Train Loss: 0.2646, Val Loss: 0.2572\n",
      "Epoch 20/100, Train Loss: 0.2348, Val Loss: 0.2323\n",
      "Epoch 21/100, Train Loss: 0.2193, Val Loss: 0.2120\n",
      "Epoch 22/100, Train Loss: 0.1972, Val Loss: 0.1948\n",
      "Epoch 23/100, Train Loss: 0.1946, Val Loss: 0.1809\n",
      "Epoch 24/100, Train Loss: 0.1816, Val Loss: 0.1727\n",
      "Epoch 25/100, Train Loss: 0.1845, Val Loss: 0.1668\n",
      "Epoch 26/100, Train Loss: 0.1763, Val Loss: 0.1625\n",
      "Epoch 27/100, Train Loss: 0.1745, Val Loss: 0.1591\n",
      "Epoch 28/100, Train Loss: 0.1659, Val Loss: 0.1572\n",
      "Epoch 29/100, Train Loss: 0.1600, Val Loss: 0.1560\n",
      "Epoch 30/100, Train Loss: 0.1571, Val Loss: 0.1550\n",
      "Epoch 31/100, Train Loss: 0.1573, Val Loss: 0.1549\n",
      "Epoch 32/100, Train Loss: 0.1576, Val Loss: 0.1542\n",
      "Epoch 33/100, Train Loss: 0.1490, Val Loss: 0.1529\n",
      "Epoch 34/100, Train Loss: 0.1483, Val Loss: 0.1509\n",
      "Epoch 35/100, Train Loss: 0.1469, Val Loss: 0.1483\n",
      "Epoch 36/100, Train Loss: 0.1461, Val Loss: 0.1461\n",
      "Epoch 37/100, Train Loss: 0.1404, Val Loss: 0.1443\n",
      "Epoch 38/100, Train Loss: 0.1401, Val Loss: 0.1428\n",
      "Epoch 39/100, Train Loss: 0.1371, Val Loss: 0.1413\n",
      "Epoch 40/100, Train Loss: 0.1416, Val Loss: 0.1396\n",
      "Epoch 41/100, Train Loss: 0.1374, Val Loss: 0.1376\n",
      "Epoch 42/100, Train Loss: 0.1354, Val Loss: 0.1356\n",
      "Epoch 43/100, Train Loss: 0.1363, Val Loss: 0.1340\n",
      "Epoch 44/100, Train Loss: 0.1341, Val Loss: 0.1327\n",
      "Epoch 45/100, Train Loss: 0.1328, Val Loss: 0.1316\n",
      "Epoch 46/100, Train Loss: 0.1287, Val Loss: 0.1305\n",
      "Epoch 47/100, Train Loss: 0.1339, Val Loss: 0.1295\n",
      "Epoch 48/100, Train Loss: 0.1284, Val Loss: 0.1284\n",
      "Epoch 49/100, Train Loss: 0.1264, Val Loss: 0.1271\n",
      "Epoch 50/100, Train Loss: 0.1304, Val Loss: 0.1254\n",
      "Epoch 51/100, Train Loss: 0.1258, Val Loss: 0.1236\n",
      "Epoch 52/100, Train Loss: 0.1227, Val Loss: 0.1216\n",
      "Epoch 53/100, Train Loss: 0.1219, Val Loss: 0.1196\n",
      "Epoch 54/100, Train Loss: 0.1184, Val Loss: 0.1177\n",
      "Epoch 55/100, Train Loss: 0.1215, Val Loss: 0.1160\n",
      "Epoch 56/100, Train Loss: 0.1206, Val Loss: 0.1145\n",
      "Epoch 57/100, Train Loss: 0.1195, Val Loss: 0.1129\n",
      "Epoch 58/100, Train Loss: 0.1149, Val Loss: 0.1112\n",
      "Epoch 59/100, Train Loss: 0.1123, Val Loss: 0.1095\n",
      "Epoch 60/100, Train Loss: 0.1128, Val Loss: 0.1074\n",
      "Epoch 61/100, Train Loss: 0.1127, Val Loss: 0.1056\n",
      "Epoch 62/100, Train Loss: 0.1092, Val Loss: 0.1040\n",
      "Epoch 63/100, Train Loss: 0.1086, Val Loss: 0.1027\n",
      "Epoch 64/100, Train Loss: 0.1045, Val Loss: 0.1009\n",
      "Epoch 65/100, Train Loss: 0.1036, Val Loss: 0.0989\n",
      "Epoch 66/100, Train Loss: 0.1002, Val Loss: 0.0973\n",
      "Epoch 67/100, Train Loss: 0.0988, Val Loss: 0.0956\n",
      "Epoch 68/100, Train Loss: 0.0981, Val Loss: 0.0939\n",
      "Epoch 69/100, Train Loss: 0.0925, Val Loss: 0.0925\n",
      "Epoch 70/100, Train Loss: 0.0911, Val Loss: 0.0901\n",
      "Epoch 71/100, Train Loss: 0.0894, Val Loss: 0.0878\n",
      "Epoch 72/100, Train Loss: 0.0878, Val Loss: 0.0856\n",
      "Epoch 73/100, Train Loss: 0.0814, Val Loss: 0.0835\n",
      "Epoch 74/100, Train Loss: 0.0812, Val Loss: 0.0810\n",
      "Epoch 75/100, Train Loss: 0.0758, Val Loss: 0.0787\n",
      "Epoch 76/100, Train Loss: 0.0762, Val Loss: 0.0778\n",
      "Epoch 77/100, Train Loss: 0.0761, Val Loss: 0.0784\n",
      "Epoch 78/100, Train Loss: 0.0710, Val Loss: 0.0761\n",
      "Epoch 79/100, Train Loss: 0.0698, Val Loss: 0.0743\n",
      "Epoch 80/100, Train Loss: 0.0698, Val Loss: 0.0739\n",
      "Epoch 81/100, Train Loss: 0.0710, Val Loss: 0.0735\n",
      "Epoch 82/100, Train Loss: 0.0713, Val Loss: 0.0739\n",
      "Epoch 83/100, Train Loss: 0.0691, Val Loss: 0.0722\n",
      "Epoch 84/100, Train Loss: 0.0679, Val Loss: 0.0723\n",
      "Epoch 85/100, Train Loss: 0.0675, Val Loss: 0.0736\n",
      "Epoch 86/100, Train Loss: 0.0662, Val Loss: 0.0728\n",
      "Epoch 87/100, Train Loss: 0.0661, Val Loss: 0.0724\n",
      "Epoch 88/100, Train Loss: 0.0689, Val Loss: 0.0727\n",
      "Epoch 89/100, Train Loss: 0.0666, Val Loss: 0.0733\n",
      "Epoch 90/100, Train Loss: 0.0639, Val Loss: 0.0727\n",
      "Epoch 91/100, Train Loss: 0.0666, Val Loss: 0.0711\n",
      "Epoch 92/100, Train Loss: 0.0649, Val Loss: 0.0713\n",
      "Epoch 93/100, Train Loss: 0.0656, Val Loss: 0.0727\n",
      "Epoch 94/100, Train Loss: 0.0678, Val Loss: 0.0717\n",
      "Epoch 95/100, Train Loss: 0.0632, Val Loss: 0.0709\n",
      "Epoch 96/100, Train Loss: 0.0633, Val Loss: 0.0706\n",
      "Epoch 97/100, Train Loss: 0.0643, Val Loss: 0.0706\n",
      "Epoch 98/100, Train Loss: 0.0642, Val Loss: 0.0709\n",
      "Epoch 99/100, Train Loss: 0.0636, Val Loss: 0.0698\n",
      "Epoch 100/100, Train Loss: 0.0630, Val Loss: 0.0693\n",
      "Best Validation Loss for 양파: 0.0693\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf601971a8674817ae123775aacde256",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "테스트 파일 추론 중:   0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Train Loss: 0.3845, Val Loss: 0.3294\n",
      "Epoch 2/100, Train Loss: 0.3725, Val Loss: 0.3181\n",
      "Epoch 3/100, Train Loss: 0.3667, Val Loss: 0.3070\n",
      "Epoch 4/100, Train Loss: 0.3550, Val Loss: 0.2955\n",
      "Epoch 5/100, Train Loss: 0.3357, Val Loss: 0.2834\n",
      "Epoch 6/100, Train Loss: 0.3225, Val Loss: 0.2710\n",
      "Epoch 7/100, Train Loss: 0.3146, Val Loss: 0.2583\n",
      "Epoch 8/100, Train Loss: 0.3004, Val Loss: 0.2454\n",
      "Epoch 9/100, Train Loss: 0.2882, Val Loss: 0.2322\n",
      "Epoch 10/100, Train Loss: 0.2671, Val Loss: 0.2185\n",
      "Epoch 11/100, Train Loss: 0.2535, Val Loss: 0.2060\n",
      "Epoch 12/100, Train Loss: 0.2402, Val Loss: 0.1941\n",
      "Epoch 13/100, Train Loss: 0.2184, Val Loss: 0.1823\n",
      "Epoch 14/100, Train Loss: 0.2054, Val Loss: 0.1703\n",
      "Epoch 15/100, Train Loss: 0.1911, Val Loss: 0.1612\n",
      "Epoch 16/100, Train Loss: 0.1746, Val Loss: 0.1533\n",
      "Epoch 17/100, Train Loss: 0.1586, Val Loss: 0.1484\n",
      "Epoch 18/100, Train Loss: 0.1510, Val Loss: 0.1478\n",
      "Epoch 19/100, Train Loss: 0.1440, Val Loss: 0.1498\n",
      "Epoch 20/100, Train Loss: 0.1399, Val Loss: 0.1553\n",
      "Epoch 21/100, Train Loss: 0.1456, Val Loss: 0.1614\n",
      "Epoch 22/100, Train Loss: 0.1441, Val Loss: 0.1640\n",
      "Epoch 23/100, Train Loss: 0.1460, Val Loss: 0.1624\n",
      "Epoch 24/100, Train Loss: 0.1417, Val Loss: 0.1589\n",
      "Epoch 25/100, Train Loss: 0.1399, Val Loss: 0.1543\n",
      "Epoch 26/100, Train Loss: 0.1358, Val Loss: 0.1502\n",
      "Epoch 27/100, Train Loss: 0.1387, Val Loss: 0.1464\n",
      "Epoch 28/100, Train Loss: 0.1355, Val Loss: 0.1438\n",
      "Epoch 29/100, Train Loss: 0.1343, Val Loss: 0.1423\n",
      "Epoch 30/100, Train Loss: 0.1335, Val Loss: 0.1411\n",
      "Epoch 31/100, Train Loss: 0.1324, Val Loss: 0.1403\n",
      "Epoch 32/100, Train Loss: 0.1308, Val Loss: 0.1399\n",
      "Epoch 33/100, Train Loss: 0.1296, Val Loss: 0.1401\n",
      "Epoch 34/100, Train Loss: 0.1277, Val Loss: 0.1404\n",
      "Epoch 35/100, Train Loss: 0.1275, Val Loss: 0.1411\n",
      "Epoch 36/100, Train Loss: 0.1289, Val Loss: 0.1420\n",
      "Epoch 37/100, Train Loss: 0.1229, Val Loss: 0.1427\n",
      "Epoch 38/100, Train Loss: 0.1215, Val Loss: 0.1426\n",
      "Epoch 39/100, Train Loss: 0.1241, Val Loss: 0.1412\n",
      "Epoch 40/100, Train Loss: 0.1226, Val Loss: 0.1397\n",
      "Epoch 41/100, Train Loss: 0.1218, Val Loss: 0.1382\n",
      "Epoch 42/100, Train Loss: 0.1201, Val Loss: 0.1368\n",
      "Epoch 43/100, Train Loss: 0.1199, Val Loss: 0.1355\n",
      "Epoch 44/100, Train Loss: 0.1184, Val Loss: 0.1343\n",
      "Epoch 45/100, Train Loss: 0.1159, Val Loss: 0.1336\n",
      "Epoch 46/100, Train Loss: 0.1172, Val Loss: 0.1330\n",
      "Epoch 47/100, Train Loss: 0.1147, Val Loss: 0.1330\n",
      "Epoch 48/100, Train Loss: 0.1149, Val Loss: 0.1332\n",
      "Epoch 49/100, Train Loss: 0.1157, Val Loss: 0.1328\n",
      "Epoch 50/100, Train Loss: 0.1130, Val Loss: 0.1328\n",
      "Epoch 51/100, Train Loss: 0.1145, Val Loss: 0.1327\n",
      "Epoch 52/100, Train Loss: 0.1125, Val Loss: 0.1325\n",
      "Epoch 53/100, Train Loss: 0.1121, Val Loss: 0.1325\n",
      "Epoch 54/100, Train Loss: 0.1105, Val Loss: 0.1327\n",
      "Epoch 55/100, Train Loss: 0.1118, Val Loss: 0.1331\n",
      "Epoch 56/100, Train Loss: 0.1138, Val Loss: 0.1327\n",
      "Epoch 57/100, Train Loss: 0.1085, Val Loss: 0.1321\n",
      "Epoch 58/100, Train Loss: 0.1098, Val Loss: 0.1317\n",
      "Epoch 59/100, Train Loss: 0.1102, Val Loss: 0.1319\n",
      "Epoch 60/100, Train Loss: 0.1111, Val Loss: 0.1317\n",
      "Epoch 61/100, Train Loss: 0.1084, Val Loss: 0.1319\n",
      "Epoch 62/100, Train Loss: 0.1089, Val Loss: 0.1322\n",
      "Epoch 63/100, Train Loss: 0.1107, Val Loss: 0.1328\n",
      "Epoch 64/100, Train Loss: 0.1078, Val Loss: 0.1327\n",
      "Epoch 65/100, Train Loss: 0.1099, Val Loss: 0.1325\n",
      "Epoch 66/100, Train Loss: 0.1093, Val Loss: 0.1316\n",
      "Epoch 67/100, Train Loss: 0.1073, Val Loss: 0.1316\n",
      "Epoch 68/100, Train Loss: 0.1058, Val Loss: 0.1315\n",
      "Epoch 69/100, Train Loss: 0.1057, Val Loss: 0.1306\n",
      "Epoch 70/100, Train Loss: 0.1061, Val Loss: 0.1297\n",
      "Epoch 71/100, Train Loss: 0.1074, Val Loss: 0.1287\n",
      "Epoch 72/100, Train Loss: 0.1058, Val Loss: 0.1284\n",
      "Epoch 73/100, Train Loss: 0.1075, Val Loss: 0.1291\n",
      "Epoch 74/100, Train Loss: 0.1062, Val Loss: 0.1285\n",
      "Epoch 75/100, Train Loss: 0.1045, Val Loss: 0.1278\n",
      "Epoch 76/100, Train Loss: 0.1054, Val Loss: 0.1276\n",
      "Epoch 77/100, Train Loss: 0.1050, Val Loss: 0.1273\n",
      "Epoch 78/100, Train Loss: 0.1022, Val Loss: 0.1274\n",
      "Epoch 79/100, Train Loss: 0.1029, Val Loss: 0.1274\n",
      "Epoch 80/100, Train Loss: 0.1038, Val Loss: 0.1275\n",
      "Epoch 81/100, Train Loss: 0.1049, Val Loss: 0.1266\n",
      "Epoch 82/100, Train Loss: 0.1026, Val Loss: 0.1264\n",
      "Epoch 83/100, Train Loss: 0.1028, Val Loss: 0.1259\n",
      "Epoch 84/100, Train Loss: 0.1052, Val Loss: 0.1256\n",
      "Epoch 85/100, Train Loss: 0.1040, Val Loss: 0.1257\n",
      "Epoch 86/100, Train Loss: 0.1008, Val Loss: 0.1250\n",
      "Epoch 87/100, Train Loss: 0.1044, Val Loss: 0.1246\n",
      "Epoch 88/100, Train Loss: 0.1028, Val Loss: 0.1246\n",
      "Epoch 89/100, Train Loss: 0.1004, Val Loss: 0.1240\n",
      "Epoch 90/100, Train Loss: 0.1030, Val Loss: 0.1236\n",
      "Epoch 91/100, Train Loss: 0.0998, Val Loss: 0.1234\n",
      "Epoch 92/100, Train Loss: 0.1015, Val Loss: 0.1231\n",
      "Epoch 93/100, Train Loss: 0.1006, Val Loss: 0.1223\n",
      "Epoch 94/100, Train Loss: 0.0986, Val Loss: 0.1224\n",
      "Epoch 95/100, Train Loss: 0.0982, Val Loss: 0.1221\n",
      "Epoch 96/100, Train Loss: 0.0995, Val Loss: 0.1218\n",
      "Epoch 97/100, Train Loss: 0.0986, Val Loss: 0.1207\n",
      "Epoch 98/100, Train Loss: 0.0997, Val Loss: 0.1204\n",
      "Epoch 99/100, Train Loss: 0.0981, Val Loss: 0.1196\n",
      "Epoch 100/100, Train Loss: 0.0953, Val Loss: 0.1194\n",
      "Best Validation Loss for 대파: 0.1194\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b649ab82f35472ab2a7dfc2eb84864f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "테스트 파일 추론 중:   0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "품목별_predictions = {}\n",
    "품목별_scalers = {}\n",
    "\n",
    "pbar_outer = tqdm(품목_리스트, desc=\"품목 처리 중\", position=0)\n",
    "for 품목명 in pbar_outer:\n",
    "    pbar_outer.set_description(f\"품목별 전처리 및 모델 학습 -> {품목명}\")\n",
    "    train_data, scaler = process_data(\"./train/train.csv\", \n",
    "                              \"./train/meta/TRAIN_산지공판장_2018-2021.csv\", \n",
    "                              \"./train/meta/TRAIN_전국도매_2018-2021.csv\", \n",
    "                              품목명)\n",
    "    품목별_scalers[품목명] = scaler\n",
    "    dataset = AgriculturePriceDataset(train_data)\n",
    "\n",
    "    # 데이터를 train과 validation으로 분할\n",
    "    train_data, val_data = train_test_split(dataset, test_size=0.2, random_state=42)\n",
    "    \n",
    "    train_loader = DataLoader(train_data, CFG.batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_data, CFG.batch_size, shuffle=False)\n",
    "\n",
    "    input_size = len(dataset.numeric_columns)\n",
    "    \n",
    "    model = PricePredictionLSTM(input_size, CFG.hidden_size, CFG.num_layers, CFG.output_size)\n",
    "    criterion = nn.L1Loss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), CFG.learning_rate)\n",
    "    \n",
    "    best_val_loss = float('inf')\n",
    "    os.makedirs('models', exist_ok=True)\n",
    "\n",
    "    for epoch in range(CFG.epoch):\n",
    "        train_loss = train_model(model, train_loader, criterion, optimizer, CFG.epoch)\n",
    "        val_loss = evaluate_model(model, val_loader, criterion)\n",
    "        \n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save(model.state_dict(), f'models/best_model_{품목명}.pth')\n",
    "        \n",
    "        print(f'Epoch {epoch+1}/{CFG.epoch}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}')\n",
    "    \n",
    "    print(f'Best Validation Loss for {품목명}: {best_val_loss:.4f}')\n",
    "    \n",
    "    품목_predictions = []\n",
    "\n",
    "    ### 추론 \n",
    "    pbar_inner = tqdm(range(25), desc=\"테스트 파일 추론 중\", position=1, leave=False)\n",
    "    for i in pbar_inner:\n",
    "        test_file = f\"./test/TEST_{i:02d}.csv\"\n",
    "        산지공판장_file = f\"./test/meta/TEST_산지공판장_{i:02d}.csv\"\n",
    "        전국도매_file = f\"./test/meta/TEST_전국도매_{i:02d}.csv\"\n",
    "        \n",
    "        test_data, _ = process_data(test_file, 산지공판장_file, 전국도매_file, 품목명, scaler=품목별_scalers[품목명])\n",
    "        test_dataset = AgriculturePriceDataset(test_data, is_test=True)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "        model.eval()\n",
    "        predictions = []\n",
    "        with torch.no_grad():\n",
    "            for batch in test_loader:\n",
    "                output = model(batch)\n",
    "                predictions.append(output.numpy())\n",
    "        \n",
    "        predictions_array = np.concatenate(predictions)\n",
    "\n",
    "        # 예측값을 원래 스케일로 복원\n",
    "        price_column_index = test_data.columns.get_loc(test_dataset.price_column)\n",
    "        predictions_reshaped = predictions_array.reshape(-1, 1)\n",
    "        \n",
    "        # 가격 열에 대해서만 inverse_transform 적용\n",
    "        price_scaler = MinMaxScaler()\n",
    "        price_scaler.min_ = 품목별_scalers[품목명].min_[price_column_index]\n",
    "        price_scaler.scale_ = 품목별_scalers[품목명].scale_[price_column_index]\n",
    "        predictions_original_scale = price_scaler.inverse_transform(predictions_reshaped)\n",
    "        #print(predictions_original_scale)\n",
    "        \n",
    "        if np.isnan(predictions_original_scale).any():\n",
    "            pbar_inner.set_postfix({\"상태\": \"NaN\"})\n",
    "        else:\n",
    "            pbar_inner.set_postfix({\"상태\": \"정상\"})\n",
    "            품목_predictions.extend(predictions_original_scale.flatten())\n",
    "\n",
    "            \n",
    "    품목별_predictions[품목명] = 품목_predictions\n",
    "    pbar_outer.update(1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Submission File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv('./sample_submission.csv')\n",
    "\n",
    "for 품목명, predictions in 품목별_predictions.items():\n",
    "    sample_submission[품목명] = predictions\n",
    "\n",
    "# 결과 저장\n",
    "sample_submission.to_csv('./baseline_submission6.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
