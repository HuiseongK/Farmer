{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 농산물 가격 예측을 위한 AI 모델 개발 \n",
    "- '2024 농산물 가격 예측 AI 경진대회'는 데이터와 AI 기술을 활용하여 농산물 가격 예측 능력을 향상시키는 것을 목표로 합니다.<br>  이 대회는 농업 분야의 복잡한 시계열 데이터를 효율적으로 분석하고 예측할 수 있는 AI 알고리즘 개발에 초점을 맞추고 있습니다. <br> <br>\n",
    "- 이 대회의 궁극적 목적은 참가자들의 시계열 데이터 분석 및 예측 역량을 강화하고, <br> AI 기술이 실제 농산물 가격 예측과 관련 정책 결정에 어떻게 기여할 수 있는지 탐구하는 것입니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm.notebook import tqdm\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from types import SimpleNamespace\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"learning_rate\": 2e-4,\n",
    "    \"epoch\": 100,\n",
    "    \"batch_size\": 64,\n",
    "    \"hidden_size\": 64,\n",
    "    \"num_layers\": 2,\n",
    "    \"output_size\": 3\n",
    "}\n",
    "\n",
    "CFG = SimpleNamespace(**config)\n",
    "\n",
    "품목_리스트 = ['건고추', '사과', '감자', '배', '깐마늘(국산)', '무', '상추', '배추', '양파', '대파']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Function for Feature Engineering\n",
    "- 타겟의 필터 조건을 제외한 메타데이터의 필터 조건은 참가자들 각자의 기준에 맞춰 자유롭게 사용가능 \n",
    "- 밑의 필터 조건은 임의로 제공하는 예시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def process_data(raw_file, 품목명, scaler=None):\n",
    "    raw_data = pd.read_csv(raw_file)\n",
    "\n",
    "    # 타겟 및 메타데이터 필터 조건 정의\n",
    "    conditions = {\n",
    "    '감자': {\n",
    "        'target': lambda df: (df['품종명'] == '감자 수미') & (df['거래단위'] == '20키로상자') & (df['등급'] == '상')\n",
    "    },\n",
    "    '건고추': {\n",
    "        'target': lambda df: (df['품종명'] == '화건') & (df['거래단위'] == '30 kg') & (df['등급'] == '상품')\n",
    "    },\n",
    "    '깐마늘(국산)': {\n",
    "        'target': lambda df: (df['거래단위'] == '20 kg') & (df['등급'] == '상품')\n",
    "    },\n",
    "    '대파': {\n",
    "        'target': lambda df: (df['품종명'] == '대파(일반)') & (df['거래단위'] == '1키로단') & (df['등급'] == '상')\n",
    "    },\n",
    "    '무': {\n",
    "        'target': lambda df: (df['거래단위'] == '20키로상자') & (df['등급'] == '상')\n",
    "    },\n",
    "    '배추': {\n",
    "        'target': lambda df: (df['거래단위'] == '10키로망대') & (df['등급'] == '상')\n",
    "    },\n",
    "    '사과': {\n",
    "        'target': lambda df: (df['품종명'].isin(['홍로', '후지'])) & (df['거래단위'] == '10 개') & (df['등급'] == '상품')\n",
    "    },\n",
    "    '상추': {\n",
    "        'target': lambda df: (df['품종명'] == '청') & (df['거래단위'] == '100 g') & (df['등급'] == '상품')\n",
    "    },\n",
    "    '양파': {\n",
    "        'target': lambda df: (df['품종명'] == '양파') & (df['거래단위'] == '1키로') & (df['등급'] == '상')\n",
    "    },\n",
    "    '배': {\n",
    "        'target': lambda df: (df['품종명'] == '신고') & (df['거래단위'] == '10 개') & (df['등급'] == '상품')\n",
    "    }\n",
    "    }\n",
    "\n",
    "    # 타겟 데이터 필터링\n",
    "    raw_품목 = raw_data[raw_data['품목명'] == 품목명]\n",
    "    target_mask = conditions[품목명]['target'](raw_품목)\n",
    "    filtered_data = raw_품목[target_mask]\n",
    "\n",
    "    # 다른 품종에 대한 파생변수 생성\n",
    "    other_data = raw_품목[~target_mask]\n",
    "    unique_combinations = other_data[['품종명', '거래단위', '등급']].drop_duplicates()\n",
    "    for _, row in unique_combinations.iterrows():\n",
    "        품종명, 거래단위, 등급 = row['품종명'], row['거래단위'], row['등급']\n",
    "        mask = (other_data['품종명'] == 품종명) & (other_data['거래단위'] == 거래단위) & (other_data['등급'] == 등급)\n",
    "        temp_df = other_data[mask]\n",
    "        for col in ['평년 평균가격(원)', '평균가격(원)']:\n",
    "            new_col_name = f'{품종명}_{거래단위}_{등급}_{col}'\n",
    "            filtered_data = filtered_data.merge(temp_df[['시점', col]], on='시점', how='left', suffixes=('', f'_{new_col_name}'))\n",
    "            filtered_data.rename(columns={f'{col}_{new_col_name}': new_col_name}, inplace=True)\n",
    "\n",
    "\n",
    "    # 공판장 데이터 처리\n",
    " \n",
    "\n",
    "    # 도매 데이터 처리\n",
    "\n",
    "\n",
    "    # 수치형 컬럼 처리\n",
    "    numeric_columns = filtered_data.select_dtypes(include=[np.number]).columns\n",
    "    filtered_data = filtered_data[['시점'] + list(numeric_columns)]\n",
    "    filtered_data[numeric_columns] = filtered_data[numeric_columns].fillna(0)\n",
    "\n",
    "    # 정규화 적용\n",
    "    if scaler is None:\n",
    "        scaler = MinMaxScaler()\n",
    "        filtered_data[numeric_columns] = scaler.fit_transform(filtered_data[numeric_columns])\n",
    "    else:\n",
    "        filtered_data[numeric_columns] = scaler.transform(filtered_data[numeric_columns])\n",
    "\n",
    "    return filtered_data, scaler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Custom Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgriculturePriceDataset(Dataset):\n",
    "    def __init__(self, dataframe, window_size=9, prediction_length=3, is_test=False):\n",
    "        self.data = dataframe\n",
    "        self.window_size = window_size\n",
    "        self.prediction_length = prediction_length\n",
    "        self.is_test = is_test\n",
    "\n",
    "        self.price_column = [col for col in self.data.columns if '평균가격(원)' in col and len(col.split('_')) == 1][0]\n",
    "        self.numeric_columns = self.data.select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "        self.sequences = []\n",
    "        if not self.is_test:\n",
    "            for i in range(len(self.data) - self.window_size - self.prediction_length + 1):\n",
    "                x = self.data[self.numeric_columns].iloc[i:i+self.window_size].values\n",
    "                y = self.data[self.price_column].iloc[i+self.window_size:i+self.window_size+self.prediction_length].values\n",
    "                self.sequences.append((x, y))\n",
    "        else:\n",
    "            self.sequences = [self.data[self.numeric_columns].values]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if not self.is_test:\n",
    "            x, y = self.sequences[idx]\n",
    "            return torch.FloatTensor(x), torch.FloatTensor(y)\n",
    "        else:\n",
    "            return torch.FloatTensor(self.sequences[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Model Architecture and Training Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class PricePredictionLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
    "        super(PricePredictionLSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n",
    "\n",
    "def train_model(model, train_loader, criterion, optimizer, num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch_x, batch_y in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_x)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(train_loader)\n",
    "\n",
    "def evaluate_model(model, test_loader, criterion):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_x, batch_y in test_loader:\n",
    "            outputs = model(batch_x)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            total_loss += loss.item()\n",
    "    return total_loss / len(test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Models and Generate Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b468ab3603c45f6a503a24e660f37b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "품목 처리 중:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Train Loss: 0.7612, Val Loss: 0.7344\n",
      "Epoch 2/100, Train Loss: 0.7529, Val Loss: 0.7271\n",
      "Epoch 3/100, Train Loss: 0.7485, Val Loss: 0.7198\n",
      "Epoch 4/100, Train Loss: 0.7410, Val Loss: 0.7125\n",
      "Epoch 5/100, Train Loss: 0.7288, Val Loss: 0.7052\n",
      "Epoch 6/100, Train Loss: 0.7222, Val Loss: 0.6978\n",
      "Epoch 7/100, Train Loss: 0.7133, Val Loss: 0.6902\n",
      "Epoch 8/100, Train Loss: 0.7056, Val Loss: 0.6825\n",
      "Epoch 9/100, Train Loss: 0.7032, Val Loss: 0.6745\n",
      "Epoch 10/100, Train Loss: 0.6918, Val Loss: 0.6661\n",
      "Epoch 11/100, Train Loss: 0.6827, Val Loss: 0.6574\n",
      "Epoch 12/100, Train Loss: 0.6757, Val Loss: 0.6482\n",
      "Epoch 13/100, Train Loss: 0.6681, Val Loss: 0.6384\n",
      "Epoch 14/100, Train Loss: 0.6535, Val Loss: 0.6278\n",
      "Epoch 15/100, Train Loss: 0.6410, Val Loss: 0.6164\n",
      "Epoch 16/100, Train Loss: 0.6327, Val Loss: 0.6040\n",
      "Epoch 17/100, Train Loss: 0.6176, Val Loss: 0.5904\n",
      "Epoch 18/100, Train Loss: 0.6078, Val Loss: 0.5752\n",
      "Epoch 19/100, Train Loss: 0.5932, Val Loss: 0.5583\n",
      "Epoch 20/100, Train Loss: 0.5722, Val Loss: 0.5393\n",
      "Epoch 21/100, Train Loss: 0.5559, Val Loss: 0.5176\n",
      "Epoch 22/100, Train Loss: 0.5321, Val Loss: 0.4929\n",
      "Epoch 23/100, Train Loss: 0.5089, Val Loss: 0.4643\n",
      "Epoch 24/100, Train Loss: 0.4759, Val Loss: 0.4311\n",
      "Epoch 25/100, Train Loss: 0.4471, Val Loss: 0.3924\n",
      "Epoch 26/100, Train Loss: 0.4030, Val Loss: 0.3470\n",
      "Epoch 27/100, Train Loss: 0.3572, Val Loss: 0.2935\n",
      "Epoch 28/100, Train Loss: 0.3020, Val Loss: 0.2304\n",
      "Epoch 29/100, Train Loss: 0.2365, Val Loss: 0.1696\n",
      "Epoch 30/100, Train Loss: 0.1830, Val Loss: 0.1550\n",
      "Epoch 31/100, Train Loss: 0.1647, Val Loss: 0.1558\n",
      "Epoch 32/100, Train Loss: 0.1656, Val Loss: 0.1546\n",
      "Epoch 33/100, Train Loss: 0.1632, Val Loss: 0.1431\n",
      "Epoch 34/100, Train Loss: 0.1520, Val Loss: 0.1351\n",
      "Epoch 35/100, Train Loss: 0.1390, Val Loss: 0.1206\n",
      "Epoch 36/100, Train Loss: 0.1199, Val Loss: 0.1003\n",
      "Epoch 37/100, Train Loss: 0.1018, Val Loss: 0.0870\n",
      "Epoch 38/100, Train Loss: 0.0991, Val Loss: 0.0813\n",
      "Epoch 39/100, Train Loss: 0.0968, Val Loss: 0.0786\n",
      "Epoch 40/100, Train Loss: 0.0938, Val Loss: 0.0751\n",
      "Epoch 41/100, Train Loss: 0.0964, Val Loss: 0.0737\n",
      "Epoch 42/100, Train Loss: 0.0955, Val Loss: 0.0730\n",
      "Epoch 43/100, Train Loss: 0.0868, Val Loss: 0.0735\n",
      "Epoch 44/100, Train Loss: 0.0861, Val Loss: 0.0775\n",
      "Epoch 45/100, Train Loss: 0.0871, Val Loss: 0.0800\n",
      "Epoch 46/100, Train Loss: 0.0873, Val Loss: 0.0810\n",
      "Epoch 47/100, Train Loss: 0.0891, Val Loss: 0.0799\n",
      "Epoch 48/100, Train Loss: 0.0857, Val Loss: 0.0781\n",
      "Epoch 49/100, Train Loss: 0.0862, Val Loss: 0.0756\n",
      "Epoch 50/100, Train Loss: 0.0823, Val Loss: 0.0735\n",
      "Epoch 51/100, Train Loss: 0.0844, Val Loss: 0.0718\n",
      "Epoch 52/100, Train Loss: 0.0830, Val Loss: 0.0711\n",
      "Epoch 53/100, Train Loss: 0.0830, Val Loss: 0.0713\n",
      "Epoch 54/100, Train Loss: 0.0826, Val Loss: 0.0721\n",
      "Epoch 55/100, Train Loss: 0.0809, Val Loss: 0.0727\n",
      "Epoch 56/100, Train Loss: 0.0843, Val Loss: 0.0727\n",
      "Epoch 57/100, Train Loss: 0.0802, Val Loss: 0.0724\n",
      "Epoch 58/100, Train Loss: 0.0808, Val Loss: 0.0716\n",
      "Epoch 59/100, Train Loss: 0.0784, Val Loss: 0.0706\n",
      "Epoch 60/100, Train Loss: 0.0765, Val Loss: 0.0698\n",
      "Epoch 61/100, Train Loss: 0.0782, Val Loss: 0.0693\n",
      "Epoch 62/100, Train Loss: 0.0762, Val Loss: 0.0690\n",
      "Epoch 63/100, Train Loss: 0.0771, Val Loss: 0.0689\n",
      "Epoch 64/100, Train Loss: 0.0746, Val Loss: 0.0688\n",
      "Epoch 65/100, Train Loss: 0.0752, Val Loss: 0.0685\n",
      "Epoch 66/100, Train Loss: 0.0735, Val Loss: 0.0682\n",
      "Epoch 67/100, Train Loss: 0.0751, Val Loss: 0.0674\n",
      "Epoch 68/100, Train Loss: 0.0762, Val Loss: 0.0668\n",
      "Epoch 69/100, Train Loss: 0.0733, Val Loss: 0.0669\n",
      "Epoch 70/100, Train Loss: 0.0734, Val Loss: 0.0670\n",
      "Epoch 71/100, Train Loss: 0.0724, Val Loss: 0.0670\n",
      "Epoch 72/100, Train Loss: 0.0713, Val Loss: 0.0666\n",
      "Epoch 73/100, Train Loss: 0.0706, Val Loss: 0.0657\n",
      "Epoch 74/100, Train Loss: 0.0689, Val Loss: 0.0648\n",
      "Epoch 75/100, Train Loss: 0.0714, Val Loss: 0.0644\n",
      "Epoch 76/100, Train Loss: 0.0687, Val Loss: 0.0645\n",
      "Epoch 77/100, Train Loss: 0.0709, Val Loss: 0.0646\n",
      "Epoch 78/100, Train Loss: 0.0696, Val Loss: 0.0641\n",
      "Epoch 79/100, Train Loss: 0.0670, Val Loss: 0.0635\n",
      "Epoch 80/100, Train Loss: 0.0686, Val Loss: 0.0627\n",
      "Epoch 81/100, Train Loss: 0.0651, Val Loss: 0.0623\n",
      "Epoch 82/100, Train Loss: 0.0667, Val Loss: 0.0617\n",
      "Epoch 83/100, Train Loss: 0.0634, Val Loss: 0.0612\n",
      "Epoch 84/100, Train Loss: 0.0642, Val Loss: 0.0606\n",
      "Epoch 85/100, Train Loss: 0.0660, Val Loss: 0.0600\n",
      "Epoch 86/100, Train Loss: 0.0616, Val Loss: 0.0596\n",
      "Epoch 87/100, Train Loss: 0.0628, Val Loss: 0.0594\n",
      "Epoch 88/100, Train Loss: 0.0619, Val Loss: 0.0588\n",
      "Epoch 89/100, Train Loss: 0.0599, Val Loss: 0.0581\n",
      "Epoch 90/100, Train Loss: 0.0623, Val Loss: 0.0576\n",
      "Epoch 91/100, Train Loss: 0.0602, Val Loss: 0.0570\n",
      "Epoch 92/100, Train Loss: 0.0601, Val Loss: 0.0563\n",
      "Epoch 93/100, Train Loss: 0.0599, Val Loss: 0.0563\n",
      "Epoch 94/100, Train Loss: 0.0569, Val Loss: 0.0562\n",
      "Epoch 95/100, Train Loss: 0.0572, Val Loss: 0.0552\n",
      "Epoch 96/100, Train Loss: 0.0560, Val Loss: 0.0544\n",
      "Epoch 97/100, Train Loss: 0.0571, Val Loss: 0.0537\n",
      "Epoch 98/100, Train Loss: 0.0590, Val Loss: 0.0529\n",
      "Epoch 99/100, Train Loss: 0.0565, Val Loss: 0.0528\n",
      "Epoch 100/100, Train Loss: 0.0552, Val Loss: 0.0529\n",
      "Best Validation Loss for 건고추: 0.0528\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f7858dd33b84f43b8fdbb2503f2a5c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "테스트 파일 추론 중:   0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Train Loss: 0.7907, Val Loss: 0.7963\n",
      "Epoch 2/100, Train Loss: 0.7843, Val Loss: 0.7893\n",
      "Epoch 3/100, Train Loss: 0.7740, Val Loss: 0.7823\n",
      "Epoch 4/100, Train Loss: 0.7681, Val Loss: 0.7751\n",
      "Epoch 5/100, Train Loss: 0.7591, Val Loss: 0.7678\n",
      "Epoch 6/100, Train Loss: 0.7529, Val Loss: 0.7604\n",
      "Epoch 7/100, Train Loss: 0.7485, Val Loss: 0.7527\n",
      "Epoch 8/100, Train Loss: 0.7357, Val Loss: 0.7447\n",
      "Epoch 9/100, Train Loss: 0.7260, Val Loss: 0.7364\n",
      "Epoch 10/100, Train Loss: 0.7187, Val Loss: 0.7279\n",
      "Epoch 11/100, Train Loss: 0.7123, Val Loss: 0.7189\n",
      "Epoch 12/100, Train Loss: 0.7035, Val Loss: 0.7094\n",
      "Epoch 13/100, Train Loss: 0.6941, Val Loss: 0.6992\n",
      "Epoch 14/100, Train Loss: 0.6799, Val Loss: 0.6882\n",
      "Epoch 15/100, Train Loss: 0.6702, Val Loss: 0.6762\n",
      "Epoch 16/100, Train Loss: 0.6578, Val Loss: 0.6630\n",
      "Epoch 17/100, Train Loss: 0.6450, Val Loss: 0.6485\n",
      "Epoch 18/100, Train Loss: 0.6260, Val Loss: 0.6323\n",
      "Epoch 19/100, Train Loss: 0.6126, Val Loss: 0.6142\n",
      "Epoch 20/100, Train Loss: 0.5895, Val Loss: 0.5939\n",
      "Epoch 21/100, Train Loss: 0.5695, Val Loss: 0.5708\n",
      "Epoch 22/100, Train Loss: 0.5457, Val Loss: 0.5444\n",
      "Epoch 23/100, Train Loss: 0.5185, Val Loss: 0.5142\n",
      "Epoch 24/100, Train Loss: 0.4852, Val Loss: 0.4793\n",
      "Epoch 25/100, Train Loss: 0.4492, Val Loss: 0.4390\n",
      "Epoch 26/100, Train Loss: 0.4013, Val Loss: 0.3921\n",
      "Epoch 27/100, Train Loss: 0.3512, Val Loss: 0.3377\n",
      "Epoch 28/100, Train Loss: 0.2925, Val Loss: 0.2744\n",
      "Epoch 29/100, Train Loss: 0.2235, Val Loss: 0.2015\n",
      "Epoch 30/100, Train Loss: 0.1447, Val Loss: 0.1294\n",
      "Epoch 31/100, Train Loss: 0.0905, Val Loss: 0.1132\n",
      "Epoch 32/100, Train Loss: 0.1137, Val Loss: 0.1383\n",
      "Epoch 33/100, Train Loss: 0.1429, Val Loss: 0.1459\n",
      "Epoch 34/100, Train Loss: 0.1513, Val Loss: 0.1292\n",
      "Epoch 35/100, Train Loss: 0.1220, Val Loss: 0.1086\n",
      "Epoch 36/100, Train Loss: 0.0937, Val Loss: 0.1030\n",
      "Epoch 37/100, Train Loss: 0.0885, Val Loss: 0.1124\n",
      "Epoch 38/100, Train Loss: 0.0916, Val Loss: 0.1251\n",
      "Epoch 39/100, Train Loss: 0.0964, Val Loss: 0.1291\n",
      "Epoch 40/100, Train Loss: 0.0984, Val Loss: 0.1228\n",
      "Epoch 41/100, Train Loss: 0.0917, Val Loss: 0.1123\n",
      "Epoch 42/100, Train Loss: 0.0834, Val Loss: 0.1014\n",
      "Epoch 43/100, Train Loss: 0.0791, Val Loss: 0.0966\n",
      "Epoch 44/100, Train Loss: 0.0766, Val Loss: 0.0954\n",
      "Epoch 45/100, Train Loss: 0.0817, Val Loss: 0.0951\n",
      "Epoch 46/100, Train Loss: 0.0818, Val Loss: 0.0938\n",
      "Epoch 47/100, Train Loss: 0.0742, Val Loss: 0.0929\n",
      "Epoch 48/100, Train Loss: 0.0756, Val Loss: 0.0932\n",
      "Epoch 49/100, Train Loss: 0.0726, Val Loss: 0.0943\n",
      "Epoch 50/100, Train Loss: 0.0772, Val Loss: 0.0940\n",
      "Epoch 51/100, Train Loss: 0.0737, Val Loss: 0.0926\n",
      "Epoch 52/100, Train Loss: 0.0768, Val Loss: 0.0905\n",
      "Epoch 53/100, Train Loss: 0.0703, Val Loss: 0.0889\n",
      "Epoch 54/100, Train Loss: 0.0677, Val Loss: 0.0875\n",
      "Epoch 55/100, Train Loss: 0.0704, Val Loss: 0.0867\n",
      "Epoch 56/100, Train Loss: 0.0695, Val Loss: 0.0860\n",
      "Epoch 57/100, Train Loss: 0.0692, Val Loss: 0.0855\n",
      "Epoch 58/100, Train Loss: 0.0665, Val Loss: 0.0857\n",
      "Epoch 59/100, Train Loss: 0.0659, Val Loss: 0.0857\n",
      "Epoch 60/100, Train Loss: 0.0668, Val Loss: 0.0853\n",
      "Epoch 61/100, Train Loss: 0.0698, Val Loss: 0.0845\n",
      "Epoch 62/100, Train Loss: 0.0681, Val Loss: 0.0837\n",
      "Epoch 63/100, Train Loss: 0.0674, Val Loss: 0.0830\n",
      "Epoch 64/100, Train Loss: 0.0656, Val Loss: 0.0825\n",
      "Epoch 65/100, Train Loss: 0.0679, Val Loss: 0.0821\n",
      "Epoch 66/100, Train Loss: 0.0660, Val Loss: 0.0817\n",
      "Epoch 67/100, Train Loss: 0.0656, Val Loss: 0.0815\n",
      "Epoch 68/100, Train Loss: 0.0643, Val Loss: 0.0813\n",
      "Epoch 69/100, Train Loss: 0.0639, Val Loss: 0.0811\n",
      "Epoch 70/100, Train Loss: 0.0648, Val Loss: 0.0808\n",
      "Epoch 71/100, Train Loss: 0.0633, Val Loss: 0.0804\n",
      "Epoch 72/100, Train Loss: 0.0635, Val Loss: 0.0801\n",
      "Epoch 73/100, Train Loss: 0.0643, Val Loss: 0.0800\n",
      "Epoch 74/100, Train Loss: 0.0661, Val Loss: 0.0799\n",
      "Epoch 75/100, Train Loss: 0.0593, Val Loss: 0.0799\n",
      "Epoch 76/100, Train Loss: 0.0635, Val Loss: 0.0796\n",
      "Epoch 77/100, Train Loss: 0.0619, Val Loss: 0.0793\n",
      "Epoch 78/100, Train Loss: 0.0621, Val Loss: 0.0790\n",
      "Epoch 79/100, Train Loss: 0.0623, Val Loss: 0.0788\n",
      "Epoch 80/100, Train Loss: 0.0622, Val Loss: 0.0786\n",
      "Epoch 81/100, Train Loss: 0.0615, Val Loss: 0.0784\n",
      "Epoch 82/100, Train Loss: 0.0589, Val Loss: 0.0784\n",
      "Epoch 83/100, Train Loss: 0.0588, Val Loss: 0.0783\n",
      "Epoch 84/100, Train Loss: 0.0588, Val Loss: 0.0781\n",
      "Epoch 85/100, Train Loss: 0.0657, Val Loss: 0.0780\n",
      "Epoch 86/100, Train Loss: 0.0582, Val Loss: 0.0779\n",
      "Epoch 87/100, Train Loss: 0.0624, Val Loss: 0.0779\n",
      "Epoch 88/100, Train Loss: 0.0620, Val Loss: 0.0778\n",
      "Epoch 89/100, Train Loss: 0.0605, Val Loss: 0.0778\n",
      "Epoch 90/100, Train Loss: 0.0619, Val Loss: 0.0777\n",
      "Epoch 91/100, Train Loss: 0.0605, Val Loss: 0.0778\n",
      "Epoch 92/100, Train Loss: 0.0621, Val Loss: 0.0779\n",
      "Epoch 93/100, Train Loss: 0.0598, Val Loss: 0.0779\n",
      "Epoch 94/100, Train Loss: 0.0617, Val Loss: 0.0777\n",
      "Epoch 95/100, Train Loss: 0.0579, Val Loss: 0.0775\n",
      "Epoch 96/100, Train Loss: 0.0618, Val Loss: 0.0775\n",
      "Epoch 97/100, Train Loss: 0.0606, Val Loss: 0.0775\n",
      "Epoch 98/100, Train Loss: 0.0608, Val Loss: 0.0776\n",
      "Epoch 99/100, Train Loss: 0.0592, Val Loss: 0.0777\n",
      "Epoch 100/100, Train Loss: 0.0568, Val Loss: 0.0776\n",
      "Best Validation Loss for 사과: 0.0775\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a12c8b25ce64effbcf7bfd43722e32f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "테스트 파일 추론 중:   0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Train Loss: 0.4683, Val Loss: 0.3827\n",
      "Epoch 2/100, Train Loss: 0.4632, Val Loss: 0.3751\n",
      "Epoch 3/100, Train Loss: 0.4570, Val Loss: 0.3674\n",
      "Epoch 4/100, Train Loss: 0.4445, Val Loss: 0.3596\n",
      "Epoch 5/100, Train Loss: 0.4357, Val Loss: 0.3517\n",
      "Epoch 6/100, Train Loss: 0.4221, Val Loss: 0.3436\n",
      "Epoch 7/100, Train Loss: 0.4265, Val Loss: 0.3352\n",
      "Epoch 8/100, Train Loss: 0.4065, Val Loss: 0.3266\n",
      "Epoch 9/100, Train Loss: 0.4058, Val Loss: 0.3176\n",
      "Epoch 10/100, Train Loss: 0.4024, Val Loss: 0.3083\n",
      "Epoch 11/100, Train Loss: 0.3918, Val Loss: 0.2986\n",
      "Epoch 12/100, Train Loss: 0.3718, Val Loss: 0.2883\n",
      "Epoch 13/100, Train Loss: 0.3574, Val Loss: 0.2781\n",
      "Epoch 14/100, Train Loss: 0.3523, Val Loss: 0.2686\n",
      "Epoch 15/100, Train Loss: 0.3421, Val Loss: 0.2589\n",
      "Epoch 16/100, Train Loss: 0.3296, Val Loss: 0.2500\n",
      "Epoch 17/100, Train Loss: 0.3178, Val Loss: 0.2405\n",
      "Epoch 18/100, Train Loss: 0.3007, Val Loss: 0.2300\n",
      "Epoch 19/100, Train Loss: 0.2809, Val Loss: 0.2196\n",
      "Epoch 20/100, Train Loss: 0.2762, Val Loss: 0.2092\n",
      "Epoch 21/100, Train Loss: 0.2483, Val Loss: 0.1982\n",
      "Epoch 22/100, Train Loss: 0.2375, Val Loss: 0.1867\n",
      "Epoch 23/100, Train Loss: 0.2209, Val Loss: 0.1772\n",
      "Epoch 24/100, Train Loss: 0.2056, Val Loss: 0.1727\n",
      "Epoch 25/100, Train Loss: 0.1966, Val Loss: 0.1748\n",
      "Epoch 26/100, Train Loss: 0.1815, Val Loss: 0.1799\n",
      "Epoch 27/100, Train Loss: 0.1773, Val Loss: 0.1864\n",
      "Epoch 28/100, Train Loss: 0.1777, Val Loss: 0.1908\n",
      "Epoch 29/100, Train Loss: 0.1760, Val Loss: 0.1912\n",
      "Epoch 30/100, Train Loss: 0.1647, Val Loss: 0.1890\n",
      "Epoch 31/100, Train Loss: 0.1683, Val Loss: 0.1852\n",
      "Epoch 32/100, Train Loss: 0.1638, Val Loss: 0.1809\n",
      "Epoch 33/100, Train Loss: 0.1601, Val Loss: 0.1767\n",
      "Epoch 34/100, Train Loss: 0.1598, Val Loss: 0.1723\n",
      "Epoch 35/100, Train Loss: 0.1508, Val Loss: 0.1690\n",
      "Epoch 36/100, Train Loss: 0.1540, Val Loss: 0.1671\n",
      "Epoch 37/100, Train Loss: 0.1558, Val Loss: 0.1661\n",
      "Epoch 38/100, Train Loss: 0.1521, Val Loss: 0.1657\n",
      "Epoch 39/100, Train Loss: 0.1503, Val Loss: 0.1655\n",
      "Epoch 40/100, Train Loss: 0.1462, Val Loss: 0.1654\n",
      "Epoch 41/100, Train Loss: 0.1472, Val Loss: 0.1653\n",
      "Epoch 42/100, Train Loss: 0.1479, Val Loss: 0.1654\n",
      "Epoch 43/100, Train Loss: 0.1460, Val Loss: 0.1654\n",
      "Epoch 44/100, Train Loss: 0.1448, Val Loss: 0.1647\n",
      "Epoch 45/100, Train Loss: 0.1446, Val Loss: 0.1631\n",
      "Epoch 46/100, Train Loss: 0.1429, Val Loss: 0.1614\n",
      "Epoch 47/100, Train Loss: 0.1390, Val Loss: 0.1590\n",
      "Epoch 48/100, Train Loss: 0.1357, Val Loss: 0.1568\n",
      "Epoch 49/100, Train Loss: 0.1368, Val Loss: 0.1550\n",
      "Epoch 50/100, Train Loss: 0.1349, Val Loss: 0.1540\n",
      "Epoch 51/100, Train Loss: 0.1340, Val Loss: 0.1544\n",
      "Epoch 52/100, Train Loss: 0.1345, Val Loss: 0.1557\n",
      "Epoch 53/100, Train Loss: 0.1345, Val Loss: 0.1572\n",
      "Epoch 54/100, Train Loss: 0.1334, Val Loss: 0.1574\n",
      "Epoch 55/100, Train Loss: 0.1304, Val Loss: 0.1564\n",
      "Epoch 56/100, Train Loss: 0.1306, Val Loss: 0.1538\n",
      "Epoch 57/100, Train Loss: 0.1271, Val Loss: 0.1504\n",
      "Epoch 58/100, Train Loss: 0.1290, Val Loss: 0.1484\n",
      "Epoch 59/100, Train Loss: 0.1301, Val Loss: 0.1483\n",
      "Epoch 60/100, Train Loss: 0.1271, Val Loss: 0.1491\n",
      "Epoch 61/100, Train Loss: 0.1244, Val Loss: 0.1512\n",
      "Epoch 62/100, Train Loss: 0.1264, Val Loss: 0.1526\n",
      "Epoch 63/100, Train Loss: 0.1215, Val Loss: 0.1520\n",
      "Epoch 64/100, Train Loss: 0.1184, Val Loss: 0.1497\n",
      "Epoch 65/100, Train Loss: 0.1217, Val Loss: 0.1476\n",
      "Epoch 66/100, Train Loss: 0.1194, Val Loss: 0.1458\n",
      "Epoch 67/100, Train Loss: 0.1185, Val Loss: 0.1450\n",
      "Epoch 68/100, Train Loss: 0.1197, Val Loss: 0.1447\n",
      "Epoch 69/100, Train Loss: 0.1158, Val Loss: 0.1440\n",
      "Epoch 70/100, Train Loss: 0.1151, Val Loss: 0.1433\n",
      "Epoch 71/100, Train Loss: 0.1163, Val Loss: 0.1439\n",
      "Epoch 72/100, Train Loss: 0.1137, Val Loss: 0.1425\n",
      "Epoch 73/100, Train Loss: 0.1127, Val Loss: 0.1415\n",
      "Epoch 74/100, Train Loss: 0.1149, Val Loss: 0.1406\n",
      "Epoch 75/100, Train Loss: 0.1151, Val Loss: 0.1380\n",
      "Epoch 76/100, Train Loss: 0.1126, Val Loss: 0.1363\n",
      "Epoch 77/100, Train Loss: 0.1090, Val Loss: 0.1359\n",
      "Epoch 78/100, Train Loss: 0.1097, Val Loss: 0.1346\n",
      "Epoch 79/100, Train Loss: 0.1058, Val Loss: 0.1338\n",
      "Epoch 80/100, Train Loss: 0.1026, Val Loss: 0.1344\n",
      "Epoch 81/100, Train Loss: 0.1078, Val Loss: 0.1339\n",
      "Epoch 82/100, Train Loss: 0.1048, Val Loss: 0.1318\n",
      "Epoch 83/100, Train Loss: 0.1044, Val Loss: 0.1285\n",
      "Epoch 84/100, Train Loss: 0.1047, Val Loss: 0.1254\n",
      "Epoch 85/100, Train Loss: 0.1023, Val Loss: 0.1250\n",
      "Epoch 86/100, Train Loss: 0.1027, Val Loss: 0.1266\n",
      "Epoch 87/100, Train Loss: 0.1000, Val Loss: 0.1258\n",
      "Epoch 88/100, Train Loss: 0.0964, Val Loss: 0.1247\n",
      "Epoch 89/100, Train Loss: 0.0978, Val Loss: 0.1233\n",
      "Epoch 90/100, Train Loss: 0.0968, Val Loss: 0.1217\n",
      "Epoch 91/100, Train Loss: 0.0963, Val Loss: 0.1193\n",
      "Epoch 92/100, Train Loss: 0.0985, Val Loss: 0.1185\n",
      "Epoch 93/100, Train Loss: 0.0939, Val Loss: 0.1181\n",
      "Epoch 94/100, Train Loss: 0.0912, Val Loss: 0.1176\n",
      "Epoch 95/100, Train Loss: 0.0911, Val Loss: 0.1140\n",
      "Epoch 96/100, Train Loss: 0.0905, Val Loss: 0.1119\n",
      "Epoch 97/100, Train Loss: 0.0909, Val Loss: 0.1131\n",
      "Epoch 98/100, Train Loss: 0.0925, Val Loss: 0.1125\n",
      "Epoch 99/100, Train Loss: 0.0898, Val Loss: 0.1129\n",
      "Epoch 100/100, Train Loss: 0.0914, Val Loss: 0.1106\n",
      "Best Validation Loss for 감자: 0.1106\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "477909e262be479381df32b033cfc7c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "테스트 파일 추론 중:   0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Train Loss: 0.4505, Val Loss: 0.4773\n",
      "Epoch 2/100, Train Loss: 0.4383, Val Loss: 0.4707\n",
      "Epoch 3/100, Train Loss: 0.4402, Val Loss: 0.4641\n",
      "Epoch 4/100, Train Loss: 0.4308, Val Loss: 0.4576\n",
      "Epoch 5/100, Train Loss: 0.4198, Val Loss: 0.4510\n",
      "Epoch 6/100, Train Loss: 0.4137, Val Loss: 0.4443\n",
      "Epoch 7/100, Train Loss: 0.4073, Val Loss: 0.4375\n",
      "Epoch 8/100, Train Loss: 0.4034, Val Loss: 0.4304\n",
      "Epoch 9/100, Train Loss: 0.3974, Val Loss: 0.4232\n",
      "Epoch 10/100, Train Loss: 0.3864, Val Loss: 0.4156\n",
      "Epoch 11/100, Train Loss: 0.3849, Val Loss: 0.4077\n",
      "Epoch 12/100, Train Loss: 0.3703, Val Loss: 0.3993\n",
      "Epoch 13/100, Train Loss: 0.3598, Val Loss: 0.3905\n",
      "Epoch 14/100, Train Loss: 0.3574, Val Loss: 0.3812\n",
      "Epoch 15/100, Train Loss: 0.3497, Val Loss: 0.3715\n",
      "Epoch 16/100, Train Loss: 0.3396, Val Loss: 0.3613\n",
      "Epoch 17/100, Train Loss: 0.3300, Val Loss: 0.3510\n",
      "Epoch 18/100, Train Loss: 0.3181, Val Loss: 0.3401\n",
      "Epoch 19/100, Train Loss: 0.3116, Val Loss: 0.3290\n",
      "Epoch 20/100, Train Loss: 0.2951, Val Loss: 0.3177\n",
      "Epoch 21/100, Train Loss: 0.2779, Val Loss: 0.3064\n",
      "Epoch 22/100, Train Loss: 0.2733, Val Loss: 0.2951\n",
      "Epoch 23/100, Train Loss: 0.2567, Val Loss: 0.2834\n",
      "Epoch 24/100, Train Loss: 0.2426, Val Loss: 0.2707\n",
      "Epoch 25/100, Train Loss: 0.2285, Val Loss: 0.2581\n",
      "Epoch 26/100, Train Loss: 0.2181, Val Loss: 0.2453\n",
      "Epoch 27/100, Train Loss: 0.1988, Val Loss: 0.2344\n",
      "Epoch 28/100, Train Loss: 0.1942, Val Loss: 0.2252\n",
      "Epoch 29/100, Train Loss: 0.1850, Val Loss: 0.2199\n",
      "Epoch 30/100, Train Loss: 0.1779, Val Loss: 0.2172\n",
      "Epoch 31/100, Train Loss: 0.1824, Val Loss: 0.2157\n",
      "Epoch 32/100, Train Loss: 0.1783, Val Loss: 0.2159\n",
      "Epoch 33/100, Train Loss: 0.1824, Val Loss: 0.2153\n",
      "Epoch 34/100, Train Loss: 0.1843, Val Loss: 0.2138\n",
      "Epoch 35/100, Train Loss: 0.1797, Val Loss: 0.2118\n",
      "Epoch 36/100, Train Loss: 0.1778, Val Loss: 0.2098\n",
      "Epoch 37/100, Train Loss: 0.1746, Val Loss: 0.2085\n",
      "Epoch 38/100, Train Loss: 0.1754, Val Loss: 0.2079\n",
      "Epoch 39/100, Train Loss: 0.1744, Val Loss: 0.2088\n",
      "Epoch 40/100, Train Loss: 0.1670, Val Loss: 0.2093\n",
      "Epoch 41/100, Train Loss: 0.1724, Val Loss: 0.2093\n",
      "Epoch 42/100, Train Loss: 0.1700, Val Loss: 0.2088\n",
      "Epoch 43/100, Train Loss: 0.1720, Val Loss: 0.2078\n",
      "Epoch 44/100, Train Loss: 0.1731, Val Loss: 0.2066\n",
      "Epoch 45/100, Train Loss: 0.1664, Val Loss: 0.2053\n",
      "Epoch 46/100, Train Loss: 0.1656, Val Loss: 0.2042\n",
      "Epoch 47/100, Train Loss: 0.1657, Val Loss: 0.2033\n",
      "Epoch 48/100, Train Loss: 0.1650, Val Loss: 0.2026\n",
      "Epoch 49/100, Train Loss: 0.1668, Val Loss: 0.2020\n",
      "Epoch 50/100, Train Loss: 0.1678, Val Loss: 0.2014\n",
      "Epoch 51/100, Train Loss: 0.1627, Val Loss: 0.2009\n",
      "Epoch 52/100, Train Loss: 0.1568, Val Loss: 0.2004\n",
      "Epoch 53/100, Train Loss: 0.1608, Val Loss: 0.2000\n",
      "Epoch 54/100, Train Loss: 0.1588, Val Loss: 0.1996\n",
      "Epoch 55/100, Train Loss: 0.1594, Val Loss: 0.1992\n",
      "Epoch 56/100, Train Loss: 0.1624, Val Loss: 0.1988\n",
      "Epoch 57/100, Train Loss: 0.1599, Val Loss: 0.1982\n",
      "Epoch 58/100, Train Loss: 0.1558, Val Loss: 0.1975\n",
      "Epoch 59/100, Train Loss: 0.1585, Val Loss: 0.1967\n",
      "Epoch 60/100, Train Loss: 0.1548, Val Loss: 0.1958\n",
      "Epoch 61/100, Train Loss: 0.1599, Val Loss: 0.1948\n",
      "Epoch 62/100, Train Loss: 0.1551, Val Loss: 0.1938\n",
      "Epoch 63/100, Train Loss: 0.1539, Val Loss: 0.1927\n",
      "Epoch 64/100, Train Loss: 0.1498, Val Loss: 0.1918\n",
      "Epoch 65/100, Train Loss: 0.1487, Val Loss: 0.1910\n",
      "Epoch 66/100, Train Loss: 0.1535, Val Loss: 0.1904\n",
      "Epoch 67/100, Train Loss: 0.1521, Val Loss: 0.1895\n",
      "Epoch 68/100, Train Loss: 0.1487, Val Loss: 0.1885\n",
      "Epoch 69/100, Train Loss: 0.1481, Val Loss: 0.1875\n",
      "Epoch 70/100, Train Loss: 0.1457, Val Loss: 0.1862\n",
      "Epoch 71/100, Train Loss: 0.1439, Val Loss: 0.1851\n",
      "Epoch 72/100, Train Loss: 0.1463, Val Loss: 0.1841\n",
      "Epoch 73/100, Train Loss: 0.1454, Val Loss: 0.1829\n",
      "Epoch 74/100, Train Loss: 0.1425, Val Loss: 0.1819\n",
      "Epoch 75/100, Train Loss: 0.1376, Val Loss: 0.1809\n",
      "Epoch 76/100, Train Loss: 0.1428, Val Loss: 0.1798\n",
      "Epoch 77/100, Train Loss: 0.1356, Val Loss: 0.1785\n",
      "Epoch 78/100, Train Loss: 0.1372, Val Loss: 0.1772\n",
      "Epoch 79/100, Train Loss: 0.1362, Val Loss: 0.1759\n",
      "Epoch 80/100, Train Loss: 0.1367, Val Loss: 0.1751\n",
      "Epoch 81/100, Train Loss: 0.1334, Val Loss: 0.1746\n",
      "Epoch 82/100, Train Loss: 0.1302, Val Loss: 0.1744\n",
      "Epoch 83/100, Train Loss: 0.1309, Val Loss: 0.1737\n",
      "Epoch 84/100, Train Loss: 0.1302, Val Loss: 0.1727\n",
      "Epoch 85/100, Train Loss: 0.1274, Val Loss: 0.1716\n",
      "Epoch 86/100, Train Loss: 0.1330, Val Loss: 0.1711\n",
      "Epoch 87/100, Train Loss: 0.1306, Val Loss: 0.1698\n",
      "Epoch 88/100, Train Loss: 0.1286, Val Loss: 0.1685\n",
      "Epoch 89/100, Train Loss: 0.1258, Val Loss: 0.1674\n",
      "Epoch 90/100, Train Loss: 0.1288, Val Loss: 0.1665\n",
      "Epoch 91/100, Train Loss: 0.1239, Val Loss: 0.1658\n",
      "Epoch 92/100, Train Loss: 0.1233, Val Loss: 0.1654\n",
      "Epoch 93/100, Train Loss: 0.1276, Val Loss: 0.1653\n",
      "Epoch 94/100, Train Loss: 0.1241, Val Loss: 0.1647\n",
      "Epoch 95/100, Train Loss: 0.1223, Val Loss: 0.1644\n",
      "Epoch 96/100, Train Loss: 0.1234, Val Loss: 0.1640\n",
      "Epoch 97/100, Train Loss: 0.1224, Val Loss: 0.1630\n",
      "Epoch 98/100, Train Loss: 0.1231, Val Loss: 0.1619\n",
      "Epoch 99/100, Train Loss: 0.1237, Val Loss: 0.1605\n",
      "Epoch 100/100, Train Loss: 0.1208, Val Loss: 0.1592\n",
      "Best Validation Loss for 배: 0.1592\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aac8348e6c9e4bc2b78c60ab06d5f219",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "테스트 파일 추론 중:   0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Train Loss: 0.0573, Val Loss: 0.0526\n",
      "Epoch 2/100, Train Loss: 0.0517, Val Loss: 0.0480\n",
      "Epoch 3/100, Train Loss: 0.0469, Val Loss: 0.0431\n",
      "Epoch 4/100, Train Loss: 0.0420, Val Loss: 0.0382\n",
      "Epoch 5/100, Train Loss: 0.0372, Val Loss: 0.0335\n",
      "Epoch 6/100, Train Loss: 0.0324, Val Loss: 0.0285\n",
      "Epoch 7/100, Train Loss: 0.0274, Val Loss: 0.0236\n",
      "Epoch 8/100, Train Loss: 0.0224, Val Loss: 0.0186\n",
      "Epoch 9/100, Train Loss: 0.0174, Val Loss: 0.0136\n",
      "Epoch 10/100, Train Loss: 0.0123, Val Loss: 0.0089\n",
      "Epoch 11/100, Train Loss: 0.0091, Val Loss: 0.0085\n",
      "Epoch 12/100, Train Loss: 0.0084, Val Loss: 0.0070\n",
      "Epoch 13/100, Train Loss: 0.0066, Val Loss: 0.0046\n",
      "Epoch 14/100, Train Loss: 0.0041, Val Loss: 0.0041\n",
      "Epoch 15/100, Train Loss: 0.0043, Val Loss: 0.0045\n",
      "Epoch 16/100, Train Loss: 0.0045, Val Loss: 0.0038\n",
      "Epoch 17/100, Train Loss: 0.0040, Val Loss: 0.0048\n",
      "Epoch 18/100, Train Loss: 0.0048, Val Loss: 0.0048\n",
      "Epoch 19/100, Train Loss: 0.0045, Val Loss: 0.0038\n",
      "Epoch 20/100, Train Loss: 0.0033, Val Loss: 0.0021\n",
      "Epoch 21/100, Train Loss: 0.0015, Val Loss: 0.0007\n",
      "Epoch 22/100, Train Loss: 0.0011, Val Loss: 0.0020\n",
      "Epoch 23/100, Train Loss: 0.0022, Val Loss: 0.0024\n",
      "Epoch 24/100, Train Loss: 0.0024, Val Loss: 0.0017\n",
      "Epoch 25/100, Train Loss: 0.0015, Val Loss: 0.0011\n",
      "Epoch 26/100, Train Loss: 0.0009, Val Loss: 0.0009\n",
      "Epoch 27/100, Train Loss: 0.0010, Val Loss: 0.0012\n",
      "Epoch 28/100, Train Loss: 0.0012, Val Loss: 0.0011\n",
      "Epoch 29/100, Train Loss: 0.0010, Val Loss: 0.0006\n",
      "Epoch 30/100, Train Loss: 0.0005, Val Loss: 0.0007\n",
      "Epoch 31/100, Train Loss: 0.0007, Val Loss: 0.0009\n",
      "Epoch 32/100, Train Loss: 0.0009, Val Loss: 0.0007\n",
      "Epoch 33/100, Train Loss: 0.0005, Val Loss: 0.0007\n",
      "Epoch 34/100, Train Loss: 0.0008, Val Loss: 0.0009\n",
      "Epoch 35/100, Train Loss: 0.0008, Val Loss: 0.0004\n",
      "Epoch 36/100, Train Loss: 0.0003, Val Loss: 0.0005\n",
      "Epoch 37/100, Train Loss: 0.0006, Val Loss: 0.0004\n",
      "Epoch 38/100, Train Loss: 0.0004, Val Loss: 0.0006\n",
      "Epoch 39/100, Train Loss: 0.0006, Val Loss: 0.0005\n",
      "Epoch 40/100, Train Loss: 0.0005, Val Loss: 0.0002\n",
      "Epoch 41/100, Train Loss: 0.0003, Val Loss: 0.0005\n",
      "Epoch 42/100, Train Loss: 0.0004, Val Loss: 0.0003\n",
      "Epoch 43/100, Train Loss: 0.0003, Val Loss: 0.0003\n",
      "Epoch 44/100, Train Loss: 0.0003, Val Loss: 0.0003\n",
      "Epoch 45/100, Train Loss: 0.0003, Val Loss: 0.0002\n",
      "Epoch 46/100, Train Loss: 0.0002, Val Loss: 0.0001\n",
      "Epoch 47/100, Train Loss: 0.0002, Val Loss: 0.0003\n",
      "Epoch 48/100, Train Loss: 0.0002, Val Loss: 0.0003\n",
      "Epoch 49/100, Train Loss: 0.0003, Val Loss: 0.0004\n",
      "Epoch 50/100, Train Loss: 0.0004, Val Loss: 0.0001\n",
      "Epoch 51/100, Train Loss: 0.0002, Val Loss: 0.0003\n",
      "Epoch 52/100, Train Loss: 0.0002, Val Loss: 0.0002\n",
      "Epoch 53/100, Train Loss: 0.0002, Val Loss: 0.0001\n",
      "Epoch 54/100, Train Loss: 0.0002, Val Loss: 0.0003\n",
      "Epoch 55/100, Train Loss: 0.0002, Val Loss: 0.0002\n",
      "Epoch 56/100, Train Loss: 0.0002, Val Loss: 0.0002\n",
      "Epoch 57/100, Train Loss: 0.0003, Val Loss: 0.0002\n",
      "Epoch 58/100, Train Loss: 0.0002, Val Loss: 0.0004\n",
      "Epoch 59/100, Train Loss: 0.0003, Val Loss: 0.0002\n",
      "Epoch 60/100, Train Loss: 0.0002, Val Loss: 0.0002\n",
      "Epoch 61/100, Train Loss: 0.0002, Val Loss: 0.0003\n",
      "Epoch 62/100, Train Loss: 0.0003, Val Loss: 0.0002\n",
      "Epoch 63/100, Train Loss: 0.0002, Val Loss: 0.0002\n",
      "Epoch 64/100, Train Loss: 0.0002, Val Loss: 0.0003\n",
      "Epoch 65/100, Train Loss: 0.0003, Val Loss: 0.0002\n",
      "Epoch 66/100, Train Loss: 0.0002, Val Loss: 0.0003\n",
      "Epoch 67/100, Train Loss: 0.0002, Val Loss: 0.0002\n",
      "Epoch 68/100, Train Loss: 0.0002, Val Loss: 0.0003\n",
      "Epoch 69/100, Train Loss: 0.0002, Val Loss: 0.0003\n",
      "Epoch 70/100, Train Loss: 0.0003, Val Loss: 0.0003\n",
      "Epoch 71/100, Train Loss: 0.0002, Val Loss: 0.0003\n",
      "Epoch 72/100, Train Loss: 0.0002, Val Loss: 0.0002\n",
      "Epoch 73/100, Train Loss: 0.0002, Val Loss: 0.0001\n",
      "Epoch 74/100, Train Loss: 0.0001, Val Loss: 0.0002\n",
      "Epoch 75/100, Train Loss: 0.0002, Val Loss: 0.0002\n",
      "Epoch 76/100, Train Loss: 0.0003, Val Loss: 0.0002\n",
      "Epoch 77/100, Train Loss: 0.0002, Val Loss: 0.0003\n",
      "Epoch 78/100, Train Loss: 0.0003, Val Loss: 0.0002\n",
      "Epoch 79/100, Train Loss: 0.0002, Val Loss: 0.0002\n",
      "Epoch 80/100, Train Loss: 0.0001, Val Loss: 0.0002\n",
      "Epoch 81/100, Train Loss: 0.0002, Val Loss: 0.0002\n",
      "Epoch 82/100, Train Loss: 0.0002, Val Loss: 0.0002\n",
      "Epoch 83/100, Train Loss: 0.0002, Val Loss: 0.0002\n",
      "Epoch 84/100, Train Loss: 0.0002, Val Loss: 0.0003\n",
      "Epoch 85/100, Train Loss: 0.0002, Val Loss: 0.0002\n",
      "Epoch 86/100, Train Loss: 0.0002, Val Loss: 0.0001\n",
      "Epoch 87/100, Train Loss: 0.0001, Val Loss: 0.0002\n",
      "Epoch 88/100, Train Loss: 0.0001, Val Loss: 0.0003\n",
      "Epoch 89/100, Train Loss: 0.0003, Val Loss: 0.0002\n",
      "Epoch 90/100, Train Loss: 0.0002, Val Loss: 0.0002\n",
      "Epoch 91/100, Train Loss: 0.0002, Val Loss: 0.0003\n",
      "Epoch 92/100, Train Loss: 0.0002, Val Loss: 0.0003\n",
      "Epoch 93/100, Train Loss: 0.0003, Val Loss: 0.0002\n",
      "Epoch 94/100, Train Loss: 0.0002, Val Loss: 0.0003\n",
      "Epoch 95/100, Train Loss: 0.0003, Val Loss: 0.0001\n",
      "Epoch 96/100, Train Loss: 0.0002, Val Loss: 0.0003\n",
      "Epoch 97/100, Train Loss: 0.0002, Val Loss: 0.0003\n",
      "Epoch 98/100, Train Loss: 0.0003, Val Loss: 0.0002\n",
      "Epoch 99/100, Train Loss: 0.0002, Val Loss: 0.0003\n",
      "Epoch 100/100, Train Loss: 0.0002, Val Loss: 0.0003\n",
      "Best Validation Loss for 깐마늘(국산): 0.0001\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40845946e9cc424197bad4b5d6a0de88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "테스트 파일 추론 중:   0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Train Loss: 0.0721, Val Loss: 0.0674\n",
      "Epoch 2/100, Train Loss: 0.0649, Val Loss: 0.0603\n",
      "Epoch 3/100, Train Loss: 0.0576, Val Loss: 0.0530\n",
      "Epoch 4/100, Train Loss: 0.0502, Val Loss: 0.0457\n",
      "Epoch 5/100, Train Loss: 0.0435, Val Loss: 0.0397\n",
      "Epoch 6/100, Train Loss: 0.0380, Val Loss: 0.0341\n",
      "Epoch 7/100, Train Loss: 0.0323, Val Loss: 0.0280\n",
      "Epoch 8/100, Train Loss: 0.0260, Val Loss: 0.0214\n",
      "Epoch 9/100, Train Loss: 0.0189, Val Loss: 0.0153\n",
      "Epoch 10/100, Train Loss: 0.0126, Val Loss: 0.0096\n",
      "Epoch 11/100, Train Loss: 0.0077, Val Loss: 0.0063\n",
      "Epoch 12/100, Train Loss: 0.0068, Val Loss: 0.0079\n",
      "Epoch 13/100, Train Loss: 0.0097, Val Loss: 0.0096\n",
      "Epoch 14/100, Train Loss: 0.0111, Val Loss: 0.0089\n",
      "Epoch 15/100, Train Loss: 0.0099, Val Loss: 0.0069\n",
      "Epoch 16/100, Train Loss: 0.0074, Val Loss: 0.0051\n",
      "Epoch 17/100, Train Loss: 0.0055, Val Loss: 0.0048\n",
      "Epoch 18/100, Train Loss: 0.0050, Val Loss: 0.0055\n",
      "Epoch 19/100, Train Loss: 0.0052, Val Loss: 0.0061\n",
      "Epoch 20/100, Train Loss: 0.0054, Val Loss: 0.0059\n",
      "Epoch 21/100, Train Loss: 0.0050, Val Loss: 0.0050\n",
      "Epoch 22/100, Train Loss: 0.0044, Val Loss: 0.0041\n",
      "Epoch 23/100, Train Loss: 0.0038, Val Loss: 0.0033\n",
      "Epoch 24/100, Train Loss: 0.0034, Val Loss: 0.0027\n",
      "Epoch 25/100, Train Loss: 0.0032, Val Loss: 0.0026\n",
      "Epoch 26/100, Train Loss: 0.0032, Val Loss: 0.0026\n",
      "Epoch 27/100, Train Loss: 0.0030, Val Loss: 0.0025\n",
      "Epoch 28/100, Train Loss: 0.0026, Val Loss: 0.0024\n",
      "Epoch 29/100, Train Loss: 0.0023, Val Loss: 0.0024\n",
      "Epoch 30/100, Train Loss: 0.0024, Val Loss: 0.0026\n",
      "Epoch 31/100, Train Loss: 0.0023, Val Loss: 0.0023\n",
      "Epoch 32/100, Train Loss: 0.0020, Val Loss: 0.0019\n",
      "Epoch 33/100, Train Loss: 0.0017, Val Loss: 0.0015\n",
      "Epoch 34/100, Train Loss: 0.0016, Val Loss: 0.0015\n",
      "Epoch 35/100, Train Loss: 0.0017, Val Loss: 0.0013\n",
      "Epoch 36/100, Train Loss: 0.0015, Val Loss: 0.0013\n",
      "Epoch 37/100, Train Loss: 0.0013, Val Loss: 0.0015\n",
      "Epoch 38/100, Train Loss: 0.0013, Val Loss: 0.0014\n",
      "Epoch 39/100, Train Loss: 0.0012, Val Loss: 0.0012\n",
      "Epoch 40/100, Train Loss: 0.0011, Val Loss: 0.0012\n",
      "Epoch 41/100, Train Loss: 0.0011, Val Loss: 0.0011\n",
      "Epoch 42/100, Train Loss: 0.0010, Val Loss: 0.0011\n",
      "Epoch 43/100, Train Loss: 0.0010, Val Loss: 0.0012\n",
      "Epoch 44/100, Train Loss: 0.0009, Val Loss: 0.0011\n",
      "Epoch 45/100, Train Loss: 0.0009, Val Loss: 0.0010\n",
      "Epoch 46/100, Train Loss: 0.0009, Val Loss: 0.0010\n",
      "Epoch 47/100, Train Loss: 0.0008, Val Loss: 0.0010\n",
      "Epoch 48/100, Train Loss: 0.0008, Val Loss: 0.0010\n",
      "Epoch 49/100, Train Loss: 0.0008, Val Loss: 0.0009\n",
      "Epoch 50/100, Train Loss: 0.0008, Val Loss: 0.0008\n",
      "Epoch 51/100, Train Loss: 0.0007, Val Loss: 0.0009\n",
      "Epoch 52/100, Train Loss: 0.0007, Val Loss: 0.0008\n",
      "Epoch 53/100, Train Loss: 0.0007, Val Loss: 0.0008\n",
      "Epoch 54/100, Train Loss: 0.0006, Val Loss: 0.0008\n",
      "Epoch 55/100, Train Loss: 0.0006, Val Loss: 0.0007\n",
      "Epoch 56/100, Train Loss: 0.0006, Val Loss: 0.0007\n",
      "Epoch 57/100, Train Loss: 0.0006, Val Loss: 0.0007\n",
      "Epoch 58/100, Train Loss: 0.0006, Val Loss: 0.0007\n",
      "Epoch 59/100, Train Loss: 0.0006, Val Loss: 0.0007\n",
      "Epoch 60/100, Train Loss: 0.0006, Val Loss: 0.0007\n",
      "Epoch 61/100, Train Loss: 0.0006, Val Loss: 0.0007\n",
      "Epoch 62/100, Train Loss: 0.0006, Val Loss: 0.0006\n",
      "Epoch 63/100, Train Loss: 0.0006, Val Loss: 0.0006\n",
      "Epoch 64/100, Train Loss: 0.0006, Val Loss: 0.0006\n",
      "Epoch 65/100, Train Loss: 0.0005, Val Loss: 0.0006\n",
      "Epoch 66/100, Train Loss: 0.0006, Val Loss: 0.0006\n",
      "Epoch 67/100, Train Loss: 0.0005, Val Loss: 0.0006\n",
      "Epoch 68/100, Train Loss: 0.0005, Val Loss: 0.0006\n",
      "Epoch 69/100, Train Loss: 0.0005, Val Loss: 0.0006\n",
      "Epoch 70/100, Train Loss: 0.0005, Val Loss: 0.0006\n",
      "Epoch 71/100, Train Loss: 0.0005, Val Loss: 0.0006\n",
      "Epoch 72/100, Train Loss: 0.0005, Val Loss: 0.0005\n",
      "Epoch 73/100, Train Loss: 0.0005, Val Loss: 0.0005\n",
      "Epoch 74/100, Train Loss: 0.0005, Val Loss: 0.0006\n",
      "Epoch 75/100, Train Loss: 0.0005, Val Loss: 0.0005\n",
      "Epoch 76/100, Train Loss: 0.0004, Val Loss: 0.0006\n",
      "Epoch 77/100, Train Loss: 0.0004, Val Loss: 0.0005\n",
      "Epoch 78/100, Train Loss: 0.0004, Val Loss: 0.0005\n",
      "Epoch 79/100, Train Loss: 0.0004, Val Loss: 0.0005\n",
      "Epoch 80/100, Train Loss: 0.0004, Val Loss: 0.0005\n",
      "Epoch 81/100, Train Loss: 0.0004, Val Loss: 0.0005\n",
      "Epoch 82/100, Train Loss: 0.0004, Val Loss: 0.0004\n",
      "Epoch 83/100, Train Loss: 0.0004, Val Loss: 0.0004\n",
      "Epoch 84/100, Train Loss: 0.0004, Val Loss: 0.0004\n",
      "Epoch 85/100, Train Loss: 0.0003, Val Loss: 0.0004\n",
      "Epoch 86/100, Train Loss: 0.0003, Val Loss: 0.0004\n",
      "Epoch 87/100, Train Loss: 0.0004, Val Loss: 0.0005\n",
      "Epoch 88/100, Train Loss: 0.0004, Val Loss: 0.0005\n",
      "Epoch 89/100, Train Loss: 0.0004, Val Loss: 0.0005\n",
      "Epoch 90/100, Train Loss: 0.0004, Val Loss: 0.0006\n",
      "Epoch 91/100, Train Loss: 0.0005, Val Loss: 0.0007\n",
      "Epoch 92/100, Train Loss: 0.0006, Val Loss: 0.0004\n",
      "Epoch 93/100, Train Loss: 0.0005, Val Loss: 0.0005\n",
      "Epoch 94/100, Train Loss: 0.0005, Val Loss: 0.0004\n",
      "Epoch 95/100, Train Loss: 0.0004, Val Loss: 0.0004\n",
      "Epoch 96/100, Train Loss: 0.0003, Val Loss: 0.0004\n",
      "Epoch 97/100, Train Loss: 0.0004, Val Loss: 0.0005\n",
      "Epoch 98/100, Train Loss: 0.0004, Val Loss: 0.0005\n",
      "Epoch 99/100, Train Loss: 0.0004, Val Loss: 0.0005\n",
      "Epoch 100/100, Train Loss: 0.0004, Val Loss: 0.0005\n",
      "Best Validation Loss for 무: 0.0004\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44207e1bcfbb47e280db64596630dab4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "테스트 파일 추론 중:   0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Train Loss: 0.3169, Val Loss: 0.3397\n",
      "Epoch 2/100, Train Loss: 0.3142, Val Loss: 0.3347\n",
      "Epoch 3/100, Train Loss: 0.3101, Val Loss: 0.3298\n",
      "Epoch 4/100, Train Loss: 0.2989, Val Loss: 0.3248\n",
      "Epoch 5/100, Train Loss: 0.3026, Val Loss: 0.3199\n",
      "Epoch 6/100, Train Loss: 0.2959, Val Loss: 0.3152\n",
      "Epoch 7/100, Train Loss: 0.2927, Val Loss: 0.3107\n",
      "Epoch 8/100, Train Loss: 0.2888, Val Loss: 0.3062\n",
      "Epoch 9/100, Train Loss: 0.2846, Val Loss: 0.3017\n",
      "Epoch 10/100, Train Loss: 0.2755, Val Loss: 0.2972\n",
      "Epoch 11/100, Train Loss: 0.2661, Val Loss: 0.2925\n",
      "Epoch 12/100, Train Loss: 0.2634, Val Loss: 0.2876\n",
      "Epoch 13/100, Train Loss: 0.2564, Val Loss: 0.2826\n",
      "Epoch 14/100, Train Loss: 0.2596, Val Loss: 0.2773\n",
      "Epoch 15/100, Train Loss: 0.2500, Val Loss: 0.2718\n",
      "Epoch 16/100, Train Loss: 0.2344, Val Loss: 0.2659\n",
      "Epoch 17/100, Train Loss: 0.2326, Val Loss: 0.2596\n",
      "Epoch 18/100, Train Loss: 0.2404, Val Loss: 0.2531\n",
      "Epoch 19/100, Train Loss: 0.2280, Val Loss: 0.2461\n",
      "Epoch 20/100, Train Loss: 0.2202, Val Loss: 0.2385\n",
      "Epoch 21/100, Train Loss: 0.2112, Val Loss: 0.2310\n",
      "Epoch 22/100, Train Loss: 0.2049, Val Loss: 0.2242\n",
      "Epoch 23/100, Train Loss: 0.1992, Val Loss: 0.2188\n",
      "Epoch 24/100, Train Loss: 0.1958, Val Loss: 0.2141\n",
      "Epoch 25/100, Train Loss: 0.1936, Val Loss: 0.2102\n",
      "Epoch 26/100, Train Loss: 0.1941, Val Loss: 0.2076\n",
      "Epoch 27/100, Train Loss: 0.1897, Val Loss: 0.2057\n",
      "Epoch 28/100, Train Loss: 0.1916, Val Loss: 0.2055\n",
      "Epoch 29/100, Train Loss: 0.1909, Val Loss: 0.2056\n",
      "Epoch 30/100, Train Loss: 0.1901, Val Loss: 0.2058\n",
      "Epoch 31/100, Train Loss: 0.1818, Val Loss: 0.2061\n",
      "Epoch 32/100, Train Loss: 0.1851, Val Loss: 0.2063\n",
      "Epoch 33/100, Train Loss: 0.1802, Val Loss: 0.2066\n",
      "Epoch 34/100, Train Loss: 0.1904, Val Loss: 0.2071\n",
      "Epoch 35/100, Train Loss: 0.1897, Val Loss: 0.2075\n",
      "Epoch 36/100, Train Loss: 0.1881, Val Loss: 0.2076\n",
      "Epoch 37/100, Train Loss: 0.1821, Val Loss: 0.2073\n",
      "Epoch 38/100, Train Loss: 0.1859, Val Loss: 0.2068\n",
      "Epoch 39/100, Train Loss: 0.1838, Val Loss: 0.2064\n",
      "Epoch 40/100, Train Loss: 0.1800, Val Loss: 0.2061\n",
      "Epoch 41/100, Train Loss: 0.1914, Val Loss: 0.2059\n",
      "Epoch 42/100, Train Loss: 0.1857, Val Loss: 0.2056\n",
      "Epoch 43/100, Train Loss: 0.1805, Val Loss: 0.2054\n",
      "Epoch 44/100, Train Loss: 0.1803, Val Loss: 0.2052\n",
      "Epoch 45/100, Train Loss: 0.1777, Val Loss: 0.2050\n",
      "Epoch 46/100, Train Loss: 0.1771, Val Loss: 0.2048\n",
      "Epoch 47/100, Train Loss: 0.1793, Val Loss: 0.2047\n",
      "Epoch 48/100, Train Loss: 0.1781, Val Loss: 0.2047\n",
      "Epoch 49/100, Train Loss: 0.1794, Val Loss: 0.2047\n",
      "Epoch 50/100, Train Loss: 0.1807, Val Loss: 0.2048\n",
      "Epoch 51/100, Train Loss: 0.1856, Val Loss: 0.2047\n",
      "Epoch 52/100, Train Loss: 0.1832, Val Loss: 0.2046\n",
      "Epoch 53/100, Train Loss: 0.1753, Val Loss: 0.2044\n",
      "Epoch 54/100, Train Loss: 0.1754, Val Loss: 0.2042\n",
      "Epoch 55/100, Train Loss: 0.1731, Val Loss: 0.2042\n",
      "Epoch 56/100, Train Loss: 0.1761, Val Loss: 0.2041\n",
      "Epoch 57/100, Train Loss: 0.1744, Val Loss: 0.2040\n",
      "Epoch 58/100, Train Loss: 0.1748, Val Loss: 0.2037\n",
      "Epoch 59/100, Train Loss: 0.1777, Val Loss: 0.2035\n",
      "Epoch 60/100, Train Loss: 0.1766, Val Loss: 0.2032\n",
      "Epoch 61/100, Train Loss: 0.1714, Val Loss: 0.2030\n",
      "Epoch 62/100, Train Loss: 0.1761, Val Loss: 0.2028\n",
      "Epoch 63/100, Train Loss: 0.1737, Val Loss: 0.2025\n",
      "Epoch 64/100, Train Loss: 0.1747, Val Loss: 0.2022\n",
      "Epoch 65/100, Train Loss: 0.1713, Val Loss: 0.2018\n",
      "Epoch 66/100, Train Loss: 0.1703, Val Loss: 0.2013\n",
      "Epoch 67/100, Train Loss: 0.1634, Val Loss: 0.2011\n",
      "Epoch 68/100, Train Loss: 0.1745, Val Loss: 0.2009\n",
      "Epoch 69/100, Train Loss: 0.1692, Val Loss: 0.2005\n",
      "Epoch 70/100, Train Loss: 0.1663, Val Loss: 0.1999\n",
      "Epoch 71/100, Train Loss: 0.1634, Val Loss: 0.1993\n",
      "Epoch 72/100, Train Loss: 0.1682, Val Loss: 0.1986\n",
      "Epoch 73/100, Train Loss: 0.1692, Val Loss: 0.1980\n",
      "Epoch 74/100, Train Loss: 0.1712, Val Loss: 0.1976\n",
      "Epoch 75/100, Train Loss: 0.1661, Val Loss: 0.1970\n",
      "Epoch 76/100, Train Loss: 0.1581, Val Loss: 0.1962\n",
      "Epoch 77/100, Train Loss: 0.1631, Val Loss: 0.1960\n",
      "Epoch 78/100, Train Loss: 0.1526, Val Loss: 0.1958\n",
      "Epoch 79/100, Train Loss: 0.1659, Val Loss: 0.1958\n",
      "Epoch 80/100, Train Loss: 0.1649, Val Loss: 0.1954\n",
      "Epoch 81/100, Train Loss: 0.1612, Val Loss: 0.1945\n",
      "Epoch 82/100, Train Loss: 0.1570, Val Loss: 0.1936\n",
      "Epoch 83/100, Train Loss: 0.1642, Val Loss: 0.1929\n",
      "Epoch 84/100, Train Loss: 0.1611, Val Loss: 0.1921\n",
      "Epoch 85/100, Train Loss: 0.1547, Val Loss: 0.1913\n",
      "Epoch 86/100, Train Loss: 0.1581, Val Loss: 0.1906\n",
      "Epoch 87/100, Train Loss: 0.1557, Val Loss: 0.1900\n",
      "Epoch 88/100, Train Loss: 0.1575, Val Loss: 0.1894\n",
      "Epoch 89/100, Train Loss: 0.1567, Val Loss: 0.1887\n",
      "Epoch 90/100, Train Loss: 0.1561, Val Loss: 0.1880\n",
      "Epoch 91/100, Train Loss: 0.1508, Val Loss: 0.1872\n",
      "Epoch 92/100, Train Loss: 0.1481, Val Loss: 0.1862\n",
      "Epoch 93/100, Train Loss: 0.1514, Val Loss: 0.1856\n",
      "Epoch 94/100, Train Loss: 0.1480, Val Loss: 0.1848\n",
      "Epoch 95/100, Train Loss: 0.1473, Val Loss: 0.1841\n",
      "Epoch 96/100, Train Loss: 0.1450, Val Loss: 0.1834\n",
      "Epoch 97/100, Train Loss: 0.1366, Val Loss: 0.1824\n",
      "Epoch 98/100, Train Loss: 0.1465, Val Loss: 0.1814\n",
      "Epoch 99/100, Train Loss: 0.1405, Val Loss: 0.1802\n",
      "Epoch 100/100, Train Loss: 0.1436, Val Loss: 0.1789\n",
      "Best Validation Loss for 상추: 0.1789\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25b2ebda212a43ff895deaeb771ab306",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "테스트 파일 추론 중:   0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Train Loss: 0.2765, Val Loss: 0.2463\n",
      "Epoch 2/100, Train Loss: 0.2636, Val Loss: 0.2385\n",
      "Epoch 3/100, Train Loss: 0.2561, Val Loss: 0.2310\n",
      "Epoch 4/100, Train Loss: 0.2514, Val Loss: 0.2236\n",
      "Epoch 5/100, Train Loss: 0.2360, Val Loss: 0.2164\n",
      "Epoch 6/100, Train Loss: 0.2313, Val Loss: 0.2092\n",
      "Epoch 7/100, Train Loss: 0.2232, Val Loss: 0.2020\n",
      "Epoch 8/100, Train Loss: 0.2080, Val Loss: 0.1947\n",
      "Epoch 9/100, Train Loss: 0.2057, Val Loss: 0.1874\n",
      "Epoch 10/100, Train Loss: 0.1956, Val Loss: 0.1802\n",
      "Epoch 11/100, Train Loss: 0.1902, Val Loss: 0.1728\n",
      "Epoch 12/100, Train Loss: 0.1845, Val Loss: 0.1654\n",
      "Epoch 13/100, Train Loss: 0.1710, Val Loss: 0.1587\n",
      "Epoch 14/100, Train Loss: 0.1584, Val Loss: 0.1527\n",
      "Epoch 15/100, Train Loss: 0.1554, Val Loss: 0.1466\n",
      "Epoch 16/100, Train Loss: 0.1539, Val Loss: 0.1420\n",
      "Epoch 17/100, Train Loss: 0.1431, Val Loss: 0.1384\n",
      "Epoch 18/100, Train Loss: 0.1456, Val Loss: 0.1361\n",
      "Epoch 19/100, Train Loss: 0.1439, Val Loss: 0.1349\n",
      "Epoch 20/100, Train Loss: 0.1456, Val Loss: 0.1347\n",
      "Epoch 21/100, Train Loss: 0.1435, Val Loss: 0.1348\n",
      "Epoch 22/100, Train Loss: 0.1451, Val Loss: 0.1350\n",
      "Epoch 23/100, Train Loss: 0.1446, Val Loss: 0.1348\n",
      "Epoch 24/100, Train Loss: 0.1429, Val Loss: 0.1342\n",
      "Epoch 25/100, Train Loss: 0.1496, Val Loss: 0.1336\n",
      "Epoch 26/100, Train Loss: 0.1416, Val Loss: 0.1331\n",
      "Epoch 27/100, Train Loss: 0.1500, Val Loss: 0.1326\n",
      "Epoch 28/100, Train Loss: 0.1426, Val Loss: 0.1322\n",
      "Epoch 29/100, Train Loss: 0.1433, Val Loss: 0.1318\n",
      "Epoch 30/100, Train Loss: 0.1380, Val Loss: 0.1314\n",
      "Epoch 31/100, Train Loss: 0.1395, Val Loss: 0.1310\n",
      "Epoch 32/100, Train Loss: 0.1370, Val Loss: 0.1306\n",
      "Epoch 33/100, Train Loss: 0.1460, Val Loss: 0.1302\n",
      "Epoch 34/100, Train Loss: 0.1415, Val Loss: 0.1299\n",
      "Epoch 35/100, Train Loss: 0.1350, Val Loss: 0.1295\n",
      "Epoch 36/100, Train Loss: 0.1418, Val Loss: 0.1291\n",
      "Epoch 37/100, Train Loss: 0.1363, Val Loss: 0.1288\n",
      "Epoch 38/100, Train Loss: 0.1323, Val Loss: 0.1285\n",
      "Epoch 39/100, Train Loss: 0.1302, Val Loss: 0.1284\n",
      "Epoch 40/100, Train Loss: 0.1342, Val Loss: 0.1283\n",
      "Epoch 41/100, Train Loss: 0.1244, Val Loss: 0.1280\n",
      "Epoch 42/100, Train Loss: 0.1356, Val Loss: 0.1276\n",
      "Epoch 43/100, Train Loss: 0.1282, Val Loss: 0.1272\n",
      "Epoch 44/100, Train Loss: 0.1307, Val Loss: 0.1268\n",
      "Epoch 45/100, Train Loss: 0.1314, Val Loss: 0.1265\n",
      "Epoch 46/100, Train Loss: 0.1297, Val Loss: 0.1262\n",
      "Epoch 47/100, Train Loss: 0.1258, Val Loss: 0.1258\n",
      "Epoch 48/100, Train Loss: 0.1277, Val Loss: 0.1254\n",
      "Epoch 49/100, Train Loss: 0.1249, Val Loss: 0.1250\n",
      "Epoch 50/100, Train Loss: 0.1303, Val Loss: 0.1247\n",
      "Epoch 51/100, Train Loss: 0.1235, Val Loss: 0.1243\n",
      "Epoch 52/100, Train Loss: 0.1271, Val Loss: 0.1238\n",
      "Epoch 53/100, Train Loss: 0.1210, Val Loss: 0.1234\n",
      "Epoch 54/100, Train Loss: 0.1214, Val Loss: 0.1230\n",
      "Epoch 55/100, Train Loss: 0.1216, Val Loss: 0.1226\n",
      "Epoch 56/100, Train Loss: 0.1191, Val Loss: 0.1222\n",
      "Epoch 57/100, Train Loss: 0.1210, Val Loss: 0.1217\n",
      "Epoch 58/100, Train Loss: 0.1190, Val Loss: 0.1212\n",
      "Epoch 59/100, Train Loss: 0.1167, Val Loss: 0.1207\n",
      "Epoch 60/100, Train Loss: 0.1183, Val Loss: 0.1201\n",
      "Epoch 61/100, Train Loss: 0.1148, Val Loss: 0.1195\n",
      "Epoch 62/100, Train Loss: 0.1173, Val Loss: 0.1188\n",
      "Epoch 63/100, Train Loss: 0.1203, Val Loss: 0.1181\n",
      "Epoch 64/100, Train Loss: 0.1166, Val Loss: 0.1177\n",
      "Epoch 65/100, Train Loss: 0.1133, Val Loss: 0.1171\n",
      "Epoch 66/100, Train Loss: 0.1129, Val Loss: 0.1161\n",
      "Epoch 67/100, Train Loss: 0.1126, Val Loss: 0.1152\n",
      "Epoch 68/100, Train Loss: 0.1157, Val Loss: 0.1147\n",
      "Epoch 69/100, Train Loss: 0.1076, Val Loss: 0.1141\n",
      "Epoch 70/100, Train Loss: 0.1041, Val Loss: 0.1133\n",
      "Epoch 71/100, Train Loss: 0.1069, Val Loss: 0.1120\n",
      "Epoch 72/100, Train Loss: 0.1058, Val Loss: 0.1109\n",
      "Epoch 73/100, Train Loss: 0.1064, Val Loss: 0.1096\n",
      "Epoch 74/100, Train Loss: 0.1010, Val Loss: 0.1085\n",
      "Epoch 75/100, Train Loss: 0.1024, Val Loss: 0.1076\n",
      "Epoch 76/100, Train Loss: 0.1029, Val Loss: 0.1065\n",
      "Epoch 77/100, Train Loss: 0.1027, Val Loss: 0.1051\n",
      "Epoch 78/100, Train Loss: 0.1014, Val Loss: 0.1040\n",
      "Epoch 79/100, Train Loss: 0.0997, Val Loss: 0.1032\n",
      "Epoch 80/100, Train Loss: 0.0951, Val Loss: 0.1024\n",
      "Epoch 81/100, Train Loss: 0.0998, Val Loss: 0.1016\n",
      "Epoch 82/100, Train Loss: 0.1019, Val Loss: 0.1000\n",
      "Epoch 83/100, Train Loss: 0.0957, Val Loss: 0.0988\n",
      "Epoch 84/100, Train Loss: 0.0934, Val Loss: 0.0978\n",
      "Epoch 85/100, Train Loss: 0.0945, Val Loss: 0.0966\n",
      "Epoch 86/100, Train Loss: 0.0939, Val Loss: 0.0952\n",
      "Epoch 87/100, Train Loss: 0.0896, Val Loss: 0.0928\n",
      "Epoch 88/100, Train Loss: 0.0891, Val Loss: 0.0917\n",
      "Epoch 89/100, Train Loss: 0.0940, Val Loss: 0.0919\n",
      "Epoch 90/100, Train Loss: 0.0901, Val Loss: 0.0913\n",
      "Epoch 91/100, Train Loss: 0.0873, Val Loss: 0.0894\n",
      "Epoch 92/100, Train Loss: 0.0867, Val Loss: 0.0876\n",
      "Epoch 93/100, Train Loss: 0.0852, Val Loss: 0.0870\n",
      "Epoch 94/100, Train Loss: 0.0873, Val Loss: 0.0871\n",
      "Epoch 95/100, Train Loss: 0.0828, Val Loss: 0.0868\n",
      "Epoch 96/100, Train Loss: 0.0835, Val Loss: 0.0845\n",
      "Epoch 97/100, Train Loss: 0.0819, Val Loss: 0.0831\n",
      "Epoch 98/100, Train Loss: 0.0808, Val Loss: 0.0830\n",
      "Epoch 99/100, Train Loss: 0.0806, Val Loss: 0.0807\n",
      "Epoch 100/100, Train Loss: 0.0780, Val Loss: 0.0794\n",
      "Best Validation Loss for 배추: 0.0794\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df615ac8be644e4aa542aa114dacae77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "테스트 파일 추론 중:   0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Train Loss: 0.4979, Val Loss: 0.4905\n",
      "Epoch 2/100, Train Loss: 0.4855, Val Loss: 0.4816\n",
      "Epoch 3/100, Train Loss: 0.4735, Val Loss: 0.4726\n",
      "Epoch 4/100, Train Loss: 0.4659, Val Loss: 0.4632\n",
      "Epoch 5/100, Train Loss: 0.4471, Val Loss: 0.4537\n",
      "Epoch 6/100, Train Loss: 0.4458, Val Loss: 0.4438\n",
      "Epoch 7/100, Train Loss: 0.4334, Val Loss: 0.4333\n",
      "Epoch 8/100, Train Loss: 0.4173, Val Loss: 0.4222\n",
      "Epoch 9/100, Train Loss: 0.4091, Val Loss: 0.4102\n",
      "Epoch 10/100, Train Loss: 0.3939, Val Loss: 0.3975\n",
      "Epoch 11/100, Train Loss: 0.3852, Val Loss: 0.3843\n",
      "Epoch 12/100, Train Loss: 0.3640, Val Loss: 0.3699\n",
      "Epoch 13/100, Train Loss: 0.3502, Val Loss: 0.3544\n",
      "Epoch 14/100, Train Loss: 0.3340, Val Loss: 0.3372\n",
      "Epoch 15/100, Train Loss: 0.3123, Val Loss: 0.3186\n",
      "Epoch 16/100, Train Loss: 0.2971, Val Loss: 0.2985\n",
      "Epoch 17/100, Train Loss: 0.2732, Val Loss: 0.2766\n",
      "Epoch 18/100, Train Loss: 0.2486, Val Loss: 0.2533\n",
      "Epoch 19/100, Train Loss: 0.2286, Val Loss: 0.2313\n",
      "Epoch 20/100, Train Loss: 0.2057, Val Loss: 0.2105\n",
      "Epoch 21/100, Train Loss: 0.1876, Val Loss: 0.1921\n",
      "Epoch 22/100, Train Loss: 0.1823, Val Loss: 0.1817\n",
      "Epoch 23/100, Train Loss: 0.1824, Val Loss: 0.1757\n",
      "Epoch 24/100, Train Loss: 0.1854, Val Loss: 0.1706\n",
      "Epoch 25/100, Train Loss: 0.1817, Val Loss: 0.1661\n",
      "Epoch 26/100, Train Loss: 0.1761, Val Loss: 0.1630\n",
      "Epoch 27/100, Train Loss: 0.1705, Val Loss: 0.1614\n",
      "Epoch 28/100, Train Loss: 0.1590, Val Loss: 0.1604\n",
      "Epoch 29/100, Train Loss: 0.1634, Val Loss: 0.1597\n",
      "Epoch 30/100, Train Loss: 0.1584, Val Loss: 0.1596\n",
      "Epoch 31/100, Train Loss: 0.1536, Val Loss: 0.1591\n",
      "Epoch 32/100, Train Loss: 0.1543, Val Loss: 0.1584\n",
      "Epoch 33/100, Train Loss: 0.1483, Val Loss: 0.1575\n",
      "Epoch 34/100, Train Loss: 0.1477, Val Loss: 0.1559\n",
      "Epoch 35/100, Train Loss: 0.1481, Val Loss: 0.1536\n",
      "Epoch 36/100, Train Loss: 0.1457, Val Loss: 0.1510\n",
      "Epoch 37/100, Train Loss: 0.1409, Val Loss: 0.1482\n",
      "Epoch 38/100, Train Loss: 0.1475, Val Loss: 0.1455\n",
      "Epoch 39/100, Train Loss: 0.1384, Val Loss: 0.1432\n",
      "Epoch 40/100, Train Loss: 0.1369, Val Loss: 0.1415\n",
      "Epoch 41/100, Train Loss: 0.1438, Val Loss: 0.1401\n",
      "Epoch 42/100, Train Loss: 0.1404, Val Loss: 0.1392\n",
      "Epoch 43/100, Train Loss: 0.1366, Val Loss: 0.1384\n",
      "Epoch 44/100, Train Loss: 0.1370, Val Loss: 0.1375\n",
      "Epoch 45/100, Train Loss: 0.1368, Val Loss: 0.1363\n",
      "Epoch 46/100, Train Loss: 0.1305, Val Loss: 0.1353\n",
      "Epoch 47/100, Train Loss: 0.1325, Val Loss: 0.1340\n",
      "Epoch 48/100, Train Loss: 0.1329, Val Loss: 0.1328\n",
      "Epoch 49/100, Train Loss: 0.1308, Val Loss: 0.1317\n",
      "Epoch 50/100, Train Loss: 0.1284, Val Loss: 0.1308\n",
      "Epoch 51/100, Train Loss: 0.1297, Val Loss: 0.1299\n",
      "Epoch 52/100, Train Loss: 0.1250, Val Loss: 0.1288\n",
      "Epoch 53/100, Train Loss: 0.1268, Val Loss: 0.1276\n",
      "Epoch 54/100, Train Loss: 0.1300, Val Loss: 0.1265\n",
      "Epoch 55/100, Train Loss: 0.1247, Val Loss: 0.1258\n",
      "Epoch 56/100, Train Loss: 0.1236, Val Loss: 0.1248\n",
      "Epoch 57/100, Train Loss: 0.1225, Val Loss: 0.1239\n",
      "Epoch 58/100, Train Loss: 0.1200, Val Loss: 0.1228\n",
      "Epoch 59/100, Train Loss: 0.1164, Val Loss: 0.1215\n",
      "Epoch 60/100, Train Loss: 0.1189, Val Loss: 0.1199\n",
      "Epoch 61/100, Train Loss: 0.1185, Val Loss: 0.1185\n",
      "Epoch 62/100, Train Loss: 0.1130, Val Loss: 0.1180\n",
      "Epoch 63/100, Train Loss: 0.1124, Val Loss: 0.1173\n",
      "Epoch 64/100, Train Loss: 0.1106, Val Loss: 0.1163\n",
      "Epoch 65/100, Train Loss: 0.1136, Val Loss: 0.1151\n",
      "Epoch 66/100, Train Loss: 0.1092, Val Loss: 0.1144\n",
      "Epoch 67/100, Train Loss: 0.1115, Val Loss: 0.1137\n",
      "Epoch 68/100, Train Loss: 0.1056, Val Loss: 0.1127\n",
      "Epoch 69/100, Train Loss: 0.1060, Val Loss: 0.1116\n",
      "Epoch 70/100, Train Loss: 0.1049, Val Loss: 0.1110\n",
      "Epoch 71/100, Train Loss: 0.1049, Val Loss: 0.1104\n",
      "Epoch 72/100, Train Loss: 0.1002, Val Loss: 0.1095\n",
      "Epoch 73/100, Train Loss: 0.1000, Val Loss: 0.1084\n",
      "Epoch 74/100, Train Loss: 0.1003, Val Loss: 0.1068\n",
      "Epoch 75/100, Train Loss: 0.0978, Val Loss: 0.1051\n",
      "Epoch 76/100, Train Loss: 0.0951, Val Loss: 0.1044\n",
      "Epoch 77/100, Train Loss: 0.0933, Val Loss: 0.1039\n",
      "Epoch 78/100, Train Loss: 0.0943, Val Loss: 0.1032\n",
      "Epoch 79/100, Train Loss: 0.0870, Val Loss: 0.1016\n",
      "Epoch 80/100, Train Loss: 0.0874, Val Loss: 0.0996\n",
      "Epoch 81/100, Train Loss: 0.0887, Val Loss: 0.0987\n",
      "Epoch 82/100, Train Loss: 0.0858, Val Loss: 0.0975\n",
      "Epoch 83/100, Train Loss: 0.0820, Val Loss: 0.0961\n",
      "Epoch 84/100, Train Loss: 0.0806, Val Loss: 0.0940\n",
      "Epoch 85/100, Train Loss: 0.0802, Val Loss: 0.0928\n",
      "Epoch 86/100, Train Loss: 0.0781, Val Loss: 0.0919\n",
      "Epoch 87/100, Train Loss: 0.0754, Val Loss: 0.0910\n",
      "Epoch 88/100, Train Loss: 0.0774, Val Loss: 0.0894\n",
      "Epoch 89/100, Train Loss: 0.0763, Val Loss: 0.0876\n",
      "Epoch 90/100, Train Loss: 0.0727, Val Loss: 0.0858\n",
      "Epoch 91/100, Train Loss: 0.0738, Val Loss: 0.0847\n",
      "Epoch 92/100, Train Loss: 0.0714, Val Loss: 0.0833\n",
      "Epoch 93/100, Train Loss: 0.0719, Val Loss: 0.0818\n",
      "Epoch 94/100, Train Loss: 0.0708, Val Loss: 0.0802\n",
      "Epoch 95/100, Train Loss: 0.0684, Val Loss: 0.0795\n",
      "Epoch 96/100, Train Loss: 0.0676, Val Loss: 0.0776\n",
      "Epoch 97/100, Train Loss: 0.0679, Val Loss: 0.0758\n",
      "Epoch 98/100, Train Loss: 0.0685, Val Loss: 0.0748\n",
      "Epoch 99/100, Train Loss: 0.0660, Val Loss: 0.0748\n",
      "Epoch 100/100, Train Loss: 0.0666, Val Loss: 0.0739\n",
      "Best Validation Loss for 양파: 0.0739\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c64d1826116548f1893d6d7bb44ec39a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "테스트 파일 추론 중:   0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Train Loss: 0.4028, Val Loss: 0.3431\n",
      "Epoch 2/100, Train Loss: 0.3877, Val Loss: 0.3347\n",
      "Epoch 3/100, Train Loss: 0.3766, Val Loss: 0.3263\n",
      "Epoch 4/100, Train Loss: 0.3642, Val Loss: 0.3181\n",
      "Epoch 5/100, Train Loss: 0.3594, Val Loss: 0.3097\n",
      "Epoch 6/100, Train Loss: 0.3495, Val Loss: 0.3013\n",
      "Epoch 7/100, Train Loss: 0.3414, Val Loss: 0.2929\n",
      "Epoch 8/100, Train Loss: 0.3318, Val Loss: 0.2842\n",
      "Epoch 9/100, Train Loss: 0.3258, Val Loss: 0.2754\n",
      "Epoch 10/100, Train Loss: 0.3127, Val Loss: 0.2663\n",
      "Epoch 11/100, Train Loss: 0.3048, Val Loss: 0.2567\n",
      "Epoch 12/100, Train Loss: 0.2970, Val Loss: 0.2470\n",
      "Epoch 13/100, Train Loss: 0.2884, Val Loss: 0.2367\n",
      "Epoch 14/100, Train Loss: 0.2770, Val Loss: 0.2257\n",
      "Epoch 15/100, Train Loss: 0.2559, Val Loss: 0.2142\n",
      "Epoch 16/100, Train Loss: 0.2438, Val Loss: 0.2028\n",
      "Epoch 17/100, Train Loss: 0.2307, Val Loss: 0.1922\n",
      "Epoch 18/100, Train Loss: 0.2137, Val Loss: 0.1824\n",
      "Epoch 19/100, Train Loss: 0.2019, Val Loss: 0.1725\n",
      "Epoch 20/100, Train Loss: 0.1877, Val Loss: 0.1630\n",
      "Epoch 21/100, Train Loss: 0.1721, Val Loss: 0.1533\n",
      "Epoch 22/100, Train Loss: 0.1581, Val Loss: 0.1447\n",
      "Epoch 23/100, Train Loss: 0.1462, Val Loss: 0.1391\n",
      "Epoch 24/100, Train Loss: 0.1384, Val Loss: 0.1399\n",
      "Epoch 25/100, Train Loss: 0.1364, Val Loss: 0.1444\n",
      "Epoch 26/100, Train Loss: 0.1398, Val Loss: 0.1495\n",
      "Epoch 27/100, Train Loss: 0.1392, Val Loss: 0.1521\n",
      "Epoch 28/100, Train Loss: 0.1398, Val Loss: 0.1509\n",
      "Epoch 29/100, Train Loss: 0.1406, Val Loss: 0.1474\n",
      "Epoch 30/100, Train Loss: 0.1344, Val Loss: 0.1432\n",
      "Epoch 31/100, Train Loss: 0.1319, Val Loss: 0.1405\n",
      "Epoch 32/100, Train Loss: 0.1285, Val Loss: 0.1388\n",
      "Epoch 33/100, Train Loss: 0.1298, Val Loss: 0.1384\n",
      "Epoch 34/100, Train Loss: 0.1289, Val Loss: 0.1383\n",
      "Epoch 35/100, Train Loss: 0.1312, Val Loss: 0.1381\n",
      "Epoch 36/100, Train Loss: 0.1313, Val Loss: 0.1378\n",
      "Epoch 37/100, Train Loss: 0.1294, Val Loss: 0.1374\n",
      "Epoch 38/100, Train Loss: 0.1278, Val Loss: 0.1375\n",
      "Epoch 39/100, Train Loss: 0.1263, Val Loss: 0.1381\n",
      "Epoch 40/100, Train Loss: 0.1292, Val Loss: 0.1388\n",
      "Epoch 41/100, Train Loss: 0.1267, Val Loss: 0.1390\n",
      "Epoch 42/100, Train Loss: 0.1260, Val Loss: 0.1391\n",
      "Epoch 43/100, Train Loss: 0.1234, Val Loss: 0.1388\n",
      "Epoch 44/100, Train Loss: 0.1281, Val Loss: 0.1383\n",
      "Epoch 45/100, Train Loss: 0.1277, Val Loss: 0.1378\n",
      "Epoch 46/100, Train Loss: 0.1255, Val Loss: 0.1371\n",
      "Epoch 47/100, Train Loss: 0.1253, Val Loss: 0.1365\n",
      "Epoch 48/100, Train Loss: 0.1245, Val Loss: 0.1361\n",
      "Epoch 49/100, Train Loss: 0.1250, Val Loss: 0.1359\n",
      "Epoch 50/100, Train Loss: 0.1240, Val Loss: 0.1359\n",
      "Epoch 51/100, Train Loss: 0.1240, Val Loss: 0.1359\n",
      "Epoch 52/100, Train Loss: 0.1234, Val Loss: 0.1364\n",
      "Epoch 53/100, Train Loss: 0.1249, Val Loss: 0.1366\n",
      "Epoch 54/100, Train Loss: 0.1240, Val Loss: 0.1368\n",
      "Epoch 55/100, Train Loss: 0.1226, Val Loss: 0.1367\n",
      "Epoch 56/100, Train Loss: 0.1214, Val Loss: 0.1364\n",
      "Epoch 57/100, Train Loss: 0.1217, Val Loss: 0.1360\n",
      "Epoch 58/100, Train Loss: 0.1199, Val Loss: 0.1360\n",
      "Epoch 59/100, Train Loss: 0.1212, Val Loss: 0.1364\n",
      "Epoch 60/100, Train Loss: 0.1196, Val Loss: 0.1366\n",
      "Epoch 61/100, Train Loss: 0.1188, Val Loss: 0.1366\n",
      "Epoch 62/100, Train Loss: 0.1197, Val Loss: 0.1366\n",
      "Epoch 63/100, Train Loss: 0.1197, Val Loss: 0.1363\n",
      "Epoch 64/100, Train Loss: 0.1198, Val Loss: 0.1359\n",
      "Epoch 65/100, Train Loss: 0.1195, Val Loss: 0.1356\n",
      "Epoch 66/100, Train Loss: 0.1192, Val Loss: 0.1354\n",
      "Epoch 67/100, Train Loss: 0.1217, Val Loss: 0.1353\n",
      "Epoch 68/100, Train Loss: 0.1188, Val Loss: 0.1353\n",
      "Epoch 69/100, Train Loss: 0.1175, Val Loss: 0.1353\n",
      "Epoch 70/100, Train Loss: 0.1174, Val Loss: 0.1354\n",
      "Epoch 71/100, Train Loss: 0.1171, Val Loss: 0.1356\n",
      "Epoch 72/100, Train Loss: 0.1178, Val Loss: 0.1358\n",
      "Epoch 73/100, Train Loss: 0.1155, Val Loss: 0.1356\n",
      "Epoch 74/100, Train Loss: 0.1152, Val Loss: 0.1351\n",
      "Epoch 75/100, Train Loss: 0.1161, Val Loss: 0.1346\n",
      "Epoch 76/100, Train Loss: 0.1147, Val Loss: 0.1341\n",
      "Epoch 77/100, Train Loss: 0.1156, Val Loss: 0.1339\n",
      "Epoch 78/100, Train Loss: 0.1147, Val Loss: 0.1341\n",
      "Epoch 79/100, Train Loss: 0.1173, Val Loss: 0.1340\n",
      "Epoch 80/100, Train Loss: 0.1157, Val Loss: 0.1344\n",
      "Epoch 81/100, Train Loss: 0.1137, Val Loss: 0.1348\n",
      "Epoch 82/100, Train Loss: 0.1137, Val Loss: 0.1342\n",
      "Epoch 83/100, Train Loss: 0.1139, Val Loss: 0.1341\n",
      "Epoch 84/100, Train Loss: 0.1132, Val Loss: 0.1338\n",
      "Epoch 85/100, Train Loss: 0.1131, Val Loss: 0.1337\n",
      "Epoch 86/100, Train Loss: 0.1122, Val Loss: 0.1334\n",
      "Epoch 87/100, Train Loss: 0.1120, Val Loss: 0.1331\n",
      "Epoch 88/100, Train Loss: 0.1109, Val Loss: 0.1334\n",
      "Epoch 89/100, Train Loss: 0.1148, Val Loss: 0.1339\n",
      "Epoch 90/100, Train Loss: 0.1127, Val Loss: 0.1340\n",
      "Epoch 91/100, Train Loss: 0.1133, Val Loss: 0.1342\n",
      "Epoch 92/100, Train Loss: 0.1095, Val Loss: 0.1341\n",
      "Epoch 93/100, Train Loss: 0.1114, Val Loss: 0.1341\n",
      "Epoch 94/100, Train Loss: 0.1114, Val Loss: 0.1336\n",
      "Epoch 95/100, Train Loss: 0.1123, Val Loss: 0.1330\n",
      "Epoch 96/100, Train Loss: 0.1123, Val Loss: 0.1334\n",
      "Epoch 97/100, Train Loss: 0.1101, Val Loss: 0.1338\n",
      "Epoch 98/100, Train Loss: 0.1105, Val Loss: 0.1344\n",
      "Epoch 99/100, Train Loss: 0.1126, Val Loss: 0.1346\n",
      "Epoch 100/100, Train Loss: 0.1092, Val Loss: 0.1345\n",
      "Best Validation Loss for 대파: 0.1330\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a49a294f458b436aaaae1b834f1afd00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "테스트 파일 추론 중:   0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "품목별_predictions = {}\n",
    "품목별_scalers = {}\n",
    "\n",
    "pbar_outer = tqdm(품목_리스트, desc=\"품목 처리 중\", position=0)\n",
    "for 품목명 in pbar_outer:\n",
    "    pbar_outer.set_description(f\"품목별 전처리 및 모델 학습 -> {품목명}\")\n",
    "    train_data, scaler = process_data(\"./train/train.csv\", \n",
    "                              품목명)\n",
    "    품목별_scalers[품목명] = scaler\n",
    "    dataset = AgriculturePriceDataset(train_data)\n",
    "\n",
    "    # 데이터를 train과 validation으로 분할\n",
    "    train_data, val_data = train_test_split(dataset, test_size=0.2, random_state=42)\n",
    "    \n",
    "    train_loader = DataLoader(train_data, CFG.batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_data, CFG.batch_size, shuffle=False)\n",
    "\n",
    "    input_size = len(dataset.numeric_columns)\n",
    "    \n",
    "    model = PricePredictionLSTM(input_size, CFG.hidden_size, CFG.num_layers, CFG.output_size)\n",
    "    criterion = nn.L1Loss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), CFG.learning_rate)\n",
    "    \n",
    "    best_val_loss = float('inf')\n",
    "    os.makedirs('models', exist_ok=True)\n",
    "\n",
    "    for epoch in range(CFG.epoch):\n",
    "        train_loss = train_model(model, train_loader, criterion, optimizer, CFG.epoch)\n",
    "        val_loss = evaluate_model(model, val_loader, criterion)\n",
    "        \n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save(model.state_dict(), f'models/best_model_{품목명}.pth')\n",
    "        \n",
    "        print(f'Epoch {epoch+1}/{CFG.epoch}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}')\n",
    "    \n",
    "    print(f'Best Validation Loss for {품목명}: {best_val_loss:.4f}')\n",
    "    \n",
    "    품목_predictions = []\n",
    "\n",
    "    ### 추론 \n",
    "    pbar_inner = tqdm(range(25), desc=\"테스트 파일 추론 중\", position=1, leave=False)\n",
    "    for i in pbar_inner:\n",
    "        test_file = f\"./test/TEST_{i:02d}.csv\"\n",
    "        \n",
    "        test_data, _ = process_data(test_file, 품목명, scaler=품목별_scalers[품목명])\n",
    "        test_dataset = AgriculturePriceDataset(test_data, is_test=True)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "        model.eval()\n",
    "        predictions = []\n",
    "        with torch.no_grad():\n",
    "            for batch in test_loader:\n",
    "                output = model(batch)\n",
    "                predictions.append(output.numpy())\n",
    "        \n",
    "        predictions_array = np.concatenate(predictions)\n",
    "\n",
    "        # 예측값을 원래 스케일로 복원\n",
    "        price_column_index = test_data.columns.get_loc(test_dataset.price_column)\n",
    "        predictions_reshaped = predictions_array.reshape(-1, 1)\n",
    "        \n",
    "        # 가격 열에 대해서만 inverse_transform 적용\n",
    "        price_scaler = MinMaxScaler()\n",
    "        price_scaler.min_ = 품목별_scalers[품목명].min_[price_column_index]\n",
    "        price_scaler.scale_ = 품목별_scalers[품목명].scale_[price_column_index]\n",
    "        predictions_original_scale = price_scaler.inverse_transform(predictions_reshaped)\n",
    "        #print(predictions_original_scale)\n",
    "        \n",
    "        if np.isnan(predictions_original_scale).any():\n",
    "            pbar_inner.set_postfix({\"상태\": \"NaN\"})\n",
    "        else:\n",
    "            pbar_inner.set_postfix({\"상태\": \"정상\"})\n",
    "            품목_predictions.extend(predictions_original_scale.flatten())\n",
    "\n",
    "            \n",
    "    품목별_predictions[품목명] = 품목_predictions\n",
    "    pbar_outer.update(1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Submission File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv('./sample_submission.csv')\n",
    "\n",
    "for 품목명, predictions in 품목별_predictions.items():\n",
    "    sample_submission[품목명] = predictions\n",
    "\n",
    "# 결과 저장\n",
    "sample_submission.to_csv('./baseline_submission6.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
