{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1163f093-a63e-4ce1-b7a3-c8e0f2f19337",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from types import SimpleNamespace\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import os\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "import torch.optim as optim\n",
    "from tqdm.notebook import tqdm\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from blitz.modules.base_bayesian_module import BayesianModule, BayesianRNN\n",
    "from blitz.modules.lstm_bayesian_layer import BayesianLSTM\n",
    "from blitz.modules.weight_sampler import TrainableRandomDistribution, PriorWeightDistribution\n",
    "from blitz.utils import variational_estimator\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from collections import deque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c2d4994-6bc6-43e3-b9fe-d5c6aad4ef00",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"learning_rate\": 2e-5,\n",
    "    \"epoch\": 30,\n",
    "    \"batch_size\": 64,\n",
    "    \"hidden_size\": 64,\n",
    "    \"num_layers\": 2,\n",
    "    \"output_size\": 3\n",
    "}\n",
    "\n",
    "CFG = SimpleNamespace(**config)\n",
    "\n",
    "품목_리스트 = ['건고추', '사과', '감자', '배', '깐마늘(국산)', '무', '상추', '배추', '양파', '대파']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "634869b2-210d-4160-b351-627c50ef2c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def process_data(raw_file, 산지공판장_file, 전국도매_file, 품목명, scaler=None):\n",
    "    raw_data = pd.read_csv(raw_file)\n",
    "    산지공판장 = pd.read_csv(산지공판장_file)\n",
    "    전국도매 = pd.read_csv(전국도매_file)\n",
    "\n",
    "    # 타겟 및 메타데이터 필터 조건 정의\n",
    "    conditions = {\n",
    "    '감자': {\n",
    "        'target': lambda df: (df['품종명'] == '감자 수미') & (df['거래단위'] == '20키로상자') & (df['등급'] == '상'),\n",
    "        '공판장': {'공판장명': ['*전국농협공판장'], '품목명': ['감자'], '품종명': ['수미'], '등급명': ['상']},\n",
    "        '도매': {'시장명': ['*전국도매시장'], '품목명': ['감자'], '품종명': ['수미']}\n",
    "    },\n",
    "    '건고추': {\n",
    "        'target': lambda df: (df['품종명'] == '화건') & (df['거래단위'] == '30 kg') & (df['등급'] == '상품'),\n",
    "        '공판장': None, \n",
    "        '도매': None  \n",
    "    },\n",
    "    '깐마늘(국산)': {\n",
    "        'target': lambda df: (df['거래단위'] == '20 kg') & (df['등급'] == '상품'),\n",
    "        '공판장': {'공판장명': ['*전국농협공판장'], '품목명': ['마늘'], '품종명': ['깐마늘'], '등급명': ['상']},\n",
    "        '도매': {'시장명': ['*전국도매시장'], '품목명': ['마늘'], '품종명': ['깐마늘']}\n",
    "    },\n",
    "    '대파': {\n",
    "        'target': lambda df: (df['품종명'] == '대파(일반)') & (df['거래단위'] == '1키로단') & (df['등급'] == '상'),\n",
    "        '공판장': {'공판장명': ['*전국농협공판장'], '품목명': ['대파'], '품종명': ['대파(일반)'], '등급명': ['상']},\n",
    "        '도매': {'시장명': ['*전국도매시장'], '품목명': ['대파'], '품종명': ['대파(일반)']}\n",
    "    },\n",
    "    '무': {\n",
    "        'target': lambda df: (df['거래단위'] == '20키로상자') & (df['등급'] == '상'),\n",
    "        '공판장': {'공판장명': ['*전국농협공판장'], '품목명': ['무'], '품종명': ['기타무'], '등급명': ['상']},\n",
    "        '도매': {'시장명': ['*전국도매시장'], '품목명': ['무'], '품종명': ['무']}\n",
    "    },\n",
    "    '배추': {\n",
    "        'target': lambda df: (df['거래단위'] == '10키로망대') & (df['등급'] == '상'),\n",
    "        '공판장': {'공판장명': ['*전국농협공판장'], '품목명': ['배추'], '품종명': ['쌈배추'], '등급명': ['상']},\n",
    "        '도매': {'시장명': ['*전국도매시장'], '품목명': ['배추'], '품종명': ['배추']}\n",
    "    },\n",
    "    '사과': {\n",
    "        'target': lambda df: (df['품종명'].isin(['홍로', '후지'])) & (df['거래단위'] == '10 개') & (df['등급'] == '상품'),\n",
    "        '공판장': {'공판장명': ['*전국농협공판장'], '품목명': ['사과'], '품종명': ['후지'], '등급명': ['상']},\n",
    "        '도매': {'시장명': ['*전국도매시장'], '품목명': ['사과'], '품종명': ['후지']}\n",
    "    },\n",
    "    '상추': {\n",
    "        'target': lambda df: (df['품종명'] == '청') & (df['거래단위'] == '100 g') & (df['등급'] == '상품'),\n",
    "        '공판장': {'공판장명': ['*전국농협공판장'], '품목명': ['상추'], '품종명': ['청상추'], '등급명': ['상']},\n",
    "        '도매': {'시장명': ['*전국도매시장'], '품목명': ['상추'], '품종명': ['청상추']}\n",
    "    },\n",
    "    '양파': {\n",
    "        'target': lambda df: (df['품종명'] == '양파') & (df['거래단위'] == '1키로') & (df['등급'] == '상'),\n",
    "        '공판장': {'공판장명': ['*전국농협공판장'], '품목명': ['양파'], '품종명': ['기타양파'], '등급명': ['상']},\n",
    "        '도매': {'시장명': ['*전국도매시장'], '품목명': ['양파'], '품종명': ['양파(일반)']}\n",
    "    },\n",
    "    '배': {\n",
    "        'target': lambda df: (df['품종명'] == '신고') & (df['거래단위'] == '10 개') & (df['등급'] == '상품'),\n",
    "        '공판장': {'공판장명': ['*전국농협공판장'], '품목명': ['배'], '품종명': ['신고'], '등급명': ['상']},\n",
    "        '도매': {'시장명': ['*전국도매시장'], '품목명': ['배'], '품종명': ['신고']}\n",
    "    }\n",
    "    }\n",
    "\n",
    "    # 타겟 데이터 필터링\n",
    "    raw_품목 = raw_data[raw_data['품목명'] == 품목명]\n",
    "    target_mask = conditions[품목명]['target'](raw_품목)\n",
    "    filtered_data = raw_품목[target_mask]\n",
    "\n",
    "    # 다른 품종에 대한 파생변수 생성\n",
    "    other_data = raw_품목[~target_mask]\n",
    "    unique_combinations = other_data[['품종명', '거래단위', '등급']].drop_duplicates()\n",
    "    for _, row in unique_combinations.iterrows():\n",
    "        품종명, 거래단위, 등급 = row['품종명'], row['거래단위'], row['등급']\n",
    "        mask = (other_data['품종명'] == 품종명) & (other_data['거래단위'] == 거래단위) & (other_data['등급'] == 등급)\n",
    "        temp_df = other_data[mask]\n",
    "        for col in ['평년 평균가격(원)', '평균가격(원)']:\n",
    "            new_col_name = f'{품종명}_{거래단위}_{등급}_{col}'\n",
    "            filtered_data = filtered_data.merge(temp_df[['시점', col]], on='시점', how='left', suffixes=('', f'_{new_col_name}'))\n",
    "            filtered_data.rename(columns={f'{col}_{new_col_name}': new_col_name}, inplace=True)\n",
    "\n",
    "\n",
    "    # 공판장 데이터 처리\n",
    "    if conditions[품목명]['공판장']:\n",
    "        filtered_공판장 = 산지공판장\n",
    "        for key, value in conditions[품목명]['공판장'].items():\n",
    "            filtered_공판장 = filtered_공판장[filtered_공판장[key].isin(value)]\n",
    "        \n",
    "        filtered_공판장 = filtered_공판장.add_prefix('공판장_').rename(columns={'공판장_시점': '시점'})\n",
    "        filtered_data = filtered_data.merge(filtered_공판장, on='시점', how='left')\n",
    "\n",
    "    # 도매 데이터 처리\n",
    "    if conditions[품목명]['도매']:\n",
    "        filtered_도매 = 전국도매\n",
    "        for key, value in conditions[품목명]['도매'].items():\n",
    "            filtered_도매 = filtered_도매[filtered_도매[key].isin(value)]\n",
    "        \n",
    "        filtered_도매 = filtered_도매.add_prefix('도매_').rename(columns={'도매_시점': '시점'})\n",
    "        filtered_data = filtered_data.merge(filtered_도매, on='시점', how='left')\n",
    "\n",
    "    # 수치형 컬럼 처리\n",
    "    numeric_columns = filtered_data.select_dtypes(include=[np.number]).columns\n",
    "    filtered_data = filtered_data[['시점'] + list(numeric_columns)]\n",
    "    filtered_data[numeric_columns] = filtered_data[numeric_columns].fillna(0)\n",
    "\n",
    "    # 정규화 적용\n",
    "    if scaler is None:\n",
    "        scaler = MinMaxScaler()\n",
    "        filtered_data[numeric_columns] = scaler.fit_transform(filtered_data[numeric_columns])\n",
    "    else:\n",
    "        filtered_data[numeric_columns] = scaler.transform(filtered_data[numeric_columns])\n",
    "\n",
    "    return filtered_data, scaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "077abb77-3b76-4340-9338-96ba00d185ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgriculturePriceDataset(Dataset):\n",
    "    def __init__(self, dataframe, window_size=9, prediction_length=3, is_test=False):\n",
    "        self.data = dataframe\n",
    "        self.window_size = window_size\n",
    "        self.prediction_length = prediction_length\n",
    "        self.is_test = is_test\n",
    "        \n",
    "        self.price_column = '평균가격(원)'\n",
    "        self.numeric_columns = self.data.select_dtypes(include=[np.number]).columns.tolist()\n",
    "        \n",
    "        self.sequences = []\n",
    "        if not self.is_test:\n",
    "            for i in range(len(self.data) - self.window_size - self.prediction_length + 1):\n",
    "                x = self.data[self.numeric_columns].iloc[i:i+self.window_size].values\n",
    "                y = self.data[self.price_column].iloc[i+self.window_size:i+self.window_size+self.prediction_length].values\n",
    "                self.sequences.append((x, y))\n",
    "        else:\n",
    "            self.sequences = [self.data[self.numeric_columns].values]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if not self.is_test:\n",
    "            x, y = self.sequences[idx]\n",
    "            return torch.FloatTensor(x), torch.FloatTensor(y)\n",
    "        else:\n",
    "            return torch.FloatTensor(self.sequences[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5c852916-d972-4936-b677-bad012d55589",
   "metadata": {},
   "outputs": [],
   "source": [
    "@variational_estimator\n",
    "class PricePredictionLSTM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NN, self).__init__()\n",
    "        self.lstm_1 = BayesianLSTM(1, 10, prior_sigma_1=1, prior_pi=1, posterior_rho_init=-3.0)\n",
    "        self.linear = nn.Linear(10, 1)\n",
    "            \n",
    "    def forward(self, x):\n",
    "        x_, _ = self.lstm_1(x)\n",
    "        \n",
    "        #gathering only the latent end-of-sequence for the linear layer\n",
    "        x_ = x_[:, -1, :]\n",
    "        x_ = self.linear(x_)\n",
    "        return x_\n",
    "\n",
    "def train_model(model, train_loader, criterion, optimizer, num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch_x, batch_y in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_x)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(train_loader)  \n",
    "\n",
    "def evaluate_model(model, test_loader, criterion):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_x, batch_y in test_loader:\n",
    "            outputs = model(batch_x)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            total_loss += loss.item()\n",
    "    return total_loss / len(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "051bc69d-bc06-40ff-8aa6-d018d7a66c2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e8f9ae155c74e52aaec8915bfcc2a47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "품목 처리 중:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TypeError",
     "evalue": "PricePredictionLSTM.__init__() takes 1 positional argument but 5 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 22\u001b[0m\n\u001b[0;32m     18\u001b[0m val_loader \u001b[38;5;241m=\u001b[39m DataLoader(val_data, CFG\u001b[38;5;241m.\u001b[39mbatch_size, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     20\u001b[0m input_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(dataset\u001b[38;5;241m.\u001b[39mnumeric_columns)\n\u001b[1;32m---> 22\u001b[0m model \u001b[38;5;241m=\u001b[39m PricePredictionLSTM(input_size, CFG\u001b[38;5;241m.\u001b[39mhidden_size, CFG\u001b[38;5;241m.\u001b[39mnum_layers, CFG\u001b[38;5;241m.\u001b[39moutput_size)\n\u001b[0;32m     23\u001b[0m criterion \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mL1Loss()\n\u001b[0;32m     24\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), CFG\u001b[38;5;241m.\u001b[39mlearning_rate)\n",
      "\u001b[1;31mTypeError\u001b[0m: PricePredictionLSTM.__init__() takes 1 positional argument but 5 were given"
     ]
    }
   ],
   "source": [
    "품목별_predictions = {}\n",
    "품목별_scalers = {}\n",
    "\n",
    "pbar_outer = tqdm(품목_리스트, desc=\"품목 처리 중\", position=0)\n",
    "for 품목명 in pbar_outer:\n",
    "    pbar_outer.set_description(f\"품목별 전처리 및 모델 학습 -> {품목명}\")\n",
    "    train_data, scaler = process_data(\"../data/train/train.csv\", \n",
    "                              \"../data/train/meta/TRAIN_산지공판장_2018-2021.csv\", \n",
    "                              \"../data/train/meta/TRAIN_전국도매_2018-2021.csv\", \n",
    "                              품목명)\n",
    "    품목별_scalers[품목명] = scaler\n",
    "    dataset = AgriculturePriceDataset(train_data)\n",
    "\n",
    "    # 데이터를 train과 validation으로 분할\n",
    "    train_data, val_data = train_test_split(dataset, test_size=0.2, random_state=42)\n",
    "    \n",
    "    train_loader = DataLoader(train_data, CFG.batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_data, CFG.batch_size, shuffle=False)\n",
    "\n",
    "    input_size = len(dataset.numeric_columns)\n",
    "    \n",
    "    model = PricePredictionLSTM(input_size, CFG.hidden_size, CFG.num_layers, CFG.output_size)\n",
    "    criterion = nn.L1Loss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), CFG.learning_rate)\n",
    "    \n",
    "    best_val_loss = float('inf')\n",
    "    os.makedirs('models', exist_ok=True)\n",
    "\n",
    "    for epoch in range(CFG.epoch):\n",
    "        train_loss = train_model(model, train_loader, criterion, optimizer, CFG.epoch)\n",
    "        val_loss = evaluate_model(model, val_loader, criterion)\n",
    "        \n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save(model.state_dict(), f'models/best_model_{품목명}.pth')\n",
    "        \n",
    "        print(f'Epoch {epoch+1}/{CFG.epoch}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}')\n",
    "    \n",
    "    print(f'Best Validation Loss for {품목명}: {best_val_loss:.4f}')\n",
    "    \n",
    "    품목_predictions = []\n",
    "\n",
    "    ### 추론 \n",
    "    pbar_inner = tqdm(range(25), desc=\"테스트 파일 추론 중\", position=1, leave=False)\n",
    "    for i in pbar_inner:\n",
    "        test_file = f\"./test/TEST_{i:02d}.csv\"\n",
    "        산지공판장_file = f\"./test/meta/TEST_산지공판장_{i:02d}.csv\"\n",
    "        전국도매_file = f\"./test/meta/TEST_전국도매_{i:02d}.csv\"\n",
    "        \n",
    "        test_data, _ = process_data(test_file, 산지공판장_file, 전국도매_file, 품목명, scaler=품목별_scalers[품목명])\n",
    "        test_dataset = AgriculturePriceDataset(test_data, is_test=True)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "        model.eval()\n",
    "        predictions = []\n",
    "        with torch.no_grad():\n",
    "            for batch in test_loader:\n",
    "                output = model(batch)\n",
    "                predictions.append(output.numpy())\n",
    "        \n",
    "        predictions_array = np.concatenate(predictions)\n",
    "\n",
    "        # 예측값을 원래 스케일로 복원\n",
    "        price_column_index = test_data.columns.get_loc(test_dataset.price_column)\n",
    "        predictions_reshaped = predictions_array.reshape(-1, 1)\n",
    "        \n",
    "        # 가격 열에 대해서만 inverse_transform 적용\n",
    "        price_scaler = MinMaxScaler()\n",
    "        price_scaler.min_ = 품목별_scalers[품목명].min_[price_column_index]\n",
    "        price_scaler.scale_ = 품목별_scalers[품목명].scale_[price_column_index]\n",
    "        predictions_original_scale = price_scaler.inverse_transform(predictions_reshaped)\n",
    "        #print(predictions_original_scale)\n",
    "        \n",
    "        if np.isnan(predictions_original_scale).any():\n",
    "            pbar_inner.set_postfix({\"상태\": \"NaN\"})\n",
    "        else:\n",
    "            pbar_inner.set_postfix({\"상태\": \"정상\"})\n",
    "            품목_predictions.extend(predictions_original_scale.flatten())\n",
    "\n",
    "            \n",
    "    품목별_predictions[품목명] = 품목_predictions\n",
    "    pbar_outer.update(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c79fd3a-9bd6-4e9f-97b1-ceeabf431316",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
