{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57ba88fb-b70b-4c62-b994-8d9b3eca4f7b",
   "metadata": {},
   "source": [
    "# 패키지 Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97d455b1-bdfb-4847-af8f-038cd054d34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from types import SimpleNamespace\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import os\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from blitz.modules.base_bayesian_module import BayesianModule, BayesianRNN\n",
    "from blitz.modules.weight_sampler import TrainableRandomDistribution, PriorWeightDistribution\n",
    "from blitz.utils import variational_estimator\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "from collections import deque"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "125480ef-854f-49f2-b95f-7e2e7a205e37",
   "metadata": {},
   "source": [
    "# 데이터 준비 (베이스라인)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e4958a15-f203-4913-b3e9-6de73d9be434",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"learning_rate\": 2e-5,\n",
    "    \"epoch\": 30,\n",
    "    \"batch_size\": 64,\n",
    "    \"hidden_size\": 64,\n",
    "    \"num_layers\": 2,\n",
    "    \"output_size\": 3\n",
    "}\n",
    "\n",
    "CFG = SimpleNamespace(**config)\n",
    "\n",
    "품목_리스트 = ['건고추', '사과', '감자', '배', '깐마늘(국산)', '무', '상추', '배추', '양파', '대파']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd7bf75c-6f17-46fe-a5f6-857131e27938",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(raw_file, 산지공판장_file, 전국도매_file, 품목명, scaler=None):\n",
    "    raw_data = pd.read_csv(raw_file)\n",
    "    산지공판장 = pd.read_csv(산지공판장_file)\n",
    "    전국도매 = pd.read_csv(전국도매_file)\n",
    "\n",
    "    # 타겟 및 메타데이터 필터 조건 정의\n",
    "    conditions = {\n",
    "    '감자': {\n",
    "        'target': lambda df: (df['품종명'] == '감자 수미') & (df['거래단위'] == '20키로상자') & (df['등급'] == '상'),\n",
    "        '공판장': {'공판장명': ['*전국농협공판장'], '품목명': ['감자'], '품종명': ['수미'], '등급명': ['상']},\n",
    "        '도매': {'시장명': ['*전국도매시장'], '품목명': ['감자'], '품종명': ['수미']}\n",
    "    },\n",
    "    '건고추': {\n",
    "        'target': lambda df: (df['품종명'] == '화건') & (df['거래단위'] == '30 kg') & (df['등급'] == '상품'),\n",
    "        '공판장': None, \n",
    "        '도매': None  \n",
    "    },\n",
    "    '깐마늘(국산)': {\n",
    "        'target': lambda df: (df['거래단위'] == '20 kg') & (df['등급'] == '상품'),\n",
    "        '공판장': {'공판장명': ['*전국농협공판장'], '품목명': ['마늘'], '품종명': ['깐마늘'], '등급명': ['상']},\n",
    "        '도매': {'시장명': ['*전국도매시장'], '품목명': ['마늘'], '품종명': ['깐마늘']}\n",
    "    },\n",
    "    '대파': {\n",
    "        'target': lambda df: (df['품종명'] == '대파(일반)') & (df['거래단위'] == '1키로단') & (df['등급'] == '상'),\n",
    "        '공판장': {'공판장명': ['*전국농협공판장'], '품목명': ['대파'], '품종명': ['대파(일반)'], '등급명': ['상']},\n",
    "        '도매': {'시장명': ['*전국도매시장'], '품목명': ['대파'], '품종명': ['대파(일반)']}\n",
    "    },\n",
    "    '무': {\n",
    "        'target': lambda df: (df['거래단위'] == '20키로상자') & (df['등급'] == '상'),\n",
    "        '공판장': {'공판장명': ['*전국농협공판장'], '품목명': ['무'], '품종명': ['기타무'], '등급명': ['상']},\n",
    "        '도매': {'시장명': ['*전국도매시장'], '품목명': ['무'], '품종명': ['무']}\n",
    "    },\n",
    "    '배추': {\n",
    "        'target': lambda df: (df['거래단위'] == '10키로망대') & (df['등급'] == '상'),\n",
    "        '공판장': {'공판장명': ['*전국농협공판장'], '품목명': ['배추'], '품종명': ['쌈배추'], '등급명': ['상']},\n",
    "        '도매': {'시장명': ['*전국도매시장'], '품목명': ['배추'], '품종명': ['배추']}\n",
    "    },\n",
    "    '사과': {\n",
    "        'target': lambda df: (df['품종명'].isin(['홍로', '후지'])) & (df['거래단위'] == '10 개') & (df['등급'] == '상품'),\n",
    "        '공판장': {'공판장명': ['*전국농협공판장'], '품목명': ['사과'], '품종명': ['후지'], '등급명': ['상']},\n",
    "        '도매': {'시장명': ['*전국도매시장'], '품목명': ['사과'], '품종명': ['후지']}\n",
    "    },\n",
    "    '상추': {\n",
    "        'target': lambda df: (df['품종명'] == '청') & (df['거래단위'] == '100 g') & (df['등급'] == '상품'),\n",
    "        '공판장': {'공판장명': ['*전국농협공판장'], '품목명': ['상추'], '품종명': ['청상추'], '등급명': ['상']},\n",
    "        '도매': {'시장명': ['*전국도매시장'], '품목명': ['상추'], '품종명': ['청상추']}\n",
    "    },\n",
    "    '양파': {\n",
    "        'target': lambda df: (df['품종명'] == '양파') & (df['거래단위'] == '1키로') & (df['등급'] == '상'),\n",
    "        '공판장': {'공판장명': ['*전국농협공판장'], '품목명': ['양파'], '품종명': ['기타양파'], '등급명': ['상']},\n",
    "        '도매': {'시장명': ['*전국도매시장'], '품목명': ['양파'], '품종명': ['양파(일반)']}\n",
    "    },\n",
    "    '배': {\n",
    "        'target': lambda df: (df['품종명'] == '신고') & (df['거래단위'] == '10 개') & (df['등급'] == '상품'),\n",
    "        '공판장': {'공판장명': ['*전국농협공판장'], '품목명': ['배'], '품종명': ['신고'], '등급명': ['상']},\n",
    "        '도매': {'시장명': ['*전국도매시장'], '품목명': ['배'], '품종명': ['신고']}\n",
    "    }\n",
    "    }\n",
    "\n",
    "    # 타겟 데이터 필터링\n",
    "    raw_품목 = raw_data[raw_data['품목명'] == 품목명]\n",
    "    target_mask = conditions[품목명]['target'](raw_품목)\n",
    "    filtered_data = raw_품목[target_mask]\n",
    "\n",
    "    # 다른 품종에 대한 파생변수 생성\n",
    "    other_data = raw_품목[~target_mask]\n",
    "    unique_combinations = other_data[['품종명', '거래단위', '등급']].drop_duplicates()\n",
    "    for _, row in unique_combinations.iterrows():\n",
    "        품종명, 거래단위, 등급 = row['품종명'], row['거래단위'], row['등급']\n",
    "        mask = (other_data['품종명'] == 품종명) & (other_data['거래단위'] == 거래단위) & (other_data['등급'] == 등급)\n",
    "        temp_df = other_data[mask]\n",
    "        for col in ['평년 평균가격(원)', '평균가격(원)']:\n",
    "            new_col_name = f'{품종명}_{거래단위}_{등급}_{col}'\n",
    "            filtered_data = filtered_data.merge(temp_df[['시점', col]], on='시점', how='left', suffixes=('', f'_{new_col_name}'))\n",
    "            filtered_data.rename(columns={f'{col}_{new_col_name}': new_col_name}, inplace=True)\n",
    "\n",
    "\n",
    "    # 공판장 데이터 처리\n",
    "    if conditions[품목명]['공판장']:\n",
    "        filtered_공판장 = 산지공판장\n",
    "        for key, value in conditions[품목명]['공판장'].items():\n",
    "            filtered_공판장 = filtered_공판장[filtered_공판장[key].isin(value)]\n",
    "        \n",
    "        filtered_공판장 = filtered_공판장.add_prefix('공판장_').rename(columns={'공판장_시점': '시점'})\n",
    "        filtered_data = filtered_data.merge(filtered_공판장, on='시점', how='left')\n",
    "\n",
    "    # 도매 데이터 처리\n",
    "    if conditions[품목명]['도매']:\n",
    "        filtered_도매 = 전국도매\n",
    "        for key, value in conditions[품목명]['도매'].items():\n",
    "            filtered_도매 = filtered_도매[filtered_도매[key].isin(value)]\n",
    "        \n",
    "        filtered_도매 = filtered_도매.add_prefix('도매_').rename(columns={'도매_시점': '시점'})\n",
    "        filtered_data = filtered_data.merge(filtered_도매, on='시점', how='left')\n",
    "\n",
    "    # 수치형 컬럼 처리\n",
    "    numeric_columns = filtered_data.select_dtypes(include=[np.number]).columns\n",
    "    filtered_data = filtered_data[['시점'] + list(numeric_columns)]\n",
    "    filtered_data[numeric_columns] = filtered_data[numeric_columns].fillna(0)\n",
    "\n",
    "    # # 정규화 적용\n",
    "    # if scaler is None:\n",
    "    #     scaler = MinMaxScaler()\n",
    "    #     filtered_data[numeric_columns] = scaler.fit_transform(filtered_data[numeric_columns])\n",
    "    # else:\n",
    "    #     filtered_data[numeric_columns] = scaler.transform(filtered_data[numeric_columns])\n",
    "\n",
    "    return filtered_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a979145-7788-48ad-955f-1a980ec4bb9c",
   "metadata": {},
   "source": [
    "# 베이지안 LSTM 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f4286f03-f28b-4553-b605-51976971df44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 베이지안 LSTM (From blitz)\n",
    "\n",
    "class BayesianLSTM(BayesianRNN):\n",
    "    \"\"\"\n",
    "    Bayesian LSTM layer, implements the linear layer proposed on Weight Uncertainity on Neural Networks\n",
    "    (Bayes by Backprop paper).\n",
    "\n",
    "    Its objective is be interactable with torch nn.Module API, being able even to be chained in nn.Sequential models with other non-this-lib layers\n",
    "    \n",
    "    parameters:\n",
    "        in_features: 입력 특성의 수 (정수)\n",
    "        out_features: 출력 특성의 수 (정수)\n",
    "        bias: 편향 항 사용 여부 (불리언)\n",
    "        prior_sigma_1: 혼합 사전 분포 1의 표준편차 (실수)\n",
    "        prior_sigma_2: 혼합 사전 분포 2의 표준편차 (실수)\n",
    "        prior_pi: 스케일된 혼합 사전 분포의 pi 값 (실수)\n",
    "        posterior_mu_init: 가중치 mu 초기화를 위한 사후 평균 (실수)\n",
    "        posterior_rho_init: 가중치 rho 초기화를 위한 사후 평균 (실수)\n",
    "        freeze: 가중치를 고정된(결정론적) 상태로 시작할지 여부 (불리언)\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 in_features,\n",
    "                 out_features,\n",
    "                 bias = True,\n",
    "                 prior_sigma_1 = 0.1,\n",
    "                 prior_sigma_2 = 0.002,\n",
    "                 prior_pi = 1,\n",
    "                 posterior_mu_init = 0,\n",
    "                 posterior_rho_init = -6.0,\n",
    "                 freeze = False,\n",
    "                 prior_dist = None,\n",
    "                 peephole = False,\n",
    "                 **kwargs):\n",
    "        \n",
    "        super().__init__(**kwargs)\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.use_bias = bias\n",
    "        self.freeze = freeze\n",
    "        self.peephole = peephole\n",
    "        \n",
    "        self.posterior_mu_init = posterior_mu_init\n",
    "        self.posterior_rho_init = posterior_rho_init\n",
    "        \n",
    "        self.prior_sigma_1 = prior_sigma_1\n",
    "        self.prior_sigma_2 = prior_sigma_2\n",
    "        self.prior_pi = prior_pi\n",
    "        self.prior_dist = prior_dist\n",
    "        \n",
    "        # Variational weight parameters and sample for weight ih\n",
    "        self.weight_ih_mu = nn.Parameter(torch.Tensor(in_features, out_features * 4).normal_(posterior_mu_init, 0.1))\n",
    "        self.weight_ih_rho = nn.Parameter(torch.Tensor(in_features, out_features * 4).normal_(posterior_rho_init, 0.1))\n",
    "        self.weight_ih_sampler = TrainableRandomDistribution(self.weight_ih_mu, self.weight_ih_rho)\n",
    "        self.weight_ih = None\n",
    "        \n",
    "        # Variational weight parameters and sample for weight hh\n",
    "        self.weight_hh_mu = nn.Parameter(torch.Tensor(out_features, out_features * 4).normal_(posterior_mu_init, 0.1))\n",
    "        self.weight_hh_rho = nn.Parameter(torch.Tensor(out_features, out_features * 4).normal_(posterior_rho_init, 0.1))\n",
    "        self.weight_hh_sampler = TrainableRandomDistribution(self.weight_hh_mu, self.weight_hh_rho)\n",
    "        self.weight_hh = None\n",
    "        \n",
    "        # Variational weight parameters and sample for bias\n",
    "        self.bias_mu = nn.Parameter(torch.Tensor(out_features * 4).normal_(posterior_mu_init, 0.1))\n",
    "        self.bias_rho = nn.Parameter(torch.Tensor(out_features * 4).normal_(posterior_rho_init, 0.1))\n",
    "        self.bias_sampler = TrainableRandomDistribution(self.bias_mu, self.bias_rho)\n",
    "        self.bias=None\n",
    "        \n",
    "        #our prior distributions\n",
    "        self.weight_ih_prior_dist = PriorWeightDistribution(self.prior_pi, self.prior_sigma_1, self.prior_sigma_2, dist = self.prior_dist)\n",
    "        self.weight_hh_prior_dist = PriorWeightDistribution(self.prior_pi, self.prior_sigma_1, self.prior_sigma_2, dist = self.prior_dist)\n",
    "        self.bias_prior_dist = PriorWeightDistribution(self.prior_pi, self.prior_sigma_1, self.prior_sigma_2, dist = self.prior_dist)\n",
    "        \n",
    "        self.init_sharpen_parameters()\n",
    "        \n",
    "        self.log_prior = 0\n",
    "        self.log_variational_posterior = 0\n",
    "    \n",
    "    \n",
    "    def sample_weights(self):\n",
    "        #sample weights\n",
    "        weight_ih = self.weight_ih_sampler.sample()\n",
    "        weight_hh = self.weight_hh_sampler.sample()\n",
    "        \n",
    "        #if use bias, we sample it, otherwise, we are using zeros\n",
    "        if self.use_bias:\n",
    "            b = self.bias_sampler.sample()\n",
    "            b_log_posterior = self.bias_sampler.log_posterior()\n",
    "            b_log_prior = self.bias_prior_dist.log_prior(b)\n",
    "            \n",
    "        else:\n",
    "            b = None\n",
    "            b_log_posterior = 0\n",
    "            b_log_prior = 0\n",
    "            \n",
    "        bias = b\n",
    "        \n",
    "        #gather weights variational posterior and prior likelihoods\n",
    "        self.log_variational_posterior = self.weight_hh_sampler.log_posterior() + b_log_posterior + self.weight_ih_sampler.log_posterior()\n",
    "        \n",
    "        self.log_prior = self.weight_ih_prior_dist.log_prior(weight_ih) + b_log_prior + self.weight_hh_prior_dist.log_prior(weight_hh)\n",
    "        \n",
    "        \n",
    "        self.ff_parameters = [weight_ih, weight_hh, bias]\n",
    "        return weight_ih, weight_hh, bias\n",
    "        \n",
    "    def get_frozen_weights(self):\n",
    "        \n",
    "        #get all deterministic weights\n",
    "        weight_ih = self.weight_ih_mu\n",
    "        weight_hh = self.weight_hh_mu\n",
    "        if self.use_bias:\n",
    "            bias = self.bias_mu\n",
    "        else:\n",
    "            bias = 0\n",
    "\n",
    "        return weight_ih, weight_hh, bias\n",
    "\n",
    "    \n",
    "    def forward_(self,\n",
    "                 x,\n",
    "                 hidden_states,\n",
    "                 sharpen_loss):\n",
    "        \n",
    "        if self.loss_to_sharpen is not None:\n",
    "            sharpen_loss = self.loss_to_sharpen\n",
    "            weight_ih, weight_hh, bias = self.sharpen_posterior(loss=sharpen_loss, input_shape=x.shape)\n",
    "        elif (sharpen_loss is not None):\n",
    "            sharpen_loss = sharpen_loss\n",
    "            weight_ih, weight_hh, bias = self.sharpen_posterior(loss=sharpen_loss, input_shape=x.shape)\n",
    "        \n",
    "        else:\n",
    "            weight_ih, weight_hh, bias = self.sample_weights()\n",
    "\n",
    "        #Assumes x is of shape (batch, sequence, feature)\n",
    "        bs, seq_sz, _ = x.size()\n",
    "        hidden_seq = []\n",
    "        \n",
    "        #if no hidden state, we are using zeros\n",
    "        if hidden_states is None:\n",
    "            h_t, c_t = (torch.zeros(bs, self.out_features).to(x.device), \n",
    "                        torch.zeros(bs, self.out_features).to(x.device))\n",
    "        else:\n",
    "            h_t, c_t = hidden_states\n",
    "        \n",
    "        #simplifying our out features, and hidden seq list\n",
    "        HS = self.out_features\n",
    "        hidden_seq = []\n",
    "        \n",
    "        for t in range(seq_sz):\n",
    "            x_t = x[:, t, :]\n",
    "            # batch the computations into a single matrix multiplication\n",
    "            \n",
    "            if self.peephole:\n",
    "                gates = x_t @ weight_ih + c_t @ weight_hh + bias\n",
    "            else:\n",
    "                gates = x_t @ weight_ih + h_t @ weight_hh + bias\n",
    "                g_t = torch.tanh(gates[:, HS*2:HS*3])\n",
    "            \n",
    "            i_t, f_t, o_t = (\n",
    "                torch.sigmoid(gates[:, :HS]), # input\n",
    "                torch.sigmoid(gates[:, HS:HS*2]), # forget\n",
    "                torch.sigmoid(gates[:, HS*3:]), # output\n",
    "            )\n",
    "            \n",
    "            if self.peephole:\n",
    "                c_t = f_t * c_t + i_t * torch.sigmoid(x_t @ weight_ih + bias)[:, HS*2:HS*3]\n",
    "                h_t = torch.tanh(o_t * c_t)\n",
    "            else:\n",
    "                c_t = f_t * c_t + i_t * g_t\n",
    "                h_t = o_t * torch.tanh(c_t)\n",
    "                \n",
    "            hidden_seq.append(h_t.unsqueeze(0))\n",
    "            \n",
    "        hidden_seq = torch.cat(hidden_seq, dim=0)\n",
    "        # reshape from shape (sequence, batch, feature) to (batch, sequence, feature)\n",
    "        hidden_seq = hidden_seq.transpose(0, 1).contiguous()\n",
    "        \n",
    "        return hidden_seq, (h_t, c_t)\n",
    "\n",
    "    def forward_frozen(self,\n",
    "                       x,\n",
    "                       hidden_states):\n",
    "\n",
    "        weight_ih, weight_hh, bias = self.get_frozen_weights()\n",
    "\n",
    "        #Assumes x is of shape (batch, sequence, feature)\n",
    "        bs, seq_sz, _ = x.size()\n",
    "        hidden_seq = []\n",
    "        \n",
    "        #if no hidden state, we are using zeros\n",
    "        if hidden_states is None:\n",
    "            h_t, c_t = (torch.zeros(bs, self.out_features).to(x.device), \n",
    "                        torch.zeros(bs, self.out_features).to(x.device))\n",
    "        else:\n",
    "            h_t, c_t = hidden_states\n",
    "        \n",
    "        #simplifying our out features, and hidden seq list\n",
    "        HS = self.out_features\n",
    "        hidden_seq = []\n",
    "        \n",
    "        for t in range(seq_sz):\n",
    "            x_t = x[:, t, :]\n",
    "            # batch the computations into a single matrix multiplication\n",
    "            \n",
    "            if self.peephole:\n",
    "                gates = x_t @ weight_ih + c_t @ weight_hh + bias\n",
    "            else:\n",
    "                gates = x_t @ weight_ih + h_t @ weight_hh + bias\n",
    "                g_t = torch.tanh(gates[:, HS*2:HS*3])\n",
    "            \n",
    "            i_t, f_t, o_t = (\n",
    "                torch.sigmoid(gates[:, :HS]), # input\n",
    "                torch.sigmoid(gates[:, HS:HS*2]), # forget\n",
    "                torch.sigmoid(gates[:, HS*3:]), # output\n",
    "            )\n",
    "            \n",
    "            if self.peephole:\n",
    "                c_t = f_t * c_t + i_t * torch.sigmoid(x_t @ weight_ih + bias)[:, HS*2:HS*3]\n",
    "                h_t = torch.sigmoid(o_t * c_t)\n",
    "            else:\n",
    "                c_t = f_t * c_t + i_t * g_t\n",
    "                h_t = o_t * torch.tanh(c_t)\n",
    "                \n",
    "            hidden_seq.append(h_t.unsqueeze(0))\n",
    "            \n",
    "        hidden_seq = torch.cat(hidden_seq, dim=0)\n",
    "        # reshape from shape (sequence, batch, feature) to (batch, sequence, feature)\n",
    "        hidden_seq = hidden_seq.transpose(0, 1).contiguous()\n",
    "        \n",
    "        return hidden_seq, (h_t, c_t)\n",
    "\n",
    "    def forward(self,\n",
    "                x,\n",
    "                hidden_states=None,\n",
    "                sharpen_loss=None):\n",
    "\n",
    "        if self.freeze:\n",
    "            return self.forward_frozen(x, hidden_states)\n",
    "        \n",
    "        if not self.sharpen:\n",
    "            sharpen_posterior = False\n",
    "            \n",
    "        return self.forward_(x, hidden_states, sharpen_loss)   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85488f97-a865-4a21-a9f6-bddcb50a0e2a",
   "metadata": {},
   "source": [
    "# 모델 돌리기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a0b21c-2e84-40ae-bce6-2b03b6ff1f60",
   "metadata": {},
   "source": [
    "## 01. 데이터 필터링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c16ccbce-e0e5-485c-a2c8-5d3164b4b422",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>시점</th>\n",
       "      <th>평년 평균가격(원)</th>\n",
       "      <th>평균가격(원)</th>\n",
       "      <th>햇산양건_30 kg_상품_평년 평균가격(원)</th>\n",
       "      <th>햇산양건_30 kg_상품_평균가격(원)</th>\n",
       "      <th>햇산화건_30 kg_중품_평년 평균가격(원)</th>\n",
       "      <th>햇산화건_30 kg_중품_평균가격(원)</th>\n",
       "      <th>햇산화건_30 kg_상품_평년 평균가격(원)</th>\n",
       "      <th>햇산화건_30 kg_상품_평균가격(원)</th>\n",
       "      <th>양건_30 kg_중품_평년 평균가격(원)</th>\n",
       "      <th>양건_30 kg_중품_평균가격(원)</th>\n",
       "      <th>양건_30 kg_상품_평년 평균가격(원)</th>\n",
       "      <th>양건_30 kg_상품_평균가격(원)</th>\n",
       "      <th>화건_30 kg_중품_평년 평균가격(원)</th>\n",
       "      <th>화건_30 kg_중품_평균가격(원)</th>\n",
       "      <th>햇산양건_30 kg_중품_평년 평균가격(원)</th>\n",
       "      <th>햇산양건_30 kg_중품_평균가격(원)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>201801상순</td>\n",
       "      <td>381666.666667</td>\n",
       "      <td>590000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>415476.333333</td>\n",
       "      <td>670000.0</td>\n",
       "      <td>465476.333333</td>\n",
       "      <td>715000.0</td>\n",
       "      <td>338333.333333</td>\n",
       "      <td>545000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>201801중순</td>\n",
       "      <td>380809.666667</td>\n",
       "      <td>590000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>415166.666667</td>\n",
       "      <td>670000.0</td>\n",
       "      <td>465250.000000</td>\n",
       "      <td>715000.0</td>\n",
       "      <td>337393.000000</td>\n",
       "      <td>545000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>201801하순</td>\n",
       "      <td>380000.000000</td>\n",
       "      <td>590000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>414333.333333</td>\n",
       "      <td>670000.0</td>\n",
       "      <td>464666.666667</td>\n",
       "      <td>715000.0</td>\n",
       "      <td>336333.333333</td>\n",
       "      <td>545000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>201802상순</td>\n",
       "      <td>380000.000000</td>\n",
       "      <td>590000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>414333.333333</td>\n",
       "      <td>670000.0</td>\n",
       "      <td>464666.666667</td>\n",
       "      <td>715000.0</td>\n",
       "      <td>336333.333333</td>\n",
       "      <td>545000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>201802중순</td>\n",
       "      <td>376666.666667</td>\n",
       "      <td>590000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>412666.666667</td>\n",
       "      <td>670000.0</td>\n",
       "      <td>463000.000000</td>\n",
       "      <td>715000.0</td>\n",
       "      <td>333000.000000</td>\n",
       "      <td>545000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>202111중순</td>\n",
       "      <td>552944.333333</td>\n",
       "      <td>558000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>622811.000000</td>\n",
       "      <td>648400.0</td>\n",
       "      <td>672477.666667</td>\n",
       "      <td>705000.0</td>\n",
       "      <td>501477.666667</td>\n",
       "      <td>494800.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>202111하순</td>\n",
       "      <td>554071.333333</td>\n",
       "      <td>565143.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>623127.333333</td>\n",
       "      <td>648400.0</td>\n",
       "      <td>673152.333333</td>\n",
       "      <td>705000.0</td>\n",
       "      <td>502271.333333</td>\n",
       "      <td>500514.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>202112상순</td>\n",
       "      <td>559000.000000</td>\n",
       "      <td>570500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>623333.333333</td>\n",
       "      <td>648400.0</td>\n",
       "      <td>675866.666667</td>\n",
       "      <td>705000.0</td>\n",
       "      <td>504866.666667</td>\n",
       "      <td>504800.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>202112중순</td>\n",
       "      <td>552000.000000</td>\n",
       "      <td>570500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>615916.666667</td>\n",
       "      <td>648400.0</td>\n",
       "      <td>668450.000000</td>\n",
       "      <td>705000.0</td>\n",
       "      <td>497866.666667</td>\n",
       "      <td>504800.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>202112하순</td>\n",
       "      <td>540555.333333</td>\n",
       "      <td>560778.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>605111.000000</td>\n",
       "      <td>648400.0</td>\n",
       "      <td>657644.333333</td>\n",
       "      <td>705000.0</td>\n",
       "      <td>487811.000000</td>\n",
       "      <td>497022.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>144 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           시점     평년 평균가격(원)   평균가격(원)  햇산양건_30 kg_상품_평년 평균가격(원)  \\\n",
       "0    201801상순  381666.666667  590000.0                       0.0   \n",
       "1    201801중순  380809.666667  590000.0                       0.0   \n",
       "2    201801하순  380000.000000  590000.0                       0.0   \n",
       "3    201802상순  380000.000000  590000.0                       0.0   \n",
       "4    201802중순  376666.666667  590000.0                       0.0   \n",
       "..        ...            ...       ...                       ...   \n",
       "139  202111중순  552944.333333  558000.0                       0.0   \n",
       "140  202111하순  554071.333333  565143.0                       0.0   \n",
       "141  202112상순  559000.000000  570500.0                       0.0   \n",
       "142  202112중순  552000.000000  570500.0                       0.0   \n",
       "143  202112하순  540555.333333  560778.0                       0.0   \n",
       "\n",
       "     햇산양건_30 kg_상품_평균가격(원)  햇산화건_30 kg_중품_평년 평균가격(원)  햇산화건_30 kg_중품_평균가격(원)  \\\n",
       "0                      0.0                       0.0                    0.0   \n",
       "1                      0.0                       0.0                    0.0   \n",
       "2                      0.0                       0.0                    0.0   \n",
       "3                      0.0                       0.0                    0.0   \n",
       "4                      0.0                       0.0                    0.0   \n",
       "..                     ...                       ...                    ...   \n",
       "139                    0.0                       0.0                    0.0   \n",
       "140                    0.0                       0.0                    0.0   \n",
       "141                    0.0                       0.0                    0.0   \n",
       "142                    0.0                       0.0                    0.0   \n",
       "143                    0.0                       0.0                    0.0   \n",
       "\n",
       "     햇산화건_30 kg_상품_평년 평균가격(원)  햇산화건_30 kg_상품_평균가격(원)  양건_30 kg_중품_평년 평균가격(원)  \\\n",
       "0                         0.0                    0.0           415476.333333   \n",
       "1                         0.0                    0.0           415166.666667   \n",
       "2                         0.0                    0.0           414333.333333   \n",
       "3                         0.0                    0.0           414333.333333   \n",
       "4                         0.0                    0.0           412666.666667   \n",
       "..                        ...                    ...                     ...   \n",
       "139                       0.0                    0.0           622811.000000   \n",
       "140                       0.0                    0.0           623127.333333   \n",
       "141                       0.0                    0.0           623333.333333   \n",
       "142                       0.0                    0.0           615916.666667   \n",
       "143                       0.0                    0.0           605111.000000   \n",
       "\n",
       "     양건_30 kg_중품_평균가격(원)  양건_30 kg_상품_평년 평균가격(원)  양건_30 kg_상품_평균가격(원)  \\\n",
       "0               670000.0           465476.333333             715000.0   \n",
       "1               670000.0           465250.000000             715000.0   \n",
       "2               670000.0           464666.666667             715000.0   \n",
       "3               670000.0           464666.666667             715000.0   \n",
       "4               670000.0           463000.000000             715000.0   \n",
       "..                   ...                     ...                  ...   \n",
       "139             648400.0           672477.666667             705000.0   \n",
       "140             648400.0           673152.333333             705000.0   \n",
       "141             648400.0           675866.666667             705000.0   \n",
       "142             648400.0           668450.000000             705000.0   \n",
       "143             648400.0           657644.333333             705000.0   \n",
       "\n",
       "     화건_30 kg_중품_평년 평균가격(원)  화건_30 kg_중품_평균가격(원)  햇산양건_30 kg_중품_평년 평균가격(원)  \\\n",
       "0             338333.333333             545000.0                       0.0   \n",
       "1             337393.000000             545000.0                       0.0   \n",
       "2             336333.333333             545000.0                       0.0   \n",
       "3             336333.333333             545000.0                       0.0   \n",
       "4             333000.000000             545000.0                       0.0   \n",
       "..                      ...                  ...                       ...   \n",
       "139           501477.666667             494800.0                       0.0   \n",
       "140           502271.333333             500514.0                       0.0   \n",
       "141           504866.666667             504800.0                       0.0   \n",
       "142           497866.666667             504800.0                       0.0   \n",
       "143           487811.000000             497022.0                       0.0   \n",
       "\n",
       "     햇산양건_30 kg_중품_평균가격(원)  \n",
       "0                      0.0  \n",
       "1                      0.0  \n",
       "2                      0.0  \n",
       "3                      0.0  \n",
       "4                      0.0  \n",
       "..                     ...  \n",
       "139                    0.0  \n",
       "140                    0.0  \n",
       "141                    0.0  \n",
       "142                    0.0  \n",
       "143                    0.0  \n",
       "\n",
       "[144 rows x 17 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_건고추 = process_data(\"../data/train/train.csv\", \n",
    "                         \"../data/train/meta/TRAIN_산지공판장_2018-2021.csv\", \n",
    "                         \"../data/train/meta/TRAIN_전국도매_2018-2021.csv\", \n",
    "                         '건고추')\n",
    "train_건고추"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "595aeb38-e9e5-4011-a05b-17bc09b13385",
   "metadata": {},
   "outputs": [],
   "source": [
    "prices = train_건고추[\"평균가격(원)\"]\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "prices_arr = np.array(prices).reshape(-1, 1)\n",
    "prices = scaler.fit_transform(prices_arr)\n",
    "\n",
    "prices_unscaled = train_건고추[\"평균가격(원)\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "61ce6718-32ab-4682-88fd-c76609a1a092",
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 12\n",
    "\n",
    "def create_timestamps_ds(series, \n",
    "                         timestep_size=window_size):\n",
    "    time_stamps = []\n",
    "    labels = []\n",
    "    aux_deque = deque(maxlen=timestep_size)\n",
    "    \n",
    "    #starting the timestep deque\n",
    "    for i in range(timestep_size):\n",
    "        aux_deque.append(0)\n",
    "    \n",
    "    #feed the timestamps list\n",
    "    for i in range(len(series)-1):\n",
    "        aux_deque.append(series[i])\n",
    "        time_stamps.append(list(aux_deque))\n",
    "    \n",
    "    #feed the labels lsit\n",
    "    for i in range(len(series)-1):\n",
    "        labels.append(series[i + 1])\n",
    "    \n",
    "    assert len(time_stamps) == len(labels), \"Something went wrong\"\n",
    "    \n",
    "    #torch-tensoring it\n",
    "    features = torch.tensor(time_stamps[timestep_size:]).float()\n",
    "    labels = torch.tensor(labels[timestep_size:]).float()\n",
    "    \n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3a219d50-c5cf-4829-9e5f-16c3287f8739",
   "metadata": {},
   "outputs": [],
   "source": [
    "@variational_estimator\n",
    "class NN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NN, self).__init__()\n",
    "        self.lstm_1 = BayesianLSTM(1, 10, prior_sigma_1=1, prior_pi=1, posterior_rho_init=-3.0)\n",
    "        self.linear = nn.Linear(10, 1)\n",
    "            \n",
    "    def forward(self, x):\n",
    "        x_, _ = self.lstm_1(x)\n",
    "        \n",
    "        #gathering only the latent end-of-sequence for the linear layer\n",
    "        x_ = x_[:, -1, :]\n",
    "        x_ = self.linear(x_)\n",
    "        return x_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7c4aa07e-cf2c-4894-831f-ed5fb2e5db1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jjw62\\AppData\\Local\\Temp\\ipykernel_23124\\35546507.py:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\utils\\tensor_new.cpp:281.)\n",
      "  features = torch.tensor(time_stamps[timestep_size:]).float()\n"
     ]
    }
   ],
   "source": [
    "Xs, ys = create_timestamps_ds(prices)\n",
    "X_train, X_test, y_train, y_test = train_test_split(Xs,\n",
    "                                                    ys,\n",
    "                                                    test_size=.25,\n",
    "                                                    random_state=42,\n",
    "                                                    shuffle=False)\n",
    "\n",
    "\n",
    "\n",
    "ds = torch.utils.data.TensorDataset(X_train, y_train)\n",
    "dataloader_train = torch.utils.data.DataLoader(ds, batch_size=8, shuffle=True)\n",
    "\n",
    "net = NN()\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "707e9413-1f9b-468a-843d-b681604659ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 250 Val-loss: 0.0118\n",
      "Iteration: 500 Val-loss: 0.0191\n",
      "Iteration: 750 Val-loss: 0.0204\n",
      "Iteration: 1000 Val-loss: 0.0155\n",
      "Iteration: 1250 Val-loss: 0.0143\n"
     ]
    }
   ],
   "source": [
    "iteration = 0\n",
    "for epoch in range(100):\n",
    "    for i, (datapoints, labels) in enumerate(dataloader_train):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        loss = net.sample_elbo(inputs=datapoints,\n",
    "                               labels=labels,\n",
    "                               criterion=criterion,\n",
    "                               sample_nbr=3,\n",
    "                               complexity_cost_weight=1/X_train.shape[0])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        iteration += 1\n",
    "        if iteration % 250 == 0:\n",
    "            net.eval()  # 평가 모드로 전환\n",
    "            with torch.no_grad():\n",
    "                preds_val = net(X_train)[:,0].unsqueeze(1)\n",
    "                loss_val = criterion(preds_val, y_train)\n",
    "            net.train()  # 다시 학습 모드로 전환\n",
    "            print(\"Iteration: {} Val-loss: {:.4f}\".format(str(iteration), loss_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "1b14821f-cdee-433b-9a30-14c02b2dad0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Test Loss: 0.0112\n"
     ]
    }
   ],
   "source": [
    "net.eval()\n",
    "with torch.no_grad():\n",
    "    preds_test = net(X_test)[:,0].unsqueeze(1)\n",
    "    loss_test = criterion(preds_test, y_test)\n",
    "print(\"Final Test Loss: {:.4f}\".format(loss_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a0f5b75d-6d72-4c55-8d65-e7cd1c885b13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkIAAAGdCAYAAAD+JxxnAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAABaZ0lEQVR4nO3deXhTVf4G8DdJk7RpSUv3hba0FFnLLqUiiEOlIOMPBBURBRRhQHREFLGOijoz4sA4rgiuoIIiuAsCFmQRqCAVZC9QCmXrCk26L8n5/XHb0EApDaS9Wd7P8+TJck9uvomRvD333HMUQggBIiIiIjeklLsAIiIiIrkwCBEREZHbYhAiIiIit8UgRERERG6LQYiIiIjcFoMQERERuS0GISIiInJbDEJERETktjzkLsCRmc1mnD17Fq1atYJCoZC7HCIiImoCIQSKi4sRHh4OpbLxPh8GoUacPXsWkZGRcpdBRERE1+DUqVNo06ZNo20YhBrRqlUrANIHqdfrZa6GiIiImsJoNCIyMtLyO94YBqFG1B0O0+v1DEJEREROpinDWjhYmoiIiNwWgxARERG5LQYhIiIiclscI0RERHQNhBCoqamByWSSuxS3pFaroVKprns/DEJEREQ2qqqqwrlz51BWViZ3KW5LoVCgTZs28PHxua79MAgRERHZwGw2IysrCyqVCuHh4dBoNJx0t4UJIZCfn4/Tp0+jffv219UzxCBERERkg6qqKpjNZkRGRkKn08ldjtsKCgrCiRMnUF1dfV1BiIOliYiIrsHVlm6g5mWvXjj+VyQiIiK3xSBEREREbotBiIiIiOxq4sSJGDlypOX+oEGDMGPGDNnqaQyDEBERkZuYOHEiFAoFFAoFNBoN4uLi8PLLL6OmpqZZX/ebb77BP//5zya13bRpExQKBYqKipq1pjo8a4yI5GOqBs5nAQUZQMERoCRf7oqaRucP3PiwdE3kZIYOHYrFixejsrISP/30E6ZPnw61Wo2UlBSrdlVVVdBoNHZ5TX9/x/1/hUGIiJpfVakUdAqOAvkZUvDJPwKcPw6Yq+Wu7tocTQUmrgI8tHJXQg5ACIHyanlmmPZSq2w6g0qr1SI0NBQAMG3aNHz77bf44YcfkJGRgaKiItx4441YsGABtFotsrKycOrUKTz55JP4+eefoVQqMWDAALz55pto27YtAMBkMmHWrFn4+OOPoVKpMGnSJAghrF5z0KBB6NGjB9544w0AQGVlJV544QV8/vnnyMvLQ2RkJFJSUjB48GDceuutAIDWrVsDACZMmIAlS5Zc34fUCAYhIrIfIYDcA8Dp36Xgk1/b02M4deXnqHVAYHsgsAPgGwEoHPyIvRDAro+A0zuB1U8C//c2wMn03F55tQmdX1gny2sffDkZOs21/5x7eXmhsLAQALBhwwbo9XqkpqYCAKqrq5GcnIzExET8+uuv8PDwwL/+9S8MHToUe/fuhUajwWuvvYYlS5bg448/RqdOnfDaa6/h22+/xV/+8pcrvub48eORlpaGt956C927d0dWVhYKCgoQGRmJr7/+GqNHj0ZGRgb0ej28vLyu+b01BYOQHCqLgcxfWv51VRrAqzXg6Sdde/nxr1m6fmYzcGYXcOgH4NCPwIUTDbfTBUhhJ+gG62t9BOBs87G07Q8suxvY/RkQ1h3oO1nuiohsJoTAhg0bsG7dOjz22GPIz8+Ht7c3PvzwQ8shsaVLl8JsNuPDDz+09DotXrwYfn5+2LRpE4YMGYI33ngDKSkpGDVqFABg0aJFWLfuyqHwyJEjWLFiBVJTU5GUlAQAiI2NtWyvO4wWHBwMPz+/5njrVhiE5FCcC6wYL3cVErWuXjCqDUdeftZhKSAOiLmFf/XSRaZq4MRWKfgcXg2U5Fzc5uEJRCUCwZ2AwBuAoA5S4PEOkK9ee4tLApJeAlKfB9bMBoI6AjED5K6KZOSlVuHgy8myvbYtVq1aBR8fH1RXV8NsNuO+++7Diy++iOnTpyM+Pt5qXNCff/6JY8eOoVWrVlb7qKioQGZmJgwGA86dO4eEhATLNg8PD/Tp0+eyw2N19uzZA5VKhVtuucWmupsLg5Ac1LU/FC2tpgIoLwLKLwAVBgACqC6TLsVnG39umxuB214Gom9qiUrJEVWXSz2Zh34EMtYAFUUXt2n1wA3JQKc7pJCg8ZatzBZz02NAzj5g3wrpD5spm4DW0XJXRTJRKBTXdXiqJd16661YuHAhNBoNwsPD4eFxsW5vb+v/d0tKStC7d28sW7bssv0EBQVd0+s396EuWznHfzVX49sGeGitvDWYzUCloV4wqr2+9H7ZBeD4RmnMx+JhwA3DgKQ50l/75PoqDMCRn6XDXsfWS6G5ji4Q6Dgc6PR/QMxAwMM+Z5c4DYUC+L+3pDFQ5/YAy+8DJv3sHiGQnJq3tzfi4uKa1LZXr1748ssvERwcDL1e32CbsLAw7NixAwMHDgQA1NTUID09Hb169WqwfXx8PMxmMzZv3mw5NFZfXY+UydQyg88ZhNyVUnnxcBhiGm9bnANsehX441PgyBrg6Dqgx33AoGelwa1yy9kP7F0OZP0KmOU5a8MlCbP0I1//rC7fSKnXp+Nfgah+gPLaFzp0CWov4N5lwPuDgNz9wHePAHcv4WFkchnjxo3D/PnzMWLECLz88sto06YNTp48iW+++QZPP/002rRpg8cffxyvvvoq2rdvj44dO+J///tfo3MAtW3bFhMmTMBDDz1kGSx98uRJ5OXl4Z577kF0dDQUCgVWrVqF22+/HV5eXvDx8Wm298ggRFfXKhS44w0gcTqw4SXp0MjupcC+r4B+04D+M6SxRC2pOAfYtxL480sgd1/Lvra7CewAdPqrFIDCevBH/lK+bYB7PgM+uQM4+B3w62vAwKfkrorILnQ6HbZs2YLZs2dj1KhRKC4uRkREBAYPHmzpIXryySdx7tw5TJgwAUqlEg899BDuvPNOGAyGK+534cKFePbZZ/HII4+gsLAQUVFRePbZZwEAEREReOmll/DMM8/gwQcfxPjx45v19HmFuNJoJoLRaISvry8MBsMVuwTd0qmdQOoLQHaadN+rNTDgKenMmeY8C62qVBqY++dy6XCdMEuPK9XS+JQud9b2cJHd+EVJp7bT1aUvAX58HIACGLsc6DBU7oqomVRUVCArKwsxMTHw9PSUuxy31dh/B1t+v9kjRLaL7As8uAY4shZY/yKQfxj4+R/AjveAvzwHxN9tv9OhzSYgawuw90upJ6qq5OK2Nn2B7mOALqM4wy/Jr/dE4NxeaY6hrx8GJm+QzpgjIofGIETXRqEAOgwD4m4D/vwc2PgKYMgGvp0CbH8buO1FoN3gaz+MkntQGvezd6X1GW2t2wLd7gW63QMEtLPHOyGyn6GvSn8YnNwGfDEWmPxLyx82JiKbMAjR9VF5AL3GA13vAnYsAra+Lo3ZWToaCO8JePnXC0OK2tu19xu6rVAARSel05LrePpKvT7d7wUiEzhGhRyXhwa4+xPgg1uB85nA15OA+1ZwUDmRA2MQIvvQ6IABM6XDA1v+C/z+AXB297Xvr27cT7cx0jVnwCZn4RMknUn2UbI05cCGl6Q5uIjIITEIkX3p/IGhr0hnk2Wn1TudXUhrNKF2bH5Dt+vG7at1QPvbOO6HnFdYd2DEO1KP0LY3gdBuQPxdcldFRA1gEKLm4RcpXYjcVfxd0txCW18Hvp8ujWkL7yl3VUR0CSdb6ZCIyIn85Xmg/RBpeZvl44CSPLkrIqJLMAgRETUXpQoY/aG0cLHxjLQmWU2V3FURUT0MQkREzcnTF7j3C2lh2uw0YNsbcldE1KwmTpyIkSNHyl1GkzEIERE1t6AbgGHzpNvpn3BNPJLNxIkToVAooFAooFarERMTg6effhoVFRVylyYbBiEiopbQ5U6pd8h4WpotnUgmQ4cOxblz53D8+HG8/vrreO+99zBnzhy5y5INgxARUUtQe0oTjwLAnmXy1kJuTavVIjQ0FJGRkRg5ciSSkpKQmpoKADCbzZg7dy5iYmLg5eWF7t2746uvvrI812QyYdKkSZbtHTp0wJtvvinXW7ELnj5PRNRSeoyT1iI79CNQYZB6iMg1CAFUl8nz2mrdNc+4v3//fmzfvh3R0dEAgLlz52Lp0qVYtGgR2rdvjy1btuD+++9HUFAQbrnlFpjNZrRp0wYrV65EQEAAtm/fjilTpiAsLAz33HOPPd9Vi2EQIiJqKRG9gKCO0npkB76VZmIn11BdBrwSLs9rP3sW0Hg3ufmqVavg4+ODmpoaVFZWQqlU4p133kFlZSVeeeUVrF+/HomJiQCA2NhYbN26Fe+99x5uueUWqNVqvPTSS5Z9xcTEIC0tDStWrGAQIiKiq1AogB73AakvALuXMQiRLG699VYsXLgQpaWleP311+Hh4YHRo0fjwIEDKCsrw2233WbVvqqqCj17XpwMdMGCBfj444+RnZ2N8vJyVFVVoUePHi38LuyHQYiIqCV1GwOsfwk4vRMoOAoEtpe7IrIHtU7qmZHrtW3g7e2NuLg4AMDHH3+M7t2746OPPkLXrl0BAKtXr0ZERITVc7Raab3H5cuX46mnnsJrr72GxMREtGrVCvPnz8eOHTvs8EbkwSBERNSSWoUCcUnA0XXSoOmkF+WuiOxBobDp8JSjUCqVePbZZzFz5kwcOXIEWq0W2dnZuOWWWxpsv23bNtx000145JFHLI9lZma2VLnNgmeNERG1tJ7jpOs/l3NOIZLd3XffDZVKhffeew9PPfUUnnjiCXzyySfIzMzEH3/8gbfffhuffPIJAKB9+/bYtWsX1q1bhyNHjuD555/H77//LvM7uD42BaG2bdtaJmKqf5k+fToAYNCgQZdtmzp1qtU+srOzMXz4cOh0OgQHB2PWrFmoqamxarNp0yb06tULWq0WcXFxWLJkyWW1LFiwAG3btoWnpycSEhKwc+dOq+0VFRWYPn06AgIC4OPjg9GjRyM3N9eWt0tE1DxuGAp4tQaKzwGZG+Wuhtych4cHHn30UcybNw8pKSl4/vnnMXfuXHTq1AlDhw7F6tWrERMTAwD429/+hlGjRmHMmDFISEhAYWGhVe+QUxI2yMvLE+fOnbNcUlNTBQCxceNGIYQQt9xyi5g8ebJVG4PBYHl+TU2N6Nq1q0hKShK7d+8WP/30kwgMDBQpKSmWNsePHxc6nU7MnDlTHDx4ULz99ttCpVKJtWvXWtosX75caDQa8fHHH4sDBw6IyZMnCz8/P5Gbm2tpM3XqVBEZGSk2bNggdu3aJfr16yduuukmW96uMBgMAoDVeyAisovVTwkxRy/EiolyV0I2Ki8vFwcPHhTl5eVyl+LWGvvvYMvvt01B6FKPP/64aNeunTCbzUIIKQg9/vjjV2z/008/CaVSKXJyciyPLVy4UOj1elFZWSmEEOLpp58WXbp0sXremDFjRHJysuV+3759xfTp0y33TSaTCA8PF3PnzhVCCFFUVCTUarVYuXKlpc2hQ4cEAJGWltbk98cgRETN5sxuKQi9HCRE2Xm5qyEbMAg5BnsFoWseI1RVVYWlS5fioYcegqLeRE7Lli1DYGAgunbtipSUFJSVXZxgKi0tDfHx8QgJCbE8lpycDKPRiAMHDljaJCUlWb1WcnIy0tLSLK+bnp5u1UapVCIpKcnSJj09HdXV1VZtOnbsiKioKEubhlRWVsJoNFpdiIiaRVh3ILgLYKoE9n8tdzVEbuuag9B3332HoqIiTJw40fLYfffdh6VLl2Ljxo1ISUnBZ599hvvvv9+yPScnxyoEAbDcz8nJabSN0WhEeXk5CgoKYDKZGmxTfx8ajQZ+fn5XbNOQuXPnwtfX13KJjIxs2odBRGQrheLioOk9n8tbC5Ebu+bT5z/66CMMGzYM4eEXZ9KcMmWK5XZ8fDzCwsIwePBgZGZmol27dtdXaQtISUnBzJkzLfeNRiPDEBE1n/h7pMkVz6QDeYeB4I5yV0Tkdq6pR+jkyZNYv349Hn744UbbJSQkAACOHTsGAAgNDb3szK26+6GhoY220ev18PLyQmBgIFQqVYNt6u+jqqoKRUVFV2zTEK1WC71eb3UhImo2PkFA+2TpNhdiJZLFNQWhxYsXIzg4GMOHD2+03Z49ewAAYWFhAIDExETs27cPeXl5ljapqanQ6/Xo3Lmzpc2GDRus9pOammpZ90Sj0aB3795WbcxmMzZs2GBp07t3b6jVaqs2GRkZyM7OtrQhInIIPe6Trvd+CZhqGm9LDkUIIXcJbs1en7/Nh8bMZjMWL16MCRMmwMPj4tMzMzPx+eef4/bbb0dAQAD27t2LJ554AgMHDkS3bt0AAEOGDEHnzp3xwAMPYN68ecjJycFzzz2H6dOnW6bvnjp1Kt555x08/fTTeOihh/DLL79gxYoVWL16teW1Zs6ciQkTJqBPnz7o27cv3njjDZSWluLBBx8EAPj6+mLSpEmYOXMm/P39odfr8dhjjyExMRH9+vW7rg+MiMiu2g8BdAFASS6QuQG4IVnuiugq1Go1AKCsrAxeXl4yV+O+qqqqAAAqleq69mNzEFq/fj2ys7Px0EMPWT2u0Wiwfv16SyiJjIzE6NGj8dxzz1naqFQqrFq1CtOmTUNiYiK8vb0xYcIEvPzyy5Y2MTExWL16NZ544gm8+eabaNOmDT788EMkJ1/8x2HMmDHIz8/HCy+8gJycHPTo0QNr1661GkD9+uuvQ6lUYvTo0aisrERycjLeffddW98uEVHz8tBI64/99q50eIxByOGpVCr4+flZjm7odDqrs6ep+ZnNZuTn50On01l1ylwLhWDf3hUZjUb4+vrCYDBwvBARNZ+cfcCimwGVBngyA9D5y10RXYUQAjk5OZeNRaWWo1QqERMTA41Gc9k2W36/uegqEZHcQuOB0G5Azl5g31dAwpSrP4dkpVAoEBYWhuDgYFRXV8tdjlvSaDRQKq9/yVQGISIiR9BjHLB2L7BnKYOQE1GpVNc9RoXkxdXniYgcQfzdgFINnPsTyNkvdzVEboNBiIjIEXgHAB2GSrf//ELeWojcCIMQEZGj6FG7JNHeLwETx50QtQQGISIiRxE3GPAOBkrzgaOpcldD5BYYhIiIHIVKDXS7R7rNJTeIWgSDEBGRI+lRuyL9kbVAaYG8tRC5AQYhIiJHEtIZCO8JmGuAfSvlrobI5TEIERE5mrpeod08PEbU3BiEiIgcTdfR0nIbufuAc3vlrobIpTEIERE5Gp0/0HG4dJuDpomaFYMQEZEjqjs8tncFUFMlby1ELoxBiIjIEcXeCviEAuXnpTPIiKhZMAgRETkilQfQ/V7p9p7P5a2FyIUxCBEROaq6w2NHfwZK8uSthchFMQgRETmqoBuANjcCwiStP0ZEdscgRETkyLrcKV2fTJO3DiIXxSBEROTI9BHSdVmhvHUQuSgGISIiR+YdKF2Xcd0xoubAIERE5Mh0AdI1e4SImgWDEBGRI9PV9giVXwBMNfLWQuSCGISIiByZV+uLt8svyFcHkYtiECIicmQqj4thiOOEiOyOQYiIyNFxnBBRs2EQIiJydHXjhErZI0RkbwxCRESOjj1CRM2GQYiIyNF5MwgRNRcGISIiR8ceIaJmwyBEROToOEaIqNkwCBEROTr2CBE1GwYhIiJHx/XGiJoNgxARkaPT+UvXZeflrYPIBTEIERE5uvpjhISQtxYiF8MgRETk6OrGCJkqgapSeWshcjEMQkREjk7jDXh4Src5TojIrhiEiIgcnULBM8eImgmDEBGRM6gLQqUMQkT2xCBEROQM2CNE1CwYhIiInAHnEiJqFgxCRETOgD1CRM2CQYiIyBlwvTGiZsEgRETkDDi7NFGzYBAiInIGHCNE1CwYhIiInAHHCBE1CwYhIiJnwDFCRM2CQYiIyBnU9QhVFAGmGllLIXIlDEJERM7AqzUAhXS7nAOmieyFQYiIyBmoPAAvP+k2xwkR2Y2H3AW4o6KyKkz6ZBeCW2kRovdEUCut5XawXovgVp5orVNDoVDIXSoRNZEQAmYBmMwCJrNAjdlsuS3dF/BQKhDUSnvt/2/rAoHyCxwnRGRHDEIyyDFWIP3khUbbaFRKKSDppZAU3MoTIXUhyVsDH62HdPH0gLdWhVZaNTzVSoYnonoqqk0orqiBsaIaxvLqerdrUFxRjZLKGlTWmFFVY0ZljQmVNeZ6982oqn2syupxE6pqzKgxC5hrA05d0GmKfrH+SBnWCd0j/Wx/Q7oAoPAoe4SI7IhBSAZhvl54d1wv5BkrkFdciVxjJfKKK5BfXIlcYwUulFWjymTGmaJynCkqb/J+VUoFvDWqegHJ42Jg0npAp1FBq1ZBo1JC46GE1qPuWnXJ/YuPaz2U8FQrodN4wFvjAZ1WBbWKR1RJPpU1Jpy+UI7swjJkn5cuOYYKKeBU1KC4vNpyu6rGLHe5AKT/N1UKBarNZvx2/DxGLNiG4d3CMGtIB7QN9G76jjiXEJHdMQjJwNdLjdvjw664vbLGhPziSuQVVyKvNiTVXecaK1FUXo3SyhqUVNRI11U1ELVd8saKGhgragBD89WvUSmh06qkYKRRwVsr9UpJYUkFnVa69vfWIiHWH90ifOHB8ERNJITA+dIqnDxfhlPnyyyBp+5+jrECommdLwAAhQLw0XpA76mG3kuNVp61tz2lPxg8a/84sP5DQNXgHwZ197UeSqiUCngolVCpFPBQKqBUSNeX3VcqLD21Z4rK8b+fj+Cb3aexeu85rNufg/sSovD3we0R6KO9+pvh7NJEdscg5IC0Hiq0aa1Dm9a6JrU3mwXKq00oqayRLrUBqbjudlUNiitqUF5lQpWp4cMA9bv8Lz0UUF5tsjwXgLSPMjOKyqqbVF8rrQcSYgPQPy4AN8cFIi7Yh4fw3JzZLJBXXImsglKcLCxFVmEpThSU4mShFHZKq0yNPt9bo0Kkvw7RATpE+esQ7ucFXy819J61QcfrYujx0XhAqXSM71uEnxdeu6c7Hh4Qg/+sPYxNGfn4NO0kvk4/jckDYzF5QCy8tY38s8y5hIjsTiGELX9buRej0QhfX18YDAbo9Xq5y5FdVY0Z5VUmlFbVoKyqBqWVtbfrrqtMKK2sva6qwcmCMqQdL4Sh3DowBbfSon9cYO0lAGG+XjK9I2pOjYWdE4WlqKhu/LBVmK+nFHb8pbATFaCz3Pf31rhEmN6eWYD/rDmMP09LXbiBPho8Prg97u0b1fAh6O3vAD//A+h6F3DXRy1cLZHzsOX3m0GoEQxC189kFjh41oitxwqw7VgBfj9xHpWXjNuIDfLGzXGBuKldIBJjA+CrU8tU7ZXV9bqVVZlQVhv6yqtrB82aBKrN0nWNyYxqs3Rd93h17cDa6nrbzWYBc+1ZRmZRd7/2du3FZK47E8n6tgAgBCAgtYcABIT0WO0+6tqg7nFIz5cekdQ9jnrbYLXt8scaul37Klb3i8qqrxp2VEoF2rT2QtsAb7QN0KFtoHdtD4832rT2gqda1YT/Ms5PCIGf9uVg/rrDOFFYBgBoG6DDrOSOuD0+1Drw/bkc+PZvQOwgYPz38hRM5AQYhOyEQcj+KqpN+OPkBSkYZRZi3+ki1D/ZRqkAOoXp0TbAGxGtvRDu64mI1jpE+Hkhws8Lei+Pa+4JqBt7kmOsQI6hAjnGCuQapAHrJZXSocOyKhPKqk0or+3xksJPzVV7L6hhDYWdtgHeaBsohR0OvL+o2mTG8p3ZeHPDURSUVAEAukf64ZmhHZHYrnZW6aOpwLK7gNB4YOpWGaslcmzNFoTatm2LkydPXvb4I488ggULFqCiogJPPvkkli9fjsrKSiQnJ+Pdd99FSEiIpW12djamTZuGjRs3wsfHBxMmTMDcuXPh4XHxuPimTZswc+ZMHDhwAJGRkXjuuecwceJEq9dcsGAB5s+fj5ycHHTv3h1vv/02+vbta9nelFquhkGo+RnKqpF2vBDbMwuw9VgBjueXNtreR+uBcD9PRPh5Ibz20qa1dB3grUFhaRVyDBXIrRd26q7zjJWWcU7XQ6dRQadRwUsjnUGnVirhoVLAQ6WEWqmAWiXdV6uU8Kh330OphFqlgIdKOoNIWTugVqmA5baq9r5CIQ2yrb9NqQCUtSFQoVBAAWkgsFKhgEJRO+dwvccVuPh43fNgfWXZT+1Tra9rn9+Q+mFUYfW4dO2t8WDYuUYllTX4YMtxfPDrcZTVjpW6tUMQXh7RFZHlh4EPbgVahQNPHpK5UiLH1WxBKD8/HybTxUGM+/fvx2233YaNGzdi0KBBmDZtGlavXo0lS5bA19cXjz76KJRKJbZt2wYAMJlM6NGjB0JDQzF//nycO3cO48ePx+TJk/HKK68AALKystC1a1dMnToVDz/8MDZs2IAZM2Zg9erVSE5OBgB8+eWXGD9+PBYtWoSEhAS88cYbWLlyJTIyMhAcHAwAV63F3h8k2cc5Qzn+PFWE0xfKcbaoAmeKynC2qAJni8pRWFpll9cI9NEgRO+JUL0nQnw9EdLKEz6eHpaAo6s9G85Lc/HMOK/abZ4eKocZeEuuLa+4Am9vOIYvdmajxizQPtgHqx6IgnZBD0ClBZ7LxRWTKpGba7FDYzNmzMCqVatw9OhRGI1GBAUF4fPPP8ddd90FADh8+DA6deqEtLQ09OvXD2vWrMFf//pXnD171tIzs2jRIsyePRv5+fnQaDSYPXs2Vq9ejf3791te595770VRURHWrl0LAEhISMCNN96Id955BwBgNpsRGRmJxx57DM888wwMBsNVa2kKBiHHUl5lwllDOc5cKMfZ2jmWzhRdvF1YUoUAH40UcPSeCPOVrkN9PS2PBeu10Hq4x9gTcg3H80twz3u/oaCkElMTQ/HM7r9IG1JOA9pW8hZH5KBs+f2+5tPnq6qqsHTpUsycORMKhQLp6emorq5GUlKSpU3Hjh0RFRVlCR9paWmIj4+3OjyVnJyMadOm4cCBA+jZsyfS0tKs9lHXZsaMGZbXTU9PR0pKimW7UqlEUlIS0tLSAKBJtTSksrISlZWVlvtGo/FaPx5qBl4aFdoF+aBdkI/cpRC1mNggH/xndDwmfbILi9LOYZa3FipTpTS7NIMQ0XW75oP33333HYqKiixjd3JycqDRaODn52fVLiQkBDk5OZY2l47Rqbt/tTZGoxHl5eUoKCiAyWRqsE39fVytlobMnTsXvr6+lktkZOTVPwgiomY2uFMIxvaNAqBAvqk2/JRymQ0ie7jmIPTRRx9h2LBhCA8Pt2c9skpJSYHBYLBcTp06JXdJREQAgOeGd0LbAB0KzLU9olxvjMgurikInTx5EuvXr8fDDz9seSw0NBRVVVUoKiqyapubm4vQ0FBLm9zc3Mu2121rrI1er4eXlxcCAwOhUqkabFN/H1erpSFarRZ6vd7qQkTkCLy1HvjfmB44D6lHaE/GMZkrInIN1xSEFi9ejODgYAwfPtzyWO/evaFWq7FhwwbLYxkZGcjOzkZiYiIAIDExEfv27UNeXp6lTWpqKvR6PTp37mxpU38fdW3q9qHRaNC7d2+rNmazGRs2bLC0aUotRETOpldUawQFS73wG9IPIcdQIXNFRC5A2MhkMomoqCgxe/bsy7ZNnTpVREVFiV9++UXs2rVLJCYmisTERMv2mpoa0bVrVzFkyBCxZ88esXbtWhEUFCRSUlIsbY4fPy50Op2YNWuWOHTokFiwYIFQqVRi7dq1ljbLly8XWq1WLFmyRBw8eFBMmTJF+Pn5iZycnCbX0hQGg0EAEAaDwabnERE1l5rVTwsxRy/e/cc4cf+Hvwmz2Sx3SUQOx5bfb5uD0Lp16wQAkZGRcdm28vJy8cgjj4jWrVsLnU4n7rzzTnHu3DmrNidOnBDDhg0TXl5eIjAwUDz55JOiurraqs3GjRtFjx49hEajEbGxsWLx4sWXvdbbb78toqKihEajEX379hW//fabzbVcDYMQETmczfOEmKMXK54fIaJnrxKfbM+SuyIih2PL7zeX2GgE5xEiIoez62Ng1RPIDhqEgaemwFOtxKrHBiAumNNKENWx5febc98TETkTXSAAIFJbjgHtA1FRbcbMFXtQbYflY4jcEYMQEZEz0UkLsCrKCjD/ru7w9VJj72kD3v6FZ5ERXQsGISIiZ+It9QihrBChvp74951dAQALNh7DH9kXZCyMyDkxCBEROZPaHiFUFAGmavy1WzhG9giHySww88s9KKuqkbU8ImfDIERE5Ey8WgOoXXW+XOoBemlEV4T5euJEYRn+vfqQfLUROSEGISIiZ6JU1YYhAKUFAABfLzVeu7s7AGDZjmxsPJx3pWcT0SUYhIiInE29cUJ1booLxKSbYwAAs77ai/OlVXJURuR0GISIiJxN3TihsgKrh2cld0D7YB8UlFQi5Zu94DRxRFfHIERE5GwsQch6BXpPtQqvj+kBtUqBdQdy8fUfZ2Qojsi5MAgRETmbuiBUWnjZpq4RvnjithsAAC/+cACnzpe1ZGVETodBiIjI2TQwRqi+vw1shz7RrVFSWYNX1x5uwcKInA+DEBGRs7nCGKE6KqUCTw7pAAD481RRCxVF5JwYhIiInI2u8R4hAGgfIi3CeqaoHBXVppaoisgpMQgRETmbRsYI1Qnw1kDv6QEhgBOFpS1UGJHzYRAiInI23g2fNVafQqFAbJDUK3Q8n0GI6EoYhIiInE39MUKNzBUUG+QNAMjMK2mJqoicEoMQEZGzqRsjZKoCKouv2KxdXY9QAXuEiK6EQYiIyNlodICHl3S7kcNjsYFSj9DxfPYIEV0JgxARkTO6ylxCAKzGCHG5DaKGMQgRETkjnb903UgQig7QQakAiitrkF9S2UKFETkXBiEiImdUN06otOFJFQFp7bE2rXUAeOYY0ZUwCBEROaMrLLx6qbozxxiEiBrGIERE5IwsY4Su3CMEALGBdeOEOGCaqCEMQkREzqgJY4SAej1CPIWeqEEMQkREzsgyRqiph8bYI0TUEAYhIiJn1MQxQnWTKmafL0NlDRdfJboUgxARkTNq4hih4FZaeGtUMAsgu7CsBQojci4MQkREzqiJPUL1F1/N5JljRJdhECIickZ1Y4QqDICputGm7SwDpjlOiOhSDEJERM7Iyw+AQrpddr7RpvWX2iAiawxCRETOSKmqdwr9VeYS4pljRFfEIERE5KyaOrt03aSKnEuI6DIMQkREzqoJ640BQEyg1CNUVFaN86VVzV0VkVNhECIiclZNnF3aS6NChJ8XAB4eI7oUgxARkbOyzCXUeBACuPgq0ZUwCBEROasmjhECgNjaw2OZ7BEissIgRETkrJo4RggAJ1UkugIGISIiZ2VDj1DdmmOcVJHIGoMQEZGz8rbh0FjtGKHswjJUm8zNWRWRU2EQIiJyVjb0CIXqPeGlVqHGLHDqPBdfJarDIERE5KzqjxESotGmSqXCMp8QzxwjuohBiIjIWdX1CJmrgcriqzaP5eKrRJdhECIiclYaHaDWSbevst4YwMVXiRrCIERE5Mws44QaX4EeANpxUkWiyzAIERE5s7og1JS5hALr5hLioTGiOgxCRETOzIYzx2Jqe4QKS6tgKKtuzqqInAaDEBGRM7OsN3b1HiEfrQdC9Z4AgEwOmCYCwCBEROTcbOgRArj4KtGlGISIiJyZZYyQrUGIPUJEAIMQEZFzs7VHKJCn0BPVxyBEROTMbBgjBHBSRaJLMQgRETkzG3uE6lahP1FYBpO58WU5iNwBgxARkTOzrDfWtCAU7ucFjYcSVTVmnLlQ3oyFETkHBiEiImdW1yNUaQBMV58bSKVUICZAOjzGU+iJGISIiJyblx+gqP2n3MZT6DPzGISIGISIiJyZUgV4tZZu2zhO6HgBzxwjsjkInTlzBvfffz8CAgLg5eWF+Ph47Nq1y7J94sSJUCgUVpehQ4da7eP8+fMYN24c9Ho9/Pz8MGnSJJSUWP9lsnfvXgwYMACenp6IjIzEvHnzLqtl5cqV6NixIzw9PREfH4+ffvrJarsQAi+88ALCwsLg5eWFpKQkHD161Na3TETk2CzjhGw8c4xzCRHZFoQuXLiA/v37Q61WY82aNTh48CBee+01tG7d2qrd0KFDce7cOcvliy++sNo+btw4HDhwAKmpqVi1ahW2bNmCKVOmWLYbjUYMGTIE0dHRSE9Px/z58/Hiiy/i/ffft7TZvn07xo4di0mTJmH37t0YOXIkRo4cif3791vazJs3D2+99RYWLVqEHTt2wNvbG8nJyaioqLDpQyIicmg2zy7NuYSILIQNZs+eLW6++eZG20yYMEGMGDHiitsPHjwoAIjff//d8tiaNWuEQqEQZ86cEUII8e6774rWrVuLyspKq9fu0KGD5f4999wjhg8fbrXvhIQE8be//U0IIYTZbBahoaFi/vz5lu1FRUVCq9WKL7744upvVghhMBgEAGEwGJrUnohIFsvHCTFHL8SO95vU3FBeJaJnrxLRs1cJY3lVMxdH1PJs+f22qUfohx9+QJ8+fXD33XcjODgYPXv2xAcffHBZu02bNiE4OBgdOnTAtGnTUFh48a+UtLQ0+Pn5oU+fPpbHkpKSoFQqsWPHDkubgQMHQqPRWNokJycjIyMDFy5csLRJSkqyet3k5GSkpaUBALKyspCTk2PVxtfXFwkJCZY2l6qsrITRaLS6EBE5PBt7hPSeagT6aAEAWRwnRG7OpiB0/PhxLFy4EO3bt8e6deswbdo0/P3vf8cnn3xiaTN06FB8+umn2LBhA/7zn/9g8+bNGDZsGEwmEwAgJycHwcHBVvv18PCAv78/cnJyLG1CQkKs2tTdv1qb+tvrP6+hNpeaO3cufH19LZfIyMimfzhERHKxcYwQwMVXiep42NLYbDajT58+eOWVVwAAPXv2xP79+7Fo0SJMmDABAHDvvfda2sfHx6Nbt25o164dNm3ahMGDB9uxdPtLSUnBzJkzLfeNRiPDEBE5Pht7hACgXZA3dmad54Bpcns29QiFhYWhc+fOVo916tQJ2dnZV3xObGwsAgMDcezYMQBAaGgo8vLyrNrU1NTg/PnzCA0NtbTJzc21alN3/2pt6m+v/7yG2lxKq9VCr9dbXYiIHJ6N640BFxdfzeShMXJzNgWh/v37IyMjw+qxI0eOIDo6+orPOX36NAoLCxEWFgYASExMRFFREdLT0y1tfvnlF5jNZiQkJFjabNmyBdXVF2dJTU1NRYcOHSxnqCUmJmLDhg1Wr5WamorExEQAQExMDEJDQ63aGI1G7Nixw9KGiMgl6Pyl67LzTX4KD40R1bJlFPbOnTuFh4eH+Pe//y2OHj0qli1bJnQ6nVi6dKkQQoji4mLx1FNPibS0NJGVlSXWr18vevXqJdq3by8qKios+xk6dKjo2bOn2LFjh9i6dato3769GDt2rGV7UVGRCAkJEQ888IDYv3+/WL58udDpdOK9996ztNm2bZvw8PAQ//3vf8WhQ4fEnDlzhFqtFvv27bO0efXVV4Wfn5/4/vvvxd69e8WIESNETEyMKC8vb9L75VljROQUzuyWzhqbf0OTn5KVXyKiZ68SHZ77SZhM5uarjUgGtvx+2xSEhBDixx9/FF27dhVarVZ07NhRvP/+xdM1y8rKxJAhQ0RQUJBQq9UiOjpaTJ48WeTk5Fjto7CwUIwdO1b4+PgIvV4vHnzwQVFcXGzV5s8//xQ333yz0Gq1IiIiQrz66quX1bJixQpxww03CI1GI7p06SJWr15ttd1sNovnn39ehISECK1WKwYPHiwyMjKa/F4ZhIjIKVzIloLQSwFCmJsWaqprTCLu2dUievYqcep8aTMXSNSybPn9VgghhLx9Uo7LaDTC19cXBoOB44WIyHFVlwP/rh37+Ew24OnbpKcl/W8zjuWV4NOH+mLgDUHNWCBRy7Ll95trjREROTu1F6CWxvzYcuZYbCCX2iBiECIicgV1p9CX2hCEuPgqEYMQEZFL8LZ9LiGeOUbEIERE5Boskyo2fS6hdlyFnohBiIjIJdQts2HTGCHp0NhZQwXKqmqaoyoih8cgRETkCixjhJreI9TaWwN/b2lxay6+Su6KQYiIyBVYxgg1fXZpoP6ZYwxC5J4YhIiIXME1jBECLg6YzuQ4IXJTDEJERK7gGsYIAfVOoWePELkpBiEiIldwDWOEgHqHxgrYI0TuiUGIiMgVeNf1CNk4Rqi2RygrvxRccYncEYMQEZErqOsRqjQANVVNflqUvw4qpQKlVSbkGiubqTgix8UgRETkCjz9AEXtP+nlTe8V0ngoEeWvA8CJFck9MQgREbkCpRLw8pduX+M4oUzOJURuiEGIiMhVeF/bmWPtguvOHGOPELkfBiEiIldxrXMJcVJFcmMMQkRErkJ3jbNL1545xkkVyR0xCBERuYprnUuodnbpM0XlqKg22bsqIofGIERE5CqucYxQgLcGek8PCAGcKOThMXIvDEJERK7iGscIKRQKLrVBbotBiIjIVVzjemPAxcNjPHOM3A2DEBGRq9DVzSNkexBqxx4hclMMQkRErsIyRsi2Q2MAJ1Uk98UgRETkKixjhAoBGxdQrT+pIhdfJXfCIERE5CrqgpC5Bqgw2PTU6AAdlAqguKIGBSVNX7SVyNkxCBERuQq1F6CWDnHZOmBa66FCm9ZcfJXcD4MQEZEr8a53eMxGdWeOZXLANLkRBiEiIleiu44gFMjFV8n9MAgREbmSurmEbFxmA6g3lxDPHCM3wiBERORKrqdHiJMqkhtiECIiciXXMZdQ3aSKpy6Uo6rGbM+qiBwWgxARkSupm1267LzNTw1upYW3RgWTWSD7PA+PkXtgECIiciXXMUZIoVBYJlbkmWPkLhiEiIhcyXWMEQIuLrXBNcfIXTAIERG5kusYIwQAsUE8hZ7cC4MQEZErsfQI2T5GCLh45tgxBiFyEwxCRESupC4IVRqBmkqbnx4f4QsA2HfagAulXHOMXB+DEBGRK/H0AxQq6fY19ApFB3ijU5geNWaBnw/m2Lc2IgfEIERE5EqUynqn0F/bOKG/dgsDAKzexyBEro9BiIjI1VznmWO3x0tBaNuxAh4eI5fHIERE5GquYy4hAIgJ9EbnMD1MZoF1B9grRK6NQYiIyNVcx+zSdYZbDo+ds0dFRA6LQYiIyNVc51xCADC89vDY9sxCnOfhMXJhDEJERK7mOscIAUDbQG90CefhMXJ9DEJERK7mOscI1ak7PPYTD4+RC2MQIiJyNXboEQJ4eIzcA4MQEZGr8bZPEIoO8EbXCB4eI9fGIERE5Grs1CMEXJxTaPVeHh4j18QgRETkaurGCJUVAkJc164uHh4rQGGJ7WuXETk6BiEiIldT1yNkrgEqDNe1q+gAb8RH+MIsgHUHcu1QHJFjYRAiInI1ak9A4yPdtufhsX1nr3tfRI6GQYiIyBVZZpe+/iBUd3gsLbOQh8fI5TAIERG5IjvNJQQAUQE6dGsjHR5by7PHyMUwCBERuSI7njkG8Owxcl0MQkRErsgO643VV3d47LfjhSjg4TFyIQxCRESuyM49QpH+9Q6P7efhMXIdDEJERK6oLgiV2icIARd7hbj2GLkSm4PQmTNncP/99yMgIABeXl6Ij4/Hrl27LNuFEHjhhRcQFhYGLy8vJCUl4ejRo1b7OH/+PMaNGwe9Xg8/Pz9MmjQJJSUlVm327t2LAQMGwNPTE5GRkZg3b95ltaxcuRIdO3aEp6cn4uPj8dNPP1ltb0otREQuqS4IZW4A1v0D2P81cD7ruiZYvL3e4bH8Yh4eI9dgUxC6cOEC+vfvD7VajTVr1uDgwYN47bXX0Lp1a0ubefPm4a233sKiRYuwY8cOeHt7Izk5GRUVFZY248aNw4EDB5CamopVq1Zhy5YtmDJlimW70WjEkCFDEB0djfT0dMyfPx8vvvgi3n//fUub7du3Y+zYsZg0aRJ2796NkSNHYuTIkdi/f79NtRARuaSwboBCCZTkAmnvAF89BLzVA5gXCyy9C9j4CnBkHVCS3+RdRvrr0J1nj5GLUQjR9D8PnnnmGWzbtg2//vprg9uFEAgPD8eTTz6Jp556CgBgMBgQEhKCJUuW4N5778WhQ4fQuXNn/P777+jTpw8AYO3atbj99ttx+vRphIeHY+HChfjHP/6BnJwcaDQay2t/9913OHz4MABgzJgxKC0txapVqyyv369fP/To0QOLFi1qUi1XYzQa4evrC4PBAL1e39SPiYjIMZzPArLTgDN/AGfSgZx9gLn68na+UUBEr9pLbyCsB6D1aXCX72/JxCs/HUZibAC+mNKveesnuka2/H7b1CP0ww8/oE+fPrj77rsRHByMnj174oMPPrBsz8rKQk5ODpKSkiyP+fr6IiEhAWlpaQCAtLQ0+Pn5WUIQACQlJUGpVGLHjh2WNgMHDrSEIABITk5GRkYGLly4YGlT/3Xq2tS9TlNquVRlZSWMRqPVhYjIafnHAD3uA4b/F5iyEXj2DDD5F+D2/wLdxwKBHQAoAEM2cPA7IPUFYMlw4NVIYNXMBg+j1R0e25FViLxi9q6T87MpCB0/fhwLFy5E+/btsW7dOkybNg1///vf8cknnwAAcnKkrtKQkBCr54WEhFi25eTkIDg42Gq7h4cH/P39rdo0tI/6r3GlNvW3X62WS82dOxe+vr6WS2Rk5NU+EiIi5+GhlXp8+k4G7lwEPLoTeOYkMP4HIOlFoNMdgD4CEGZg10fA1v9dtos2rXXoHuknrT3Gs8fIBdgUhMxmM3r16oVXXnkFPXv2xJQpUzB58mQsWrSoueprUSkpKTAYDJbLqVOn5C6JiKh5efoCsbcANz8BjFkKzDwI/PV1aduGfwIZay57yl8ta4/x7DFyfjYFobCwMHTu3NnqsU6dOiE7OxsAEBoaCgDIzbVeoTg3N9eyLTQ0FHl5eVbba2pqcP78eas2De2j/mtcqU397Ver5VJarRZ6vd7qQkTkdvo8BPSZBEAAX08G8jOsNg+Ll/4N3ZF1nofHyOnZFIT69++PjAzr/yGOHDmC6OhoAEBMTAxCQ0OxYcMGy3aj0YgdO3YgMTERAJCYmIiioiKkp6db2vzyyy8wm81ISEiwtNmyZQuqqy8O6ktNTUWHDh0sZ6glJiZavU5dm7rXaUotRER0BUNfBaL7A1XFwBf3AuUXLJvatNahR6QfBA+PkSsQNti5c6fw8PAQ//73v8XRo0fFsmXLhE6nE0uXLrW0efXVV4Wfn5/4/vvvxd69e8WIESNETEyMKC8vt7QZOnSo6Nmzp9ixY4fYunWraN++vRg7dqxle1FRkQgJCREPPPCA2L9/v1i+fLnQ6XTivffes7TZtm2b8PDwEP/973/FoUOHxJw5c4RarRb79u2zqZbGGAwGAUAYDAZbPiYiItdQki/E/7oIMUcvxKcjhaiptmz6YEumiJ69StyzaLuMBRI1zJbfb5uCkBBC/Pjjj6Jr165Cq9WKjh07ivfff99qu9lsFs8//7wICQkRWq1WDB48WGRkZFi1KSwsFGPHjhU+Pj5Cr9eLBx98UBQXF1u1+fPPP8XNN98stFqtiIiIEK+++upltaxYsULccMMNQqPRiC5duojVq1fbXEtjGISIyO2d/VOIf4VKYWjts5aHT18oE9GzV4m2z6wSuYam/XFJ1FJs+f22aR4hd8N5hIiIABz4Flg5Ubp953tAd2ketjvf3Ybd2UV4eUQXjE9sK1t5RJdqtnmEiIjIDXW5ExggTUyLH/4OnJbGeNatPbZqL88eI+fFIERERFd36z+AG4YBpkrgy3FAcQ6G1Qah30+cR56RZ4+Rc2IQIiKiq1MqgVHvA0EdgeJzwJf3I8JbgV5R0tlja3j2GDkpBiEiImoaTz1w7+fSJIynfwdWz8TtXaU5hVbz8Bg5KQYhIiJquoB2wF2LpZXt9yzD3abVAIDfT55HLg+PkRNiECIiItvEDQaG/AsA4LvlRTwYekI6PMYlN8gJMQgREZHt+j0CdL8PECY8U/IqohS5+GkfxwmR82EQIiIi2ykU0uKsEX2grTHiA/VrOHjyDHIMPDxGzoVBiIiIro3aU1qx3icUHZSn8T+Pd7Fm3xm5qyKyCYMQERFdO30YcO8y1Cg1GKJKR+D2l4GaKrmrImoyBiEiIro+bfqgdMhrAIA7yr5D+duJwPHNMhdF1DQMQkREdN18+43Hl23+gQKhh5fhGPDp/0nrkxl4qIwcG4MQERHZxU2jHkVyzWv4pOY2CIVSWqz1nRuBrW/wcBk5LAYhIiKyi0h/HYb26YQ5NQ8iJfAtoE1foLoUWD8HWNQfOL5J7hKJLsMgREREdjP91jhoVEosP+WP7YOWASPeBXSBQMER4NMRwIoJPFxGDoVBiIiI7Cbczwtj+0YCAF5ffwyix33AY+lA3ynSshwHv6s9XPY6D5eRQ2AQIiIiu3rk1jhoPJT4/cQFbD1WAHj5AbfPB6ZsBiL71R4uexFYeBOQuVHucsnNMQgREZFdheg9cX9CNADgf6lHIISQNoR1Ax5aC4xcBHgHAYVHgc9GAivGA4WZ8hVMbo1BiIiI7G7qoFh4qpXYnV2ETUfyL25QKIAeY4FHdwEJU2sPl30PvN0LeK2TNIYo7V3g9C4eOqMWoRCWqE6XMhqN8PX1hcFggF6vl7scIiKn8spPh/D+luPo1sYX30/vD4VCcXmjnH3Az88BWb8CwmS9zcMTCO8JtLkRiEwAIvsCPsEtUzw5NVt+vxmEGsEgRER07QpLKjFg3kaUVZnw4fg+SOoccuXGVaXA2d3AqR3AqZ3SdfmFy9u1biuForpwFNwZUHk023sg58QgZCcMQkRE1+c/aw9j4aZMdAnXY9VjNzfcK9QQIaRxQ6d2AKd3SuEo7xCAS36yAjsAD64BvAPsXjs5LwYhO2EQIiK6PhdKq3Dzf35BaZUJ7z3QG8ldQq99ZxUGaexQXY/R6d+BqhKg613AXR/Zr2hyerb8fnOwNBERNZvW3ho82D8GAPB66hGYzdfxt7enLxA3GLg1BRj/HTDhB2mw9f6vgEM/2qdgcjsMQkRE1KweHhCDVloPHM4pxtoDOfbbcURvoP/j0u1VM4Gy8/bbN7kNBiEiImpWfjoNHrr5Yq+Q6Xp6hS41KAUI6giU5gFrZttvv+Q2GISIiKjZPXRzDPSeHjiaV4LV+87Zb8ceWmk9M4US2LcCOLzafvsmt8AgREREzc7XS43JA2IBAG+st3OvUJvewE1/l27/OIOHyMgmDEJERNQiJvZvCz+dGsfzS/HDn3ZegX5QinQqfWkesPYZ++6bXBqDEBERtYhWnmpMGSj1Cr25/ihqTGb77VztCYysPUS290vg8E/22ze5NAYhIiJqMRMS28LfW4MThWX4drede4Xa9AFueky6vWoGD5FRk3BeciIiajHeWg9MvSUWr/x0GG/9chQje0ZArbLj3+SDngUy1gAFR4C1KcCo9+y3b1dXXQEcWy8td2IrpQpo9xdA52//upoZgxAREbWoB/q1xftbsnDqfDm+Tj+Ne/tG2W/nak/pLLKPhwB7lwNdRgIdhtlv/66opgrY/Rmw5b9A8dlr30+rcGmiy6AOdiutJXCJjUZwiQ0ioubx0dYs/HPVQUT4eWHjU4Og8bDzSI2fnwe2vwX4hACP/OaUPRXNzlQjhcXN/wGKsqXHWoUDwR1t31fBUcBwCvDyB+7/GojoZd9abcS1xuyEQYiIqHlUVJswcN5G5BVX4l8ju+L+ftH2fYHqcmDRAKDwKNB9LHDnIvvu35mZTcD+b4BNc4HzmdJjPiHAgCeBXhOkXjVblRYCy0YDZ3cDmlbA2C+AmAH2rdsGXGuMiIgcmqdahem3xgEAFmw8hopqk31fQO0FjFwonUX25xfSuCF3ZzYDB78HFt4EfPOwFIJ0AcBt/wT+vgdI+Nu1hSAA8A4Axv8AtB0AVBUDS0c7zWfOIERERLIYc2Mkwnw9cc5QgS9/P2X/F4i8EUicLt3+cQZQfsH+r+EMhAAy1gLvDwRWjAfyD0sL2P7leeDxP4H+fwc0uut/HU89MO4roMPtgKkSWD4O+PPL699vM2MQIiIiWdTvFXr7l2PIK66w/4vc+g8gIA4oyQHWPmv//TsyIYBjG4APk4AvxgA5+6TDVrfMBh7fCwx8CtC2su9rqj2Bez4Dut0LCBPw7RRgx/v2fQ07YxAiIiLZ3NMnEnHBPigoqcSUT9Ob5xDZiHcBKIA/PweOrLPv/h3ViW3A4tuBpaOAM7sAtQ7oPwOYsRe49VnAy6/5XlvlIR2W7Ps36f6aWcDm+VIwc0AMQkREJBuNhxIfjO8DXy819pwqwjNf74Xdz+GJSqh3iOxx1z5EVn4B+PphYMntQPZ2QKUF+j0iHQK77aWWO3tOqQSG/Qe4pXa5k43/Atb9Qxqn5GAYhIiISFYxgd5YOK4XPJQKfLfnLN7dlGn/F/nLc9IhsuJz0g+yKzq2Hng3Edi3ElCogD4PAX/fDQydC/gEt3w9CgVwawow9FXp/m8LgB8elU7bdyAMQkREJLub4gLx4v91AQDMX5eBdQdy7PsCai9gxAIACmDPMuDIz/bdv5wqS4BVT0hnahWfAwLaA5NSgb++DvhGyF0d0G9a7Rl8Kumz/2oiUFMpd1UWDEJEROQQ7u8XjQmJ0nxCT3y5BwfPGu37AlH9Lh4i++FRYN9XDtc7YbOTacCi/sCuj6X7CdOAv20B2vSWt65L9bgPuOdTQKUBDv0ILLtbCnAOgEGIiIgcxvN/7YwB7QNRVmXCw5/8jvxiO/cc3PoPIPAGoCQX+HoS8FYPIG0BUFls39dpbtUV0uzZi4cBF04AvpHSPD7DXrXPqfDNodNfgXErAbU3kLUZ+HSEQyyMy5mlG8GZpYmIWp6hrBp3vrsNxwtK0SvKD59P7gdPtcp+L1B+Adj5AbDjPaCsQHpMqwd6TwQSpjrG4aTGnPsT+OZvQP4h6X6PcdI4IE9feetqqtPp0izU5ReAoE7AA98C+jC7vgSX2LATBiEiInkczy/ByAXbYKyowaieEXjtnu5QKBT2fZHqCmDvl0DaO9Jq9QCg9AC6jgYSHwXCutn39a6XqQbY+jqw+VXAXAN4BwF3vAV0vF3uymyXdwj4dKQ0v1PrtsDkjXY9o41ByE4YhIiI5LP1aAEmLN4Jk1ng6aEd8MiguOZ5IbMZOPqzFIhO/Hrx8dhBQOJjQNxg6QwoORUcBb79G3AmXbrf6Q7gr28A3oGylnVdLpyQDo/FJQG3/9eunzGDkJ0wCBERyeuztBN4/vsDUCiA9+7vjSFdQpv3Bc/8IQWiA99JMyMDQHBnqYco/i7AQ9u8r38psxnY+T6wfg5QUwFofYHb5wPd7pE/nNlD2XnA00+ad8iOGITshEGIiEh+z3+3H5/9dhI6jQpfTb0JncNb4N/jomzgt0XAH58AVbVnN/mEAN3vtf+yFI05vvliL1XsrdIUAI4+hskBMAjZCYMQEZH8qk1mTFy8E9uOFSLCzwvfTe+PoFYt1DNTXgSkL5EGVhefbZnXvJRaBwz5J9Bnkmv0ArUABiE7YRAiInIMhrJqjHx3G7IKStE7ujU+n5wArYcdzyS7mpoq4MA3wMntAFrwZ1PjA9z4MBDQruVe0wUwCNkJgxARkePIzC/BnXVnkvWKwGt3N8OZZOQSbPn95oSKRETkFNoF+WDBuF5QKRX45o8zeG/LcblLIhfAIERERE5jQPsgvPDXzgCA/6w9jNSDuTJXRM6OQYiIiJzK+MRojEuIghDAo5//gY+2ZsFs5igPujYMQkRE5FQUCgVe/L8uSOoUgsoaM/656iDuff83nCgolbs0ckI2BaEXX3wRCoXC6tKxY0fL9kGDBl22ferUqVb7yM7OxvDhw6HT6RAcHIxZs2ahpsZ69d9NmzahV69e0Gq1iIuLw5IlSy6rZcGCBWjbti08PT2RkJCAnTt3Wm2vqKjA9OnTERAQAB8fH4wePRq5uexCJSJyBWqVEh+M741/39kV3hoVdp44j6FvbsGSbewdItvY3CPUpUsXnDt3znLZunWr1fbJkydbbZ83b55lm8lkwvDhw1FVVYXt27fjk08+wZIlS/DCCy9Y2mRlZWH48OG49dZbsWfPHsyYMQMPP/ww1q1bZ2nz5ZdfYubMmZgzZw7++OMPdO/eHcnJycjLy7O0eeKJJ/Djjz9i5cqV2Lx5M86ePYtRo0bZ+naJiMhBKRQKjEuIxtoZA3FTuwBUVJvx4o8HMfaD35BdWCZ3eeQshA3mzJkjunfvfsXtt9xyi3j88cevuP2nn34SSqVS5OTkWB5buHCh0Ov1orKyUgghxNNPPy26dOli9bwxY8aI5ORky/2+ffuK6dOnW+6bTCYRHh4u5s6dK4QQoqioSKjVarFy5UpLm0OHDgkAIi0trUnvVQghDAaDACAMBkOTn0NERC3PZDKLT7dniU7PrxHRs1eJjs+tEZ9szxImk1nu0kgGtvx+29wjdPToUYSHhyM2Nhbjxo1Ddna21fZly5YhMDAQXbt2RUpKCsrKLqbytLQ0xMfHIyQkxPJYcnIyjEYjDhw4YGmTlJRktc/k5GSkpaUBAKqqqpCenm7VRqlUIikpydImPT0d1dXVVm06duyIqKgoS5uGVFZWwmg0Wl2IiMjxKZUKPJDYFutmDES/WH+UV5vwwvcHcN+Hv+HUefYO0ZXZFIQSEhKwZMkSrF27FgsXLkRWVhYGDBiA4uJiAMB9992HpUuXYuPGjUhJScFnn32G+++/3/L8nJwcqxAEwHI/Jyen0TZGoxHl5eUoKCiAyWRqsE39fWg0Gvj5+V2xTUPmzp0LX19fyyUyMtKGT4eIiOQW6a/D5w/3w0v/1wVeahV+O34eyW9swWe/neTYIWqQhy2Nhw0bZrndrVs3JCQkIDo6GitWrMCkSZMwZcoUy/b4+HiEhYVh8ODByMzMRLt2jj89eEpKCmbOnGm5bzQaGYaIiJyMUqnAhJvaYlCHIMz6ai92Zp3H89/tx5p95/Cf0d0Q6a+Tu0RyINd1+ryfnx9uuOEGHDt2rMHtCQkJAGDZHhoaetmZW3X3Q0NDG22j1+vh5eWFwMBAqFSqBtvU30dVVRWKioqu2KYhWq0Wer3e6kJERM4pOsAbyyf3w5w7OsNTrcT2zEIMfWMLlu04CcHVpajWdQWhkpISZGZmIiwsrMHte/bsAQDL9sTEROzbt8/q7K7U1FTo9Xp07tzZ0mbDhg1W+0lNTUViYiIAQKPRoHfv3lZtzGYzNmzYYGnTu3dvqNVqqzYZGRnIzs62tCEiItenVCrwYP8YrH18IG5s2xqlVSb849v9GP/xThRXVMtdHjkCW0ZhP/nkk2LTpk0iKytLbNu2TSQlJYnAwECRl5cnjh07Jl5++WWxa9cukZWVJb7//nsRGxsrBg4caHl+TU2N6Nq1qxgyZIjYs2ePWLt2rQgKChIpKSmWNsePHxc6nU7MmjVLHDp0SCxYsECoVCqxdu1aS5vly5cLrVYrlixZIg4ePCimTJki/Pz8rM5Gmzp1qoiKihK//PKL2LVrl0hMTBSJiYm2vF2eNUZE5EJMJrP48NfjosNzP4no2avE3Yu2i7LKGrnLomZgy++3TUFozJgxIiwsTGg0GhERESHGjBkjjh07JoQQIjs7WwwcOFD4+/sLrVYr4uLixKxZsy4r4sSJE2LYsGHCy8tLBAYGiieffFJUV1dbtdm4caPo0aOH0Gg0IjY2VixevPiyWt5++20RFRUlNBqN6Nu3r/jtt9+stpeXl4tHHnlEtG7dWuh0OnHnnXeKc+fO2fJ2GYSIiFzQvtNFousLa0X07FViwsc7RGW1Se6SyM5s+f1WCMEDpVdiNBrh6+sLg8HA8UJERC7k9xPn8cBHO1BRbcbt8aF4696e8FBx1SlXYcvvN/+rExGR27mxrT/ef6APNColftqXg5Rv9vH0ejfFIERERG5p4A1BeGtsT6iUCqxMP42XVx3k2WRuiEGIiIjc1tCuoZg3uhsAYMn2E3g99YjMFVFLYxAiIiK3Nrp3G7w8ogsA4K1fjuG9zZkyV0QtiUGIiIjc3vjEtnh6aAcAwNw1h7Fsx0mZK6KWwiBEREQE4JFBcXhkkLQc1HPf7cf3e87IXBG1BAYhIiKiWrOSO2B8YjSEAGau+BM/H7jyQt3kGhiEiIiIaikUCrx4RxeM6hkBk1ng0c93Y9uxArnLombEIERERFSPUqnAvLu6IblLCKpMZkz+dBfST16QuyxqJgxCREREl/BQKfHW2J4Y0D4QZVUmPLh4Jw6cNchdFjUDBiEiIqIGaD1UeO+B3ugT3RrGihqM/2gnMvNL5C6L7IxBiIiI6Ap0Gg98/OCN6BqhR2FpFe7/cAf2ni6SuyyyIwYhIiKiRug91fjkwb6IC/bBOUMFRr27HW+uP4oak1nu0sgOGISIiIiuIsBHi6+mJmJ4tzDUmAVeX38Edy1Kw3EeKnN6DEJERERN4KfT4J2xPfHmvT3QytMDe04VYfhbW/HZbye5WKsTYxAiIiJqIoVCgRE9IrBuxkDc1C4A5dUmPP/dfjy45HfkGSvkLo+ugUIwxl6R0WiEr68vDAYD9Hq93OUQEZEDMZsFlmw/gVfXHkZVjRl+OjVeuTMet8eHyV2awxJC4JyhAsfzS5GZX4Lj+SXw8fTArOSOdn0dW36/GYQawSBERERXczS3GDO+3IMDZ40AgFE9I/DiiC7Qe6plrkw+5VUmHC8oqRd4pOusglKUVZms2kb6e+HXp/9i19dnELITBiEiImqKqhoz3tpwFO9uOgazAMJ9PfHfe7rjpnaBcpfW7ApLKpF6MBeHc4otoedMUfkV23soFYgK0KFdkA9ig7zRPrgV7urdxq41MQjZCYMQERHZIv3kecxc8SdOFpYBACbdHINZyR3gqVbJXJl9VVSbsP5QLr794ww2H8lHjfnyKOHrpUa7IG+0C/JBu2AfxAZ6o12wD6L8dVCrmneIMoOQnTAIERGRrUora/Cv1Yfwxc5sAMANIT743z090DXCV+bKro/ZLLAj6zy+3X0aa/bloLiyxrKta4QeibEBVqHH31sDhUIhS60MQnbCIERERNdqw6FczP56HwpKKqFSKtAv1h9DOofits4hCPfzkru8JjuaW4xvdp/B97vP4Kzh4plxEX5eGNkzHHf2jEBccCsZK7wcg5CdMAgREdH1KCypxD++3Y+1B3KsHo+P8MWQziFI7hqK9sE+svWcXElecQV+2HMW3+05g/1njJbHW3l6YHh8GO7sGYEb2/pDqXSsuuswCNkJgxAREdnDiYJSpB7Mxc8Hc7Dr5AXU/+VtG6DDkC6hGNI5BD2jWkMlU7g4X1qFzUfy8N3us/j1aD7qhv14KBUY1CEYo3pF4C8dg51ivBODkJ0wCBERkb3lF1fil8O5WHcgF1uPFaCq5uKaZYE+GiR1CkFyl1Aktgto1tBRUW3CrhMX8OuxfGw7VoADZ41WAa1nlB9G9YzA8G7h8PfWNFsdzYFByE4YhIiIqDmVVNZgy5F8/HwgBxsO56G44uIAZG+NCgPaB6FTmB4xQd6IDfRG20Bv+Gg9rum1TGaBg2eN2HqsAFuP5eP3ExesQhgAdAhphaFdQzGyZwRiAr2v673JiUHIThiEiIiopVSbzNhx/Dx+PpiDnw/kIucKS3YEtdIiJsAbMbXBKKb2Eh2gu6wHKbuwDFuPFWDbsQJsyyxAUVm11fZQvSf6xwViQPtA3BQXgOBWns32/loSg5CdMAgREZEczGaBfWcM2JZZgKz8UmQVlOJEYSkKSqqu+ByFAgj39UJMoDcCfDTYnV2E7PNlVm18tB7oFxuAm+MCcHP7ILQL8na4gdr2YMvv97X1rxEREVGzUSoV6B7ph+6RflaPG8qrcaI2FB3Pl66zCkqRlV+K4soanCkqt5rV2UOpQM8oP9wcF4Sb2wegWxu/Zp/M0NkwCBERETkJXy91gwFJCIHC0iqcKCjF8YJS5Boq0Dlcj4TYgGseU+Qu+OkQERE5OYVCgUAfLQJ9tOjT1l/ucpwK+8eIiIjIbTEIERERkdtiECIiIiK3xSBEREREbotBiIiIiNwWgxARERG5LQYhIiIiclsMQkREROS2GISIiIjIbTEIERERkdtiECIiIiK3xSBEREREbotBiIiIiNwWV59vhBACAGA0GmWuhIiIiJqq7ne77ne8MQxCjSguLgYAREZGylwJERER2aq4uBi+vr6NtlGIpsQlN2U2m3H27Fm0atUKCoXCrvs2Go2IjIzEqVOnoNfr7bpvZ8bP5cr42TSMn8uV8bNpGD+XK3OVz0YIgeLiYoSHh0OpbHwUEHuEGqFUKtGmTZtmfQ29Xu/UX7bmws/lyvjZNIyfy5Xxs2kYP5crc4XP5mo9QXU4WJqIiIjcFoMQERERuS0GIZlotVrMmTMHWq1W7lIcCj+XK+Nn0zB+LlfGz6Zh/FyuzB0/Gw6WJiIiIrfFHiEiIiJyWwxCRERE5LYYhIiIiMhtMQgRERGR22IQksGCBQvQtm1beHp6IiEhATt37pS7JNm9+OKLUCgUVpeOHTvKXZYstmzZgjvuuAPh4eFQKBT47rvvrLYLIfDCCy8gLCwMXl5eSEpKwtGjR+UptgVd7XOZOHHiZd+hoUOHylNsC5o7dy5uvPFGtGrVCsHBwRg5ciQyMjKs2lRUVGD69OkICAiAj48PRo8ejdzcXJkqbhlN+VwGDRp02Xdm6tSpMlXcchYuXIhu3bpZJk1MTEzEmjVrLNvd7fvCINTCvvzyS8ycORNz5szBH3/8ge7duyM5ORl5eXlylya7Ll264Ny5c5bL1q1b5S5JFqWlpejevTsWLFjQ4PZ58+bhrbfewqJFi7Bjxw54e3sjOTkZFRUVLVxpy7ra5wIAQ4cOtfoOffHFFy1YoTw2b96M6dOn47fffkNqaiqqq6sxZMgQlJaWWto88cQT+PHHH7Fy5Ups3rwZZ8+exahRo2Ssuvk15XMBgMmTJ1t9Z+bNmydTxS2nTZs2ePXVV5Geno5du3bhL3/5C0aMGIEDBw4AcMPvi6AW1bdvXzF9+nTLfZPJJMLDw8XcuXNlrEp+c+bMEd27d5e7DIcDQHz77beW+2azWYSGhor58+dbHisqKhJarVZ88cUXMlQoj0s/FyGEmDBhghgxYoQs9TiSvLw8AUBs3rxZCCF9P9RqtVi5cqWlzaFDhwQAkZaWJleZLe7Sz0UIIW655Rbx+OOPy1eUA2ndurX48MMP3fL7wh6hFlRVVYX09HQkJSVZHlMqlUhKSkJaWpqMlTmGo0ePIjw8HLGxsRg3bhyys7PlLsnhZGVlIScnx+o75Ovri4SEBH6HAGzatAnBwcHo0KEDpk2bhsLCQrlLanEGgwEA4O/vDwBIT09HdXW11XemY8eOiIqKcqvvzKWfS51ly5YhMDAQXbt2RUpKCsrKyuQoTzYmkwnLly9HaWkpEhMT3fL7wkVXW1BBQQFMJhNCQkKsHg8JCcHhw4dlqsoxJCQkYMmSJejQoQPOnTuHl156CQMGDMD+/fvRqlUructzGDk5OQDQ4Heobpu7Gjp0KEaNGoWYmBhkZmbi2WefxbBhw5CWlgaVSiV3eS3CbDZjxowZ6N+/P7p27QpA+s5oNBr4+flZtXWn70xDnwsA3HfffYiOjkZ4eDj27t2L2bNnIyMjA998842M1baMffv2ITExERUVFfDx8cG3336Lzp07Y8+ePW73fWEQIocwbNgwy+1u3bohISEB0dHRWLFiBSZNmiRjZeQs7r33Xsvt+Ph4dOvWDe3atcOmTZswePBgGStrOdOnT8f+/fvddnzdlVzpc5kyZYrldnx8PMLCwjB48GBkZmaiXbt2LV1mi+rQoQP27NkDg8GAr776ChMmTMDmzZvlLksWPDTWggIDA6FSqS4bfZ+bm4vQ0FCZqnJMfn5+uOGGG3Ds2DG5S3Eodd8TfoeuLjY2FoGBgW7zHXr00UexatUqbNy4EW3atLE8HhoaiqqqKhQVFVm1d5fvzJU+l4YkJCQAgFt8ZzQaDeLi4tC7d2/MnTsX3bt3x5tvvumW3xcGoRak0WjQu3dvbNiwwfKY2WzGhg0bkJiYKGNljqekpASZmZkICwuTuxSHEhMTg9DQUKvvkNFoxI4dO/gdusTp06dRWFjo8t8hIQQeffRRfPvtt/jll18QExNjtb13795Qq9VW35mMjAxkZ2e79Hfmap9LQ/bs2QMALv+daYjZbEZlZaVbfl94aKyFzZw5ExMmTECfPn3Qt29fvPHGGygtLcWDDz4od2myeuqpp3DHHXcgOjoaZ8+exZw5c6BSqTB27Fi5S2txJSUlVn+RZmVlYc+ePfD390dUVBRmzJiBf/3rX2jfvj1iYmLw/PPPIzw8HCNHjpSv6BbQ2Ofi7++Pl156CaNHj0ZoaCgyMzPx9NNPIy4uDsnJyTJW3fymT5+Ozz//HN9//z1atWplGcfh6+sLLy8v+Pr6YtKkSZg5cyb8/f2h1+vx2GOPITExEf369ZO5+uZztc8lMzMTn3/+OW6//XYEBARg7969eOKJJzBw4EB069ZN5uqbV0pKCoYNG4aoqCgUFxfj888/x6ZNm7Bu3Tr3/L7IfdqaO3r77bdFVFSU0Gg0om/fvuK3336TuyTZjRkzRoSFhQmNRiMiIiLEmDFjxLFjx+QuSxYbN24UAC67TJgwQQghnUL//PPPi5CQEKHVasXgwYNFRkaGvEW3gMY+l7KyMjFkyBARFBQk1Gq1iI6OFpMnTxY5OTlyl93sGvpMAIjFixdb2pSXl4tHHnlEtG7dWuh0OnHnnXeKc+fOyVd0C7ja55KdnS0GDhwo/P39hVarFXFxcWLWrFnCYDDIW3gLeOihh0R0dLTQaDQiKChIDB48WPz888+W7e72fVEIIURLBi8iIiIiR8ExQkREROS2GISIiIjIbTEIERERkdtiECIiIiK3xSBEREREbotBiIiIiNwWgxARERG5LQYhIiIiclsMQkREROS2GISIiIjIbTEIERERkdtiECIiIiK39f92o9U2tsi7LgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(scaler.inverse_transform(preds_test), label = 'Predict')\n",
    "plt.plot(scaler.inverse_transform(y_test), label='Real')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105bf108-440e-4ca3-aefa-777d1971a662",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13dce472-49ea-4696-aaed-3e7928bcc012",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "03e64535-4182-4041-8868-d4840fbc51c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_price_future(X_test, future_length, sample_nbr=10):\n",
    "    \n",
    "    #sorry for that, window_size is a global variable, and so are X_train and Xs\n",
    "    global window_size\n",
    "    global X_train\n",
    "    global Xs\n",
    "    global scaler\n",
    "    \n",
    "    #creating auxiliar variables for future prediction\n",
    "    preds_test = []\n",
    "    test_begin = X_test[0:1, :, :]\n",
    "    test_deque = deque(test_begin[0,:,0].tolist(), maxlen=window_size)\n",
    "\n",
    "    idx_pred = np.arange(len(X_train), len(Xs))\n",
    "    \n",
    "    #predict it and append to list\n",
    "    for i in range(len(X_test)):\n",
    "        #print(i)\n",
    "        as_net_input = torch.tensor(test_deque).unsqueeze(0).unsqueeze(2)\n",
    "        pred = [net(as_net_input).cpu().item() for i in range(sample_nbr)]\n",
    "        \n",
    "        \n",
    "        test_deque.append(torch.tensor(pred).mean().cpu().item())\n",
    "        preds_test.append(pred)\n",
    "        \n",
    "        if i % future_length == 0:\n",
    "            #our inptus become the i index of our X_test\n",
    "            #That tweak just helps us with shape issues\n",
    "            test_begin = X_test[i:i+1, :, :]\n",
    "            test_deque = deque(test_begin[0,:,0].tolist(), maxlen=window_size)\n",
    "\n",
    "    #preds_test = np.array(preds_test).reshape(-1, 1)\n",
    "    #preds_test_unscaled = scaler.inverse_transform(preds_test)\n",
    "    \n",
    "    return idx_pred, preds_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9ada138b-67fe-4151-aff7-772b30f263b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_confidence_intervals(preds_test, ci_multiplier):\n",
    "    global scaler\n",
    "    \n",
    "    preds_test = torch.tensor(preds_test)\n",
    "    \n",
    "    pred_mean = preds_test.mean(1)\n",
    "    pred_std = preds_test.std(1).detach().cpu().numpy()\n",
    "\n",
    "    pred_std = torch.tensor((pred_std))\n",
    "    #print(pred_std)\n",
    "    \n",
    "    upper_bound = pred_mean + (pred_std * ci_multiplier)\n",
    "    lower_bound = pred_mean - (pred_std * ci_multiplier)\n",
    "    #gather unscaled confidence intervals\n",
    "\n",
    "    pred_mean_final = pred_mean.unsqueeze(1).detach().cpu().numpy()\n",
    "    pred_mean_unscaled = scaler.inverse_transform(pred_mean_final)\n",
    "\n",
    "    upper_bound_unscaled = upper_bound.unsqueeze(1).detach().cpu().numpy()\n",
    "    upper_bound_unscaled = scaler.inverse_transform(upper_bound_unscaled)\n",
    "    \n",
    "    lower_bound_unscaled = lower_bound.unsqueeze(1).detach().cpu().numpy()\n",
    "    lower_bound_unscaled = scaler.inverse_transform(lower_bound_unscaled)\n",
    "    \n",
    "    return pred_mean_unscaled, upper_bound_unscaled, lower_bound_unscaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "22a58ae1-7b07-4053-a17c-5ffbd0fb6357",
   "metadata": {},
   "outputs": [],
   "source": [
    "future_length=8\n",
    "sample_nbr=4\n",
    "ci_multiplier=5\n",
    "idx_pred, preds_test = pred_price_future(X_test, future_length, sample_nbr)\n",
    "pred_mean_unscaled, upper_bound_unscaled, lower_bound_unscaled = get_confidence_intervals(preds_test,\n",
    "                                                                                          ci_multiplier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "791c9f0c-66c1-460f-b36f-fe269e5247b5",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (33,1) (31,1) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(train_건고추[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m평균가격(원)\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m113\u001b[39m:])\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m under_upper \u001b[38;5;241m=\u001b[39m upper_bound_unscaled \u001b[38;5;241m>\u001b[39m y\n\u001b[0;32m      3\u001b[0m over_lower \u001b[38;5;241m=\u001b[39m lower_bound_unscaled \u001b[38;5;241m<\u001b[39m y\n\u001b[0;32m      4\u001b[0m total \u001b[38;5;241m=\u001b[39m (under_upper \u001b[38;5;241m==\u001b[39m over_lower)\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (33,1) (31,1) "
     ]
    }
   ],
   "source": [
    "y = np.array(train_건고추['평균가격(원)'][113:]).reshape(-1, 1)\n",
    "under_upper = upper_bound_unscaled > y\n",
    "over_lower = lower_bound_unscaled < y\n",
    "total = (under_upper == over_lower)\n",
    "\n",
    "print(\"{} our predictions are in our confidence interval\".format(np.mean(total)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e07ab2ac-ec46-4434-bfe4-ea32c114654d",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_pred = idx_pred + window_size + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e27d7e-3081-4292-ba70-9141db2e616e",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\"ytick.color\" : \"w\",\n",
    "          \"xtick.color\" : \"w\",\n",
    "          \"axes.labelcolor\" : \"w\",\n",
    "          \"axes.edgecolor\" : \"w\"}\n",
    "\n",
    "plt.rcParams.update(params)\n",
    "plt.figure(figsize=(10,6))\n",
    "\n",
    "\n",
    "plt.title(\"Agriculture prices\", color=\"white\")\n",
    "\n",
    "plt.plot(df_pred.index,\n",
    "         df_pred['평균가격(원)'],\n",
    "         color='black',\n",
    "         label=\"Real\")\n",
    "\n",
    "plt.plot(idx_pred,\n",
    "         pred_mean_unscaled,\n",
    "         label=\"Prediction for {} days, than consult\".format(future_length),\n",
    "         color=\"red\")\n",
    "\n",
    "plt.fill_between(x=idx_pred,\n",
    "                 y1=upper_bound_unscaled[:,0],\n",
    "                 y2=lower_bound_unscaled[:,0],\n",
    "                 facecolor='green',\n",
    "                 label=\"Confidence interval\",\n",
    "                 alpha=0.5)\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb32e0b4-fe64-4cfe-862d-b39239be6212",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\"ytick.color\" : \"w\",\n",
    "          \"xtick.color\" : \"w\",\n",
    "          \"axes.labelcolor\" : \"w\",\n",
    "          \"axes.edgecolor\" : \"w\"}\n",
    "plt.rcParams.update(params)\n",
    "\n",
    "plt.title(\"IBM Stock prices\", color=\"white\")\n",
    "\n",
    "\n",
    "plt.fill_between(x=idx_pred,\n",
    "                 y1=upper_bound_unscaled[:,0],\n",
    "                 y2=lower_bound_unscaled[:,0],\n",
    "                 facecolor='green',\n",
    "                 label=\"Confidence interval\",\n",
    "                 alpha=0.75)\n",
    "\n",
    "plt.plot(idx_pred,\n",
    "         df_pred.Close[-len(pred_mean_unscaled):],\n",
    "         label=\"Real\",\n",
    "         alpha=1,\n",
    "         color='black',\n",
    "         linewidth=0.5)\n",
    "\n",
    "plt.plot(idx_pred,\n",
    "         pred_mean_unscaled,\n",
    "         label=\"Prediction for {} days, than consult\".format(future_length),\n",
    "         color=\"red\",\n",
    "         alpha=0.5)\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6635f704-6f2d-4ef2-b5eb-1a71b3e84b14",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
